---
# Source: oes/charts/gitea/charts/memcached/templates/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
automountServiceAccountToken: true
metadata:
  name: isd-memcached
  namespace: opsmx-isd
  labels:
    app.kubernetes.io/name: memcached
    helm.sh/chart: memcached-5.9.0
    app.kubernetes.io/instance: isd
    app.kubernetes.io/managed-by: Helm
---
# Source: oes/charts/minio/templates/post-install-prometheus-metrics-serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: isd-minio-update-prometheus-secret
  labels:
    app: minio-update-prometheus-secret
    chart: minio-8.0.9
    release: isd
    heritage: Helm
---
# Source: oes/charts/minio/templates/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: "isd-minio"
  namespace: "opsmx-isd"
  labels:
    app: minio
    chart: minio-8.0.9
    release: "isd"
---
# Source: oes/charts/spinnaker/templates/rbac/halyard-sa.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: isd-spinnaker-halyard
  namespace: opsmx-isd
  labels:
    app: "isd-spinnaker"
    heritage: "Helm"
    release: "isd"
    chart: "spinnaker-2.2.3"
---
# Source: oes/templates/forwarder/create-controller-secret.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: create-controller-secret
---
# Source: oes/charts/gitea/charts/postgresql/templates/secrets.yaml
apiVersion: v1
kind: Secret
metadata:
  name: isd-postgresql
  labels:
    app.kubernetes.io/name: postgresql
    helm.sh/chart: postgresql-10.3.17
    app.kubernetes.io/instance: isd
    app.kubernetes.io/managed-by: Helm
  namespace: opsmx-isd
type: Opaque
data:
  postgresql-postgres-password: "MVlXMkxwMjlTOQ=="
  postgresql-password: "Z2l0ZWE="
---
# Source: oes/charts/gitea/templates/gitea/config.yaml
apiVersion: v1
kind: Secret
metadata:
  name: isd-gitea-inline-config
  labels:
    helm.sh/chart: gitea-5.0.1
    app: gitea
    app.kubernetes.io/name: gitea
    app.kubernetes.io/instance: isd
    app.kubernetes.io/version: "1.15.10"
    version: "1.15.10"
    app.kubernetes.io/managed-by: Helm
type: Opaque
stringData:
  _generals_: ""
  cache: |-
    ADAPTER=memcache
    ENABLED=true
    HOST=isd-memcached.opsmx-isd.svc.cluster.local:11211
  database: |-
    DB_TYPE=postgres
    HOST=isd-postgresql.opsmx-isd.svc.cluster.local:5432
    NAME=gitea
    PASSWD=gitea
    USER=gitea
  metrics: ENABLED=false
  repository: ROOT=/data/git/gitea-repositories
  security: INSTALL_LOCK=true
  server: |-
    APP_DATA_PATH=/data
    DOMAIN=git.example.com
    ENABLE_PPROF=false
    HTTP_PORT=3000
    PROTOCOL=http
    ROOT_URL=http://git.example.com
    SSH_DOMAIN=git.example.com
    SSH_LISTEN_PORT=22
    SSH_PORT=22
---
# Source: oes/charts/gitea/templates/gitea/config.yaml
apiVersion: v1
kind: Secret
metadata:
  name: isd-gitea
  labels:
    helm.sh/chart: gitea-5.0.1
    app: gitea
    app.kubernetes.io/name: gitea
    app.kubernetes.io/instance: isd
    app.kubernetes.io/version: "1.15.10"
    version: "1.15.10"
    app.kubernetes.io/managed-by: Helm
type: Opaque
stringData:
  config_environment.sh: |-
    #!/usr/bin/env bash
    set -euo pipefail

    function env2ini::log() {
      printf "${1}\n"
    }

    function env2ini::read_config_to_env() {
      local section="${1}"
      local line="${2}"

      if [[ -z "${line}" ]]; then
        # skip empty line
        return
      fi
      
      # 'xargs echo -n' trims all leading/trailing whitespaces and a trailing new line
      local setting="$(awk -F '=' '{print $1}' <<< "${line}" | xargs echo -n)"

      if [[ -z "${setting}" ]]; then
        env2ini::log '  ! invalid setting'
        exit 1
      fi

      local value=''
      local regex="^${setting}(\s*)=(\s*)(.*)"
      if [[ $line =~ $regex ]]; then
        value="${BASH_REMATCH[3]}"
      else
        env2ini::log '  ! invalid setting'
        exit 1
      fi

      env2ini::log "    + '${setting}'"

      if [[ -z "${section}" ]]; then
        export "ENV_TO_INI____${setting^^}=${value}"                           # '^^' makes the variable content uppercase
        return
      fi

      local masked_section="${section//./_0X2E_}"                            # '//' instructs to replace all matches
      masked_section="${masked_section//-/_0X2D_}"

      export "ENV_TO_INI__${masked_section^^}__${setting^^}=${value}"        # '^^' makes the variable content uppercase
    }

    function env2ini::process_config_file() {
      local config_file="${1}"
      local section="$(basename "${config_file}")"

      if [[ $section == '_generals_' ]]; then
        env2ini::log "  [ini root]"
        section=''
      else
        env2ini::log "  ${section}"
      fi

      while read -r line; do
        env2ini::read_config_to_env "${section}" "${line}"
      done < <(awk 1 "${config_file}")                             # Helm .toYaml trims the trailing new line which breaks line processing; awk 1 ... adds it back while reading
    }

    function env2ini::load_config_sources() {
      local path="${1}"

      env2ini::log "Processing $(basename "${path}")..."

      while read -d '' configFile; do
        env2ini::process_config_file "${configFile}"
      done < <(find "${path}" -type l -not -name '..data' -print0)

      env2ini::log "\n"
    }

    function env2ini::generate_initial_secrets() {
      # These environment variables will either be
      #   - overwritten with user defined values,
      #   - initially used to set up Gitea
      # Anyway, they won't harm existing app.ini files

      export ENV_TO_INI__SECURITY__INTERNAL_TOKEN=$(gitea generate secret INTERNAL_TOKEN)
      export ENV_TO_INI__SECURITY__SECRET_KEY=$(gitea generate secret SECRET_KEY)
      export ENV_TO_INI__OAUTH2__JWT_SECRET=$(gitea generate secret JWT_SECRET)

      env2ini::log "...Initial secrets generated\n"
    }

    # MUST BE CALLED BEFORE OTHER CONFIGURATION
    env2ini::generate_initial_secrets

    env2ini::load_config_sources '/env-to-ini-mounts/inlines/'
    env2ini::load_config_sources '/env-to-ini-mounts/additionals/'

    env2ini::log "=== All configuration sources loaded ===\n"

    # safety to prevent rewrite of secret keys if an app.ini already exists
    if [ -f ${GITEA_APP_INI} ]; then
      env2ini::log 'An app.ini file already exists. To prevent overwriting secret keys, these settings are dropped and remain unchanged:'
      env2ini::log '  - security.INTERNAL_TOKEN'
      env2ini::log '  - security.SECRET_KEY'
      env2ini::log '  - oauth2.JWT_SECRET'

      unset ENV_TO_INI__SECURITY__INTERNAL_TOKEN
      unset ENV_TO_INI__SECURITY__SECRET_KEY
      unset ENV_TO_INI__OAUTH2__JWT_SECRET
    fi

    environment-to-ini -o $GITEA_APP_INI -p ENV_TO_INI
---
# Source: oes/charts/gitea/templates/gitea/init.yaml
apiVersion: v1
kind: Secret
metadata:
  name: isd-gitea-init
  labels:
    helm.sh/chart: gitea-5.0.1
    app: gitea
    app.kubernetes.io/name: gitea
    app.kubernetes.io/instance: isd
    app.kubernetes.io/version: "1.15.10"
    version: "1.15.10"
    app.kubernetes.io/managed-by: Helm
type: Opaque
stringData:
  init_directory_structure.sh: |-
    #!/usr/bin/env bash

    set -euo pipefail

    set -x
    chown 1000:1000 /data
    mkdir -p /data/git/.ssh
    chmod -R 700 /data/git/.ssh
    [ ! -d /data/gitea ] && mkdir -p /data/gitea/conf

    # prepare temp directory structure
    mkdir -p "${GITEA_TEMP}"
    chown 1000:1000 "${GITEA_TEMP}"
    chmod ug+rwx "${GITEA_TEMP}"

  configure_gitea.sh: |-
    #!/usr/bin/env bash

    set -euo pipefail
    # Connection retry inspired by https://gist.github.com/dublx/e99ea94858c07d2ca6de
    function test_db_connection() {
      local RETRY=0
      local MAX=30

      echo 'Wait for database to become avialable...'
      until [ "${RETRY}" -ge "${MAX}" ]; do
        nc -vz -w2 isd-postgresql 5432 && break
        RETRY=$[${RETRY}+1]
        echo "...not ready yet (${RETRY}/${MAX})"
      done

      if [ "${RETRY}" -ge "${MAX}" ]; then
        echo "Database not reachable after '${MAX}' attempts!"
        exit 1
      fi
    }

    test_db_connection

    echo '==== BEGIN GITEA CONFIGURATION ===='

    gitea migrate
    function configure_admin_user() {
      local ACCOUNT_ID=$(gitea admin user list --admin | grep -e "\s\+${GITEA_ADMIN_USERNAME}\s\+" | awk -F " " "{printf \$1}")
      if [[ -z "${ACCOUNT_ID}" ]]; then
        echo "No admin user '${GITEA_ADMIN_USERNAME}' found. Creating now..."
        gitea admin user create --admin --username "${GITEA_ADMIN_USERNAME}" --password "${GITEA_ADMIN_PASSWORD}" --email "support@opsmx.com" --must-change-password=false
        echo '...created.'
      else
        echo "Admin account '${GITEA_ADMIN_USERNAME}' already exist. Running update to sync password..."
        gitea admin user change-password --username "${GITEA_ADMIN_USERNAME}" --password "${GITEA_ADMIN_PASSWORD}"
        echo '...password sync done.'
      fi
    }

    configure_admin_user

    function configure_ldap() {
        echo 'no ldap configuration... skipping.'
    }

    configure_ldap

    function configure_oauth() {
        echo 'no oauth configuration... skipping.'
    }

    configure_oauth

    echo '==== END GITEA CONFIGURATION ===='
---
# Source: oes/charts/minio/templates/secrets.yaml
apiVersion: v1
kind: Secret
metadata:
  name: isd-minio
  labels:
    app: minio
    chart: minio-8.0.9
    release: isd
    heritage: Helm
type: Opaque
data:
  accesskey: "c3Bpbm5ha2VyYWRtaW4="
  secretkey: "c3Bpbm5ha2VyYWRtaW4="
---
# Source: oes/charts/openldap/templates/secret.yaml
apiVersion: v1
kind: Secret
metadata:
  name: isd-openldap
  labels:
    app: openldap
    chart: openldap-1.2.3
    release: isd
    heritage: Helm
type: Opaque
data:
  LDAP_ADMIN_PASSWORD: "b3BzbXhhZG1pbjEyMw=="
  LDAP_CONFIG_PASSWORD: "b3BzbXhjb25maWcxMjM="
---
# Source: oes/charts/redis/templates/secret.yaml
apiVersion: v1
kind: Secret
metadata:
  name: isd-redis
  labels:
    app: redis
    chart: redis-10.5.3
    release: "isd"
    heritage: "Helm"
type: Opaque
data:
  redis-password: "cGFzc3dvcmQ="
---
# Source: oes/charts/spinnaker/templates/secrets/registry.yaml
apiVersion: v1
kind: Secret
metadata:
  name: isd-spinnaker-registry
  labels:
    app: "isd-spinnaker"
    heritage: "Helm"
    release: "isd"
    chart: "spinnaker-2.2.3"
    component: clouddriver
type: Opaque
data:
  dockerhub: ""
---
# Source: oes/charts/spinnaker/templates/secrets/spin-config.yaml
apiVersion: v1
kind: Secret
metadata:
  name: isd-spinnaker-spin-config
  labels:
    app: "isd-spinnaker"
    heritage: "Helm"
    release: "isd"
    chart: "spinnaker-2.2.3"
stringData:
  config: |
    auth:
      basic:
        password: saporadmin
        username: admin
      enabled: true
    gate:
      endpoint: http://sapor-gate:8084
---
# Source: oes/templates/pipeline-promotion/local-spin-cli-config-secret.yaml
apiVersion: v1
stringData:
  # Spin CLI config content used by syncToSpinnaker stage
  # It is placed under ~/.spin/config
  # endpoint should be the spinnaker gate where pipelines are created/updated
  config: |-
    auth:
      basic:
        password: saporadmin
        username: admin
      enabled: true
    gate:
      endpoint: http://sapor-gate:8084
kind: Secret
metadata:
  name: local-spin-cli-config
---
# Source: oes/templates/pipeline-promotion/spin-cli-config-secret.yaml
apiVersion: v1
stringData:
  # Spin CLI config content used by syncToGit stage
  # It is placed under ~/.spin/config
  # custom job stage runs a spin cli and fetches the application/pipeline data
  # gate endpoint should point to the spinnaker from where application/pipeline data is fetched
  config: |-
    auth:
      basic:
        password: saporadmin
        username: admin
      enabled: true
    gate:
      endpoint: http://sapor-gate:8084
kind: Secret
metadata:
  name: spin-cli-config
---
# Source: oes/templates/sapor-gate/sapor-gate-secret.yaml
apiVersion: v1
data:
  gate-local.yml:
    c2VydmVyOgogIHRvbWNhdDoKICAgIGh0dHBzU2VydmVyUG9ydDogWC1Gb3J3YXJkZWQtUG9ydAogICAgaW50ZXJuYWxQcm94aWVzOiAuKgogICAgcHJvdG9jb2xIZWFkZXI6IFgtRm9yd2FyZGVkLVByb3RvCiAgICByZW1vdGVJcEhlYWRlcjogWC1Gb3J3YXJkZWQtRm9yCnNlY3VyaXR5OgogIGJhc2ljZm9ybToKICAgIGVuYWJsZWQ6IHRydWUKICB1c2VyOgogICAgbmFtZTogYWRtaW4KICAgIHBhc3N3b3JkOiBzYXBvcmFkbWluCg==
  gate-overrides.yml:
    IyMgV0FSTklORwojIyBUaGlzIGZpbGUgd2FzIGF1dG9nZW5lcmF0ZWQsIGFuZCBfd2lsbF8gYmUgb3ZlcndyaXR0ZW4gYnkgSGFseWFyZC4KIyMgQW55IGVkaXRzIHlvdSBtYWtlIGhlcmUgX3dpbGxfIGJlIGxvc3QuCgpzZXJ2aWNlczoKICBjbG91ZGRyaXZlcjoKICAgIGJhc2VVcmw6IGh0dHA6Ly9zcGluLWNsb3VkZHJpdmVyLXJvOjcwMDIKICAgIGVuYWJsZWQ6IHRydWUKICBlY2hvOgogICAgYmFzZVVybDogaHR0cDovL3NwaW4tZWNoby13b3JrZXI6ODA4OQogICAgZW5hYmxlZDogdHJ1ZQoKZ2xvYmFsLnNwaW5uYWtlci50aW1lem9uZTogQW1lcmljYS9Mb3NfQW5nZWxlcw==
  gate.yml:
    IyMgV0FSTklORwojIyBUaGlzIGZpbGUgd2FzIGF1dG9nZW5lcmF0ZWQsIGFuZCBfd2lsbF8gYmUgb3ZlcndyaXR0ZW4gYnkgSGFseWFyZC4KIyMgQW55IGVkaXRzIHlvdSBtYWtlIGhlcmUgX3dpbGxfIGJlIGxvc3QuCgpzcGVjdGF0b3I6CiAgYXBwbGljYXRpb25OYW1lOiAke3NwcmluZy5hcHBsaWNhdGlvbi5uYW1lfQogIHdlYkVuZHBvaW50OgogICAgZW5hYmxlZDogZmFsc2UKCnNwaW5uYWtlcjoKICBleHRlbnNpYmlsaXR5OgogICAgcGx1Z2luczoge30KICAgIHJlcG9zaXRvcmllczoge30KICAgIHBsdWdpbnMtcm9vdC1wYXRoOiAvb3B0L2dhdGUvcGx1Z2lucwogICAgc3RyaWN0LXBsdWdpbi1sb2FkaW5nOiBmYWxzZQoKc2VydmVyOgogIHNzbDoKICAgIGVuYWJsZWQ6IGZhbHNlCiAgcG9ydDogJzgwODQnCiAgYWRkcmVzczogMC4wLjAuMApzZWN1cml0eToKICBiYXNpYzoKICAgIGVuYWJsZWQ6IHRydWUKICB1c2VyOiB7fQpjb3JzOiB7fQpnb29nbGU6IHt9CgppbnRlZ3JhdGlvbnM6CiAgZ3JlbWxpbjoKICAgIGVuYWJsZWQ6IGZhbHNlCiAgICBiYXNlVXJsOiBodHRwczovL2FwaS5ncmVtbGluLmNvbS92MQoKIyBoYWxjb25maWcKCnNlcnZpY2VzOgogIGNsb3VkZHJpdmVyOgogICAgY29uZmlnOgogICAgICBkeW5hbWljRW5kcG9pbnRzOgogICAgICAgIGRlY2s6IGh0dHA6Ly9zcGluLWNsb3VkZHJpdmVyLXJvLWRlY2s6NzAwMgo=
  spinnaker.yml:
    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
  spinnakerconfig.yml:
    I0VtcHR5IGZpbGUK
kind: Secret
metadata:
  labels:
    app: oes
    component: sapor-gate
  name: sapor-gate-files
type: Opaque
---
# Source: oes/templates/secrets/bootstrap-secret.yaml
apiVersion: v1
stringData:
  bootstrap.yml: |-
    spring:
      cloud:
        vault:
          enterprise: false
          namespace: admin/isd-platform
          uri: https://server.vaultint.opsmx.net
          token: 123132
          enabled: false
          kv:
            enabled: false
          generic:
            enabled: false
    jasypt:
      encryptor:
        password: Q7udUkHPuA3VnNlOtksSgQ
    datasource:
      secretManagement:
        source: db
kind: Secret
metadata:
  name: bootstrap
  labels:
    heritage: "Helm"
    release: "isd"
    chart: "oes-3.12.2"
---
# Source: oes/templates/secrets/gitea-secret.yaml
apiVersion: v1
stringData:
  # Repo uri to fetch halyard configuration
  username: opsmx 
  password: opsmxadmin123
kind: Secret
metadata:
  name: gitea-secret
type: Opaque
---
# Source: oes/templates/secrets/oes-audit-client-secret.yaml
apiVersion: v1
stringData:
  audit-local.yml: |
    spring:
      datasource:
        url: jdbc:postgresql://oes-db:5432/auditdb
        username: 'postgres'
        password: 'networks123'
    logging:
      level:
        com.opsmx.auditclientservice: INFO
    standardErrorCodes:
      filePath: /opsmx/conf/standard-error-code.csv
    oes:
      admin:
        user: admin
    feign:
      client:
        config:
          default:
            connectTimeout: 5000
            readTimeout: 5000
            loggerLevel: basic
        platformservice:
          name: platformservice
          url: http://oes-platform:8095
        visibilityservice:
          name: visibilityservice
          url: http://oes-visibility:8096
    
kind: Secret
metadata:
  labels:
    app: oes
    component: auditclient
    heritage: "Helm"
    release: "isd"
    chart: "oes-3.12.2"
  name: oes-audit-client-config
---
# Source: oes/templates/secrets/oes-audit-service-secret.yaml
apiVersion: v1
stringData:
  audit-local.yml: |
    spring:
      datasource:
        url: jdbc:postgresql://oes-db:5432/auditdb
        username: 'postgres'
        password: 'networks123'
    logging:
        level:
          com.opsmx.auditservice: INFO
    standardErrorCodes:
      filePath: /opsmx/conf/standard-error-code.csv
    feign:
      client:
        config:
          default:
            connectTimeout: 100000
            readTimeout: 100000
            loggerLevel: basic
        platformservice:
          name: platformservice
          url: http://oes-platform:8095
        auditclientservice:
          name: auditclientservice
          url: http://oes-audit-client:8098
        oes:
          url: http://oes-sapor:8085
        autopilot:
          url: http://oes-autopilot:8090
        visibilityservice:
          url: http://oes-visibility:8096
        dashboard:
          url: http://oes-dashboard:8094
    
kind: Secret
metadata:
  labels:
    app: oes
    component: auditservice
    heritage: "Helm"
    release: "isd"
    chart: "oes-3.12.2"
  name: oes-audit-service-config
---
# Source: oes/templates/secrets/oes-autopilot-secret.yaml
apiVersion: v1
stringData:
  autopilot.properties: |
    # Enable Build Analysis
    build.analysis=false
    # DB configuration
    secret.datasource.username=postgres
    secret.datasource.password=networks123
    secret.datasource.url=jdbc:postgresql://oes-db:5432/opsmx
    secret.platform.url=http://oes-platform:8095
    secret.ds.protocol=http://
    secret.ds.url=localhost:5005
    
    server.host.dns.name=http://oes.example.ops.com
    
    gate.url=http://oes-gate:8084
    
    #datascience configuration
    oes.datascience.baseUrl=http://oes-datascience:5005
    #build.analysis=false
    ds.async.flow=true
    
    # Standard-error-path
    standardErrorCodes.filePath=/opsmx/conf/standard-error-code.csv
    
    #storage configuration
    storage.type =db_storage
    #storage.type =object_storage
    #storage.endpoint=http://isd-minio:9000
    #storage.accesskey = spinnakeradmin
    #storage.secretkey = spinnakeradmin
    #storage.region= us-east-1
    ds.seperate.service=true
    
    
    # Logging Level
    logging.level.com.opsmx.analytics=ERROR
    datasource.secretManagement.source = db
    
kind: Secret
metadata:
  name: oes-autopilot-config
  labels:
    app: oes
    component: autopilot
    heritage: "Helm"
    release: "isd"
    chart: "oes-3.12.2"
---
# Source: oes/templates/secrets/oes-datascience-secret.yaml
apiVersion: v1
stringData:
  app-config.yml: |
    # Enable Build Analysis
    APP:
       ENVIRONMENT: dev
       DEBUG: True
       # Only accept True or False
       BIND: 0.0.0.0:5005
       WORKERS: 1
       PROTOCOL: http://
       TIMEOUT: 3600
       CELERY_ENABLED: True
       # Only accept True or False
    
    OBJECT_STORAGE:
          ENDPOINT: http://isd-minio:9000
          BUCKET_NAME: autopilot
    POSTGRES:
          USERNAME: 'postgres'
          PASSWORD: 'networks123'
          HOST: oes-db
          PORT: 5432
          DB: autopilotqueue
    
    RABBITMQ:
          USERNAME: 'rabbitmq'
          PASSWORD: 'Networks123'
          HOST: rabbitmq-service
          PORT: 5672
    
  minio-credentials: |
    [default]
        aws_access_key_id = spinnakeradmin
        aws_secret_access_key = spinnakeradmin
    
    
kind: Secret
metadata:
  labels:
    app: oes
    component: datascience
  name: oes-datascience-config
---
# Source: oes/templates/secrets/oes-gate-configmap.yaml
apiVersion: v1
stringData:
  gate.yml: |
    retrofit:
      connectTimeout: 60000
      readTimeout: 60000
      callTimeout: 60000
      writeTimeout: 60000
      retryOnConnectionFailure: true
    services:
      opsmx:
        baseUrl: http://oes-sapor:8085
        enabled: true
      autopilot:
        baseUrl: http://oes-autopilot:8090
        enabled: true
      platform:
        baseUrl: http://oes-platform:8095
        userGroupApiPath: /platformservice/v1/users/{username}/usergroups/importAndCache
        enabled: true
      dashboard:
        baseUrl: http://oes-dashboard:8094
        enabled: true
      visibility:
        baseUrl: http://oes-visibility:8096
        enabled: true
      auditservice:
         baseUrl: "http://oes-audit-service:8097"
         enabled: true
      auditclient:
         baseUrl: "http://oes-audit-client:8098"
         enabled: true
      oesui:
        externalUrl: /ui/
      keel:
        enabled: false
      clouddriver:
        host: 0.0.0.0
        port: 7002
        baseUrl: http://spin-clouddriver-caching:7002
        enabled: true
      clouddriverCaching:
        host: 0.0.0.0
        port: 7002
        baseUrl: http://spin-clouddriver-caching:7002
        enabled: true
      clouddriverRo:
        host: 0.0.0.0
        port: 7002
        baseUrl: http://spin-clouddriver-ro:7002
        enabled: true
      clouddriverRoDeck:
        host: 0.0.0.0
        port: 7002
        baseUrl: http://spin-clouddriver-ro-deck:7002
        enabled: true
      clouddriverRw:
        host: 0.0.0.0
        port: 7002
        baseUrl: http://spin-clouddriver-rw:7002
        enabled: true
      deck:
        host: 0.0.0.0
        port: 9000
        baseUrl: http://oes.example.ops.com
        enabled: true
      echo:
        host: 0.0.0.0
        port: 8089
        baseUrl: http://spin-echo-worker:8089
        enabled: true
      echoScheduler:
        host: 0.0.0.0
        port: 8089
        baseUrl: http://spin-echo-scheduler:8089
        enabled: true
      echoWorker:
        host: 0.0.0.0
        port: 8089
        baseUrl: http://spin-echo-worker:8089
        enabled: true
      fiat:
        host: 0.0.0.0
        port: 7003
        baseUrl: http://spin-fiat:7003
        enabled: false
      front50:
        host: 0.0.0.0
        port: 8080
        baseUrl: http://spin-front50:8080
        enabled: true
      gate:
        host: 0.0.0.0
        port: 8084
        baseUrl: https://oes-gate.example.ops.com
        enabled: true
      igor:
        host: 0.0.0.0
        port: 8088
        baseUrl: http://spin-igor:8088
        enabled: true
      kayenta:
        host: 0.0.0.0
        port: 8090
        baseUrl: http://spin-kayenta:8090
        enabled: false
      orca:
        host: 0.0.0.0
        port: 8083
        baseUrl: http://spin-orca:8083
        enabled: true
      redis:
        host: 0.0.0.0
        port: 6379
        baseUrl: redis://:password@isd-redis-master:6379
        enabled: true
      rosco:
        host: 0.0.0.0
        port: 8087
        baseUrl: http://spin-rosco:8087
        enabled: true
      user: {}
    cors:
      allowed-origins-pattern: ^https?://(?:localhost|oes.example.ops.com|spin.example.ops.com|opsmx.com)(?::[1-9]\d*)?/?
      
    ldap:
      enabled: true
      managerDn: cn=admin,dc=example,dc=org
      groupSearchBase: ou=groups,dc=example,dc=org
      groupSearchFilter: member={0}
      userDnPattern: cn={0},dc=example,dc=org
      url: ldap://isd-openldap:389
      managerPassword: opsmxadmin123
    file:
      enabled: false
      url: /platformservice/v1/users/authenticate
    authn:
      mode: session
    google: {}
    redis:
      connection: redis://:password@isd-redis-master:6379
    server:
      session:
        timeoutInSeconds: 7200
      tomcat:
        httpsServerPort: X-Forwarded-Port
        internalProxies: .*
        protocolHeader: X-Forwarded-Proto
        remoteIpHeader: X-Forwarded-For
    gate:
      installation:
        mode: common    #Allowed values are --> oes,common
    rbac:
      feature:
        application:
          enabled: false
    spinnaker:
      extensibility:
        plugins:
        deck-proxy:
          enabled: true
          plugins:
            Opsmx.VerificationGatePlugin:
              enabled: true
              version: 1.0.1
            Opsmx.TestVerificationGatePlugin:
              enabled: true
              version: 1.0.1
            Opsmx.PolicyGatePlugin:
              enabled: true
              version: 1.0.1
            Opsmx.VisibilityApprovalPlugin:
              enabled: true
              version: 1.0.1
        repositories:
            opsmx-repo:
              url: file:///opt/spinnaker/plugins/plugins.json
              #url: https://raw.githubusercontent.com/OpsMx/spinnakerPluginRepository/v3.10.0/plugins.json
    
    allowUnauthenticatedAccess:
      agentAPI: false
      webhooks: false
    
    logging:
      level:
        com.netflix.spinnaker.gate.security: INFO
        org.springframework.security: INFO
        org.springframework.web: INFO
        #com.netflix.spinnaker.gate.security: DEBUG
        #org.springframework.security: DEBUG
        #org.springframework.web: DEBUG
    
    
    
kind: Secret
metadata:
  name: oes-gate-config
  labels:
    app: oes
    component: gate
    heritage: "Helm"
    release: "isd"
    chart: "oes-3.12.2"
---
# Source: oes/templates/secrets/oes-gate-secret.yaml
apiVersion: v1
stringData:
  GATEURL: http://sapor-gate:8084
  GATEUSER: admin
  GATEPASS: saporadmin
kind: Secret
metadata:
  name: oes-gate-secret
  labels:
    heritage: "Helm"
    release: "isd"
    chart: "oes-3.12.2"
---
# Source: oes/templates/secrets/oes-platform-configmap.yaml
apiVersion: v1
stringData:
  platform-local.yml: |
    
    spring:
      datasource:
        url: jdbc:postgresql://oes-db:5432/platformdb
        username: 'postgres'
        password: 'networks123'
    ldap.managerPassword: 'opsmxadmin123'
    redis:
        connection: redis://:password@isd-redis-master:6379
    #datasource.url: jdbc:postgresql://oes-db:5432/visibilitydb
    #postgres.password: 'networks123'
    #postgres.username: 'postgres'
    
    datasource:
      secretManagement:
        source: db
    rbacEnabled: false
    supportedFeatures:
      - deployment_verification
      - sapor
      - visibility
    userGroup:
      superAdminGroups: admin
    user:
      source: ldap
    ldap:
      enabled: true
      url: ldap://isd-openldap:389
      managerDn: cn=admin,dc=example,dc=org
      groupSearchBase: ou=groups,dc=example,dc=org
      groupSearchFilter: member={0}
      groupRoleAttributes: cn
      userDnPattern: cn={0},dc=example,dc=org
    
    oes:
      sapor:
        url: http://oes-sapor:8085
      autopilot:
        url: http://oes-autopilot:8090
      dashboard:
        url: http://oes-dashboard:8094
      visibility:
        url: http://oes-visibility:8096
      auditclient:
        url: http://oes-audit-client:8098
      gate:
        url: http://oes-gate:8084
      approvalGate:
        apiUrl: http://oes-gate:8084/visibilityservice/v5/approvalGates/{id}/trigger
    
      verificationGate:
        apiUrl: http://oes-gate:8084/autopilot/api/v3/registerCanary
    
    logging:
      level:
        com.opsmx.platformservice: INFO
        org.springframework.security: INFO
        org.springframework.web: INFO
    
    standardErrorCodes:
      filePath: /opsmx/conf/standard-error-code.csv
    
kind: Secret
metadata:
  name: oes-platform-config
  labels:
    app: oes
    component: platform
    heritage: "Helm"
    release: "isd"
    chart: "oes-3.12.2"
---
# Source: oes/templates/secrets/oes-sapor-configmap.yaml
apiVersion: v1
stringData:
  application.yml: |
    spring:
      datasource:
        url: jdbc:postgresql://oes-db:5432/oesdb
        username: 'postgres'
        password: 'networks123'
    
    standardErrorCodes:
      filePath: /opsmx/conf/standard-error-code.csv
    
    secretManagement:
      source:
        config: db
      encryption: true
    oes:
      rbac:
        enabled: true
      admin:
        user: admin
      platform:
        url: http://oes-platform:8095
      visibility:
        url: http://oes-visibility:8096
      auditservice:
        enabled: true
        url: "http://oes-audit-service:8097" 
      dashboard:
        url: http://oes-dashboard:8094
      commongateurl: http://oes-gate:8084
    pipeline-promotion:
      github:
        
        enabled: true
        
        username:  opsmx
        token: opsmxadmin123
        branch: master
        cloneUrl: http://opsmx:opsmxadmin123@isd-gitea-http.opsmx-isd:3000/opsmx/gitea-standard-repo
      bitbucket:
        
        enabled: false
        
        username:  git/stash_username
        token: git/stash_token
        branch: master
        cloneUrl: https://git/stash_username:git/stash_token@github.com/OpsMx//standard-gitops-repo
      amazonS3:
        
        enabled: false
        
        accessKeyId: AWS_ACCESS_KEY_ID
        secretAccessKey: AWS_SECRET_ACCESS_KEY
        region: regionofbucket
        bucketName: bucket name.e.g-testbucket 
    spinnaker:
      restart:
        endPoint: /webhooks/webhook/restartSpinnaker
      encrypt:
        enabled: false
      sync:
        permission:
          enabled: true
    
    datasources:
      platform: true
      
    ## Set the below field to true if agent for kubernetes
    kubernetes:
      kinds:
      omitKinds:
      - podPreset
      agent:
        enabled: true
        serverInternalHostName: opsmx-controller-controller1
        serverPort: 9003
        caCertfile: /opt/opsmx/controller/ca.crt
        certFile: /opt/opsmx/controller/cert/tls.crt
        keyFile: /opt/opsmx/controller/cert/tls.key
        image: quay.io/opsmxpublic/forwarder-agent:v3.12.0
      template:
        path: /opt/opsmx/controller
        kubectlTemplateFileName: kubeconfig.template
        manifestTemplateFileName: deploy-agent.template
    
  client.p12: |
    
kind: Secret
metadata:
  name: oes-sapor-config
  labels:
    app: oes
    component: sapor
    heritage: "Helm"
    release: "isd"
    chart: "oes-3.12.2"
---
# Source: oes/templates/secrets/oes-visibility-secret.yaml
apiVersion: v1
stringData:
  visibility-local.yml: |
    spring:
      datasource:
        url: jdbc:postgresql://oes-db:5432/visibilitydb
        username: 'postgres'
        password: 'networks123'
        #sslmode: require
      visiblity:
        connectors:
          configured: JIRA,GIT,AUTOPILOT,SONARQUBE,JENKINS,AQUAWAVE
      logging:
        level:  
          io:     
            swagger:
              models: 
                parameters:
                  AbstractSerializableParameter: ERROR
    gate:
      url: http://oes-gate:8084
    
    jira:
      api:
        url: /rest/api/2/search
      navigate:
        url: hosturl/browse/{issue_Id}
    
    git:
      apiurl: /repos/{username}/{repo}/commits/{commitId}
      userurl: /user
      navigate.url: https://github.com/OpsMx/{repo_name}/commit/{commit_Id}
    
    jenkins:
      api:
        url: /jenkins/job/{jobname}/{buildId}/api/json
      navigate:
        url: hosturl/jenkins/job/{jobname}/{buildId}
    
    sonar:
      navigate:
        Url: hosturl/dashboard?id={projectKey}
    
    aquawave:
      api:
        url: https://api.aquasec.com/v2/images/{id}
      navigate:
        url: https://cloud.aquasec.com/vs/#/images/{id}
    
    autopilot:
      api:
        url: http://oes-autopilot:8090
    
    platform:
      service:
        url: http://oes-platform:8095
    
    datasource:
      secretManagement:
        source: db
    
    standardErrorCodes:
      filePath: /opsmx/conf/standard-error-code.csv
    
    
kind: Secret
metadata:
  name: oes-visibility-config
  labels:
    app: oes
    component: visibility
    heritage: "Helm"
    release: "isd"
    chart: "oes-3.12.2"
---
# Source: oes/templates/secrets/opsmx-gitops-secret.yaml
apiVersion: v1
stringData:
  # Repo uri to fetch halyard configuration
  gitcloneparam: https://git/stash_username:git%2Fstash_token@github.com/OpsMx/standard-gitops-repo.git

  # Repo details to fetch dynamic configuration
  dynamicaccountsgituri: https://github.com/OpsMx/standard-gitops-repo.git
  gituser: git/stash_username
  gittoken: git/stash_token
  dynamicAccRepository: standard-gitops-repo

kind: Secret
metadata:
  name: opsmx-gitops-auth
type: Opaque
---
# Source: oes/templates/secrets/sapor-bootstrap-secret.yaml
apiVersion: v1
stringData:
  bootstrap.yml: |-
    spring:
      cloud:
        config:
          server:
            composite:
              - type: native
                search-locations: ${user.home}/config
        vault:
          enterprise: false
          namespace: admin/isd-platform
          uri: https://server.vaultint.opsmx.net
          token: 123132
          enabled: false
          kv:
            enabled: false
          generic:
            enabled: false
    jasypt:
      encryptor:
        password: Q7udUkHPuA3VnNlOtksSgQ
kind: Secret
metadata:
  name: sapor-bootstrap
  labels:
    heritage: "Helm"
    release: "isd"
    chart: "oes-3.12.2"
---
# Source: oes/charts/minio/templates/configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: isd-minio
  labels:
    app: minio
    chart: minio-8.0.9
    release: isd
    heritage: Helm
data:
  initialize: |-
    #!/bin/sh
    set -e ; # Have script exit in the event of a failed command.
    MC_CONFIG_DIR="/etc/minio/mc/"
    MC="/usr/bin/mc --insecure --config-dir ${MC_CONFIG_DIR}"
    
    # connectToMinio
    # Use a check-sleep-check loop to wait for Minio service to be available
    connectToMinio() {
      SCHEME=$1
      ATTEMPTS=0 ; LIMIT=29 ; # Allow 30 attempts
      set -e ; # fail if we can't read the keys.
      ACCESS=$(cat /config/accesskey) ; SECRET=$(cat /config/secretkey) ;
      set +e ; # The connections to minio are allowed to fail.
      echo "Connecting to Minio server: $SCHEME://$MINIO_ENDPOINT:$MINIO_PORT" ;
      MC_COMMAND="${MC} config host add myminio $SCHEME://$MINIO_ENDPOINT:$MINIO_PORT $ACCESS $SECRET" ;
      $MC_COMMAND ;
      STATUS=$? ;
      until [ $STATUS = 0 ]
      do
        ATTEMPTS=`expr $ATTEMPTS + 1` ;
        echo \"Failed attempts: $ATTEMPTS\" ;
        if [ $ATTEMPTS -gt $LIMIT ]; then
          exit 1 ;
        fi ;
        sleep 2 ; # 1 second intervals between attempts
        $MC_COMMAND ;
        STATUS=$? ;
      done ;
      set -e ; # reset `e` as active
      return 0
    }
    
    # checkBucketExists ($bucket)
    # Check if the bucket exists, by using the exit code of `mc ls`
    checkBucketExists() {
      BUCKET=$1
      CMD=$(${MC} ls myminio/$BUCKET > /dev/null 2>&1)
      return $?
    }
    
    # createBucket ($bucket, $policy, $purge)
    # Ensure bucket exists, purging if asked to
    createBucket() {
      BUCKET=$1
      POLICY=$2
      PURGE=$3
      VERSIONING=$4
    
      # Purge the bucket, if set & exists
      # Since PURGE is user input, check explicitly for `true`
      if [ $PURGE = true ]; then
        if checkBucketExists $BUCKET ; then
          echo "Purging bucket '$BUCKET'."
          set +e ; # don't exit if this fails
          ${MC} rm -r --force myminio/$BUCKET
          set -e ; # reset `e` as active
        else
          echo "Bucket '$BUCKET' does not exist, skipping purge."
        fi
      fi
    
      # Create the bucket if it does not exist
      if ! checkBucketExists $BUCKET ; then
        echo "Creating bucket '$BUCKET'"
        ${MC} mb myminio/$BUCKET
      else
        echo "Bucket '$BUCKET' already exists."
      fi
    
    
      # set versioning for bucket
      if [ ! -z $VERSIONING ] ; then
        if [ $VERSIONING = true ] ; then
            echo "Enabling versioning for '$BUCKET'"
            ${MC} version enable myminio/$BUCKET
        elif [ $VERSIONING = false ] ; then
            echo "Suspending versioning for '$BUCKET'"
            ${MC} version suspend myminio/$BUCKET
        fi
      else
          echo "Bucket '$BUCKET' versioning unchanged."
      fi
    
      # At this point, the bucket should exist, skip checking for existence
      # Set policy on the bucket
      echo "Setting policy of bucket '$BUCKET' to '$POLICY'."
      ${MC} policy set $POLICY myminio/$BUCKET
    }
    
    # Try connecting to Minio instance
    scheme=http
    connectToMinio $scheme
    # Create the bucket
    
    # Create the buckets
    createBucket spinnaker none false 
    createBucket autopilot none false
---
# Source: oes/charts/openldap/templates/configmap-customldif.yaml
#
# A ConfigMap spec for openldap slapd that map directly to files under
# /container/service/slapd/assets/config/bootstrap/ldif/custom
#
apiVersion: v1
kind: ConfigMap
metadata:
  name: isd-openldap-customldif
  labels:
    app: openldap
    chart: openldap-1.2.3
    release: isd
    heritage: Helm
data:
  01-memberof.ldif: |-
    dn: cn=module,cn=config
    cn: module
    objectClass: olcModuleList
    olcModuleLoad: memberof.la
    olcModulePath: /usr/lib/ldap
    
    dn: olcOverlay={0}memberof,olcDatabase={1}hdb,cn=config
    objectClass: olcConfig
    objectClass: olcMemberOf
    objectClass: olcOverlayConfig
    objectClass: top
    olcOverlay: memberof
    olcMemberOfDangling: ignore
    olcMemberOfRefInt: TRUE
    olcMemberOfGroupOC: groupOfNames
    olcMemberOfMemberAD: member
    olcMemberOfMemberOfAD: memberOf
  02-refint1.ldif: |-
    dn: cn=module{1},cn=config
    changetype: modify
    add: olcmoduleload
    olcmoduleload: refint.la
  03-refint2.ldif: |-
    dn: olcOverlay={1}refint,olcDatabase={1}hdb,cn=config
    objectClass: olcConfig
    objectClass: olcOverlayConfig
    objectClass: olcRefintConfig
    objectClass: top
    olcOverlay: {1}refint
    olcRefintAttribute: memberof member manager owner
  04-add_ou.ldif: |-
    dn: ou=groups,dc=example,dc=org
    objectClass: organizationalUnit
    ou: Groups
  05-admin.ldif: |-
    dn: cn=admin,ou=groups,dc=example,dc=org
    objectClass: groupofnames
    cn: admin
    description: read write and execute group
    member: cn=admin,dc=example,dc=org
  06-developer.ldif: |-
    dn: cn=developers,ou=groups,dc=example,dc=org
    objectClass: groupofnames
    cn: developers
    description: read only users
    member: cn=admin,dc=example,dc=org
    member: cn=developer,dc=example,dc=org
  07-qa.ldif: |-
    dn: cn=QA,ou=groups,dc=example,dc=org
    objectClass: groupofnames
    cn: QA
    description: read only users
    member: cn=admin,dc=example,dc=org
    member: cn=qa,dc=example,dc=org
  08-manager.ldif: |-
    dn: cn=managers,ou=groups,dc=example,dc=org
    objectClass: groupofnames
    cn: managers
    description: read and execute group
    member: cn=admin,dc=example,dc=org
    member: cn=manager,dc=example,dc=org
  09-IT-manager.ldif: |-
    dn: cn=ITManagers,ou=groups,dc=example,dc=org
    objectClass: groupofnames
    cn: ITManagers
    description: read and execute group
    member: cn=admin,dc=example,dc=org
    member: cn=ITManager,dc=example,dc=org
  10-users.ldif: |-
    dn: cn=user1,dc=example,dc=org
    objectClass: simpleSecurityObject
    objectClass: organizationalRole
    cn: user1
    userpassword: {SSHA}Y9L4AsYL16WLK10qDZ62pTScFnaWb0nz
    
    dn: cn=user2,dc=example,dc=org
    objectClass: simpleSecurityObject
    objectClass: organizationalRole
    cn: user2
    userpassword: {SSHA}DasTBI0eut1F83Bh1F1HXmDT8juJj3pY
    
    dn: cn=user3,dc=example,dc=org
    objectClass: simpleSecurityObject
    objectClass: organizationalRole
    cn: user3
    userpassword: {SSHA}Qu1FW7BdLMndwM/Gf+zc3a8VIMAymbuv
    
    dn: cn=developers,ou=groups,dc=example,dc=org
    changetype: modify
    add: member
    member: cn=user1,dc=example,dc=org
    member: cn=user3,dc=example,dc=org
    
    dn: cn=QA,ou=groups,dc=example,dc=org
    changetype: modify
    add: member
    member: cn=user2,dc=example,dc=org
    member: cn=user3,dc=example,dc=org
---
# Source: oes/charts/openldap/templates/configmap-env.yaml
#
# A ConfigMap spec for openldap slapd that map directly to env variables in the Pod.
# List of environment variables supported is from the docker image:
# https://github.com/osixia/docker-openldap#beginner-guide
# Note that passwords are defined as secrets
#
apiVersion: v1
kind: ConfigMap
metadata:
  name: isd-openldap-env
  labels:
    app: openldap
    chart: openldap-1.2.3
    release: isd
    heritage: Helm
data:
  LDAP_BACKEND: hdb
  LDAP_DOMAIN: example.org
  LDAP_ORGANISATION: Example Inc.
  LDAP_REMOVE_CONFIG_AFTER_SETUP: "false"
  LDAP_TLS: "true"
  LDAP_TLS_ENFORCE: "false"
---
# Source: oes/charts/redis/templates/configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: isd-redis
  labels:
    app: redis
    chart: redis-10.5.3
    heritage: Helm
    release: isd
data:
  redis.conf: |-
    # User-supplied configuration:
    # Enable AOF https://redis.io/topics/persistence#append-only-file
    appendonly no
    # Disable RDB persistence, AOF persistence already enabled.
    save 60 1000
  master.conf: |-
    dir /data
    rename-command FLUSHDB ""
    rename-command FLUSHALL ""
  replica.conf: |-
    dir /data
    slave-read-only yes
    rename-command FLUSHDB ""
    rename-command FLUSHALL ""
---
# Source: oes/charts/redis/templates/health-configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: isd-redis-health
  labels:
    app: redis
    chart: redis-10.5.3
    heritage: Helm
    release: isd
data:
  ping_readiness_local.sh: |-
    response=$(
      timeout -s 9 $1 \
      redis-cli \
        -a $REDIS_PASSWORD --no-auth-warning \
        -h localhost \
        -p $REDIS_PORT \
        ping
    )
    if [ "$response" != "PONG" ]; then
      echo "$response"
      exit 1
    fi
  ping_liveness_local.sh: |-
    response=$(
      timeout -s 9 $1 \
      redis-cli \
        -a $REDIS_PASSWORD --no-auth-warning \
        -h localhost \
        -p $REDIS_PORT \
        ping
    )
    if [ "$response" != "PONG" ] && [ "$response" != "LOADING Redis is loading the dataset in memory" ]; then
      echo "$response"
      exit 1
    fi
  ping_readiness_master.sh: |-
    response=$(
      timeout -s 9 $1 \
      redis-cli \
        -a $REDIS_MASTER_PASSWORD --no-auth-warning \
        -h $REDIS_MASTER_HOST \
        -p $REDIS_MASTER_PORT_NUMBER \
        ping
    )
    if [ "$response" != "PONG" ]; then
      echo "$response"
      exit 1
    fi
  ping_liveness_master.sh: |-
    response=$(
      timeout -s 9 $1 \
      redis-cli \
        -a $REDIS_MASTER_PASSWORD --no-auth-warning \
        -h $REDIS_MASTER_HOST \
        -p $REDIS_MASTER_PORT_NUMBER \
        ping
    )
    if [ "$response" != "PONG" ] && [ "$response" != "LOADING Redis is loading the dataset in memory" ]; then
      echo "$response"
      exit 1
    fi
  ping_readiness_local_and_master.sh: |-
    script_dir="$(dirname "$0")"
    exit_status=0
    "$script_dir/ping_readiness_local.sh" $1 || exit_status=$?
    "$script_dir/ping_readiness_master.sh" $1 || exit_status=$?
    exit $exit_status
  ping_liveness_local_and_master.sh: |-
    script_dir="$(dirname "$0")"
    exit_status=0
    "$script_dir/ping_liveness_local.sh" $1 || exit_status=$?
    "$script_dir/ping_liveness_master.sh" $1 || exit_status=$?
    exit $exit_status
---
# Source: oes/charts/spinnaker/templates/configmap/additional-profile-configmaps.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: isd-spinnaker-additional-profile-config-maps
  labels:
    app: "isd-spinnaker"
    heritage: "Helm"
    release: "isd"
    chart: "spinnaker-2.2.3"
data:
  echo-local.yml: |-
    microsoftteams:
      enabled: true
    rest:
      enabled: true
      endpoints:
      - url: http://oes-audit-service:8097/auditservice/v1/echo/events/data
        wrap: false
      - url: http://oes-sapor:8085/oes/echo
        wrap: false
  fiat-local.yml: |-
    auth:
      groupMembership:
        ldap:
          groupRoleAttributes: cn
          groupSearchBase: ou=groups,dc=example,dc=org
          groupSearchFilter: member={0}
          managerDn: cn=admin,dc=example,dc=org
          managerPassword: opsmxadmin123
          url: ldap://RELEASE_NAME-openldap:389
          userDnPattern: cn={0},dc=example,dc=org
        service: ldap
  front50-local.yml: |-
    policy:
      opa:
        enabled: true
        url: http://oes-sapor.opsmx-isd:8085
    spinnaker:
      s3:
        versioning: false
  gate-local.yml: |-
    server:
      tomcat:
        httpsServerPort: X-Forwarded-Port
        internalProxies: .*
        protocolHeader: X-Forwarded-Proto
        remoteIpHeader: X-Forwarded-For
    spinnaker:
      extensibility:
        deck-proxy:
          enabled: true
          plugins:
            Opsmx.CustomStagePlugin:
              enabled: true
              version: 1.0.1
            Opsmx.PolicyGatePlugin:
              enabled: true
              version: 1.0.1
            Opsmx.TestVerificationGatePlugin:
              enabled: true
              version: 1.0.1
            Opsmx.VerificationGatePlugin:
              enabled: true
              version: 1.0.1
            Opsmx.VisibilityApprovalPlugin:
              enabled: true
              version: 1.0.1
        plugins: null
        repositories:
          opsmx-repo:
            url: https://raw.githubusercontent.com/opsmx/spinnakerPluginRepository/v3.9.0/plugins.json
  # Custom stage for pipeline promotion;
  # same configuration can be put in a repo for gitops style
  orca-local.yml: |-
    
    policy:
      opa:
        enabled: true
        url: http://oes-sapor:8085
    pollers:
      oldPipelineCleanup:
        enabled: true                  # This enables old pipeline execution cleanup (default: false)
        intervalMs: 3600000            # How many milliseconds between pipeline cleanup runs (default: 1hr or 3600000)
        thresholdDays: 30              # How old a pipeline execution must be to be deleted (default: 30)
        minimumPipelineExecutions: 5   # How many executions to keep around (default: 5)
    
    tasks:
      daysOfExecutionHistory: 180      # How many days to keep old task executions around.
    
    job:
      preconfigured:
        kubernetes:
          - label: pipelineSyncToGit
            cloudProvider: kubernetes
            credentials: default
            description: Update git with pipelines in Spinnaker
            account: default
            application: sampleapp
            type: pipelineSyncToGit
            waitForCompletion: true
            parameters:
              - defaultValue: "app1,app2,..."
                description: "Please enter spinnaker applications separated by comma"
                label: spinnaker applications
                mapping: 'manifest.spec.template.spec.containers[0].env[0].value'
                name: spinnaker_applications
              - defaultValue: "pipeline1,pipeline2..."
                description: "Please enter spinnaker pipelines separated by comma"
                label: pipieline names
                mapping: 'manifest.spec.template.spec.containers[0].env[1].value'
                name: spinnaker_pipelines
            manifest:
                apiVersion: batch/v1
                kind: Job
                metadata:
                  generateName: pipepromot-
                  namespace: SPINNAKER_NAMESPACE
                  labels:
                     stage: opsmx-custom
                     stagetype: pipelinepromotion
                spec:
                  backoffLimit: 0
                  template:
                    spec:
                      containers:
                      - command: ["bash", "scripts/deployer.sh"]
                        image: 'opsmxdev/pipepromot:1.0'
                        imagePullPolicy: IfNotPresent
                        name: pipepromot
                        volumeMounts:
                        - mountPath: /home/opsmx/scripts
                          name: pipe-promot-scripts
                        - mountPath: /home/opsmx/config
                          name: pipe-promot-config
                        - mountPath: /home/opsmx/.spin
                          name: spin-cli-config
                        env:
                          - name: spinnaker_applications
                            value: 'will be replaced'
                          - name: spinnaker_pipelines
                            value: 'will be replaced'
                          - name: command
                            value: 'upload'
                          - name: git_secret_token
                            valueFrom:
                              secretKeyRef:
                                name: git-token
                                key: git_secret_token
                          - name: git_pr_token
                            valueFrom:
                              secretKeyRef:
                                name: git-token
                                key: git_pr_token
                      volumes:
                      - configMap:
                          defaultMode: 420
                          name: pipe-promot-config
                        name: pipe-promot-config
                      - configMap:
                          defaultMode: 420
                          name: pipe-promot-scripts
                        name: pipe-promot-scripts
                      - name: spin-cli-config
                        secret:
                          defaultMode: 420
                          secretName: spin-cli-config
                      restartPolicy: Never
                      serviceAccountName: default
          - label: pipelineSyncToSpinnaker
            cloudProvider: kubernetes
            credentials: default
            description: Sync Spinnaker pipelines from git
            account: default
            application: sampleapp
            type: pipelineSyncToSpinnaker
            waitForCompletion: true
            parameters:
              - defaultValue: "app1,app2,..."
                description: "Please enter spinnaker applications separated by comma"
                label: spinnaker applications
                mapping: 'manifest.spec.template.spec.containers[0].env[0].value'
                name: spinnaker_applications
              - defaultValue: "pipeline1,pipeline2..."
                description: "Please enter spinnaker pipelines separated by comma"
                label: pipieline names
                mapping: 'manifest.spec.template.spec.containers[0].env[1].value'
                name: spinnaker_pipelines
            manifest:
                apiVersion: batch/v1
                kind: Job
                metadata:
                  generateName: pipepromot-
                  namespace: SPINNAKER_NAMESPACE
                  labels:
                     stage: opsmx-custom
                     stagetype: pipelinepromotion
                spec:
                  backoffLimit: 0
                  template:
                    spec:
                      containers:
                      - command: ["bash", "scripts/deployer.sh"]
                        image: 'opsmxdev/pipepromot:1.0'
                        imagePullPolicy: IfNotPresent
                        name: pipepromot
                        volumeMounts:
                        - mountPath: /home/opsmx/scripts
                          name: pipe-promot-scripts
                        - mountPath: /home/opsmx/config
                          name: pipe-promot-config
                        - mountPath: /home/opsmx/.spin
                          name: spin-cli-config
                        env:
                          - name: spinnaker_applications
                            value: 'will be replaced'
                          - name: spinnaker_pipelines
                            value: 'will be replaced'
                          - name: command
                            value: 'download'
                          - name: git_secret_token
                            valueFrom:
                              secretKeyRef:
                                name: git-token
                                key: git_secret_token
                          - name: git_pr_token
                            valueFrom:
                              secretKeyRef:
                                name: git-token
                                key: git_pr_token
                      volumes:
                      - configMap:
                          defaultMode: 420
                          name: pipe-promot-config
                        name: pipe-promot-config
                      - configMap:
                          defaultMode: 420
                          name: pipe-promot-scripts
                        name: pipe-promot-scripts
                      - name: spin-cli-config
                        secret:
                          defaultMode: 420
                          secretName: local-spin-cli-config
                      restartPolicy: Never
                      serviceAccountName: default
    webhook:
      preconfigured:
      - label: "JIRA: Wait for state"
        type: waitJiraState
        enabled: true
        description: Custom stage that waits for a specific state on a Jira Issue
        method: GET
        url: https://<DOMAIN>/rest/api/latest/issue/${parameterValues['issue']}
        customHeaders:
          ## Provide the JIRA credentails that are in base64 encoded USER:PASSWORD/TOKEN
          Authorization: Basic base64{<<USER>>:<<Jira-token>>}
          Content-Type: application/json
        failPipeline: true
        progressJsonPath: "fields.status.name"
        payload: ""
        retryStatusCodes:
          - 200
        statusJsonPath: "fields.status.name"
        statusUrlResolution: "getMethod"
        successStatuses: ${parameterValues['success']}
        retryStatuses: ${parameterValue['retry']}
        terminalStatuses: ${parameterValues['terminate']}
        canceledStatuses: ${parameterValues['cancel']}
        waitBeforeMonitor: "1"
        waitForCompletion: true
        parameters:
        - label: JIRA Issue ID
          name: issue
          description: "The JIRA issue, the default relies on JIRA issue ID extraction"
          type: string
          defaultValue: ${jira_issue}
        - label: JIRA Retry States
          name: retry
          description: "JIRA issue states that Retry the stage e.g,: To Do, In Progress, etc."
          type: string
          defaultValue: To Do, In Progress
        - label: JIRA Success States
          name: success
          description: "JIRA issue States that progress the pipeline, e.g,: In Verificaiton etc."
          type: string
          defaultValue: In Verification
        - label: JIRA Temination States
          name: terminate
          description: "JIRA issue states that terminates the pipeline, e.g,: PR Raised etc."
          type: string
          defaultValue: PR Raised
        - label: JIRA Canceled States
          name: cancel
          description: "JIRA issue states that cancel the pipeline e.g,: Done, etc."
          type: string
          defaultValue: Done
      - label: "JIRA: Create Issue"
        type: addJiraIss
        enabled: true
        description: Custom stage that add an Issue in Jira
        method: POST
        url: https://<DOMAIN>/rest/api/2/issue/
        customHeaders:
         ## Provide the JIRA credentails that are in base64 encoded USER:PASSWORD/TOKEN
         Authorization: Basic base64{<<USER>>:<<Jira-token>>}
         Content-Type: application/json
        payload: |-
          {
            "fields": {
               "project":
                {
                  "key": "${parameterValues['projectid']}"
                },
                "summary": "${parameterValues['summary']}",
                "description": "${parameterValues['description']}",
                "issuetype": {
                  "name": "${parameterValues['issuetype']}"
                },
                "components": [
                    {
                  "id": "${parameterValues['components']}"
                }
                ],
                "priority": {
                  "name": "${parameterValues['priority']}"
                }
            }
          }
        parameters:
        - label: Project ID ("ENG" or "DOCS")
          name: projectid
          description: Which JIRA project do you want to create an item in?
          type: string
        - label: Issue Type ("Improvement", "Task", "New Feature", or "Bug")
          name: issuetype
          description: issuetype
          type: string
        - label: Priority ("Low", "Medium", or "High")
          name: priority
          description: priority
          type: string
        - label: Components ("10103")
          name: components
          description: component of the project
        - label: Issue Summary
          name: summary
          description: summary
          type: string
        - label: Description
          name: description
          description: description
          type: string
      - label: "JIRA: Comment on Issue"
        type: comJiraIss
        enabled: true
        description: Custom stage that posts a comment in a Jira Issue
        method: POST
        url: https://<DOMAIN>/rest/api/latest/issue/${parameterValues['issue']}/comment
        customHeaders:
          ## Provide the JIRA credentails that are in base64 encoded USER:PASSWORD/TOKEN
          Authorization: Basic base64{<<USER>>:<<Jira-token>>}
          Content-Type: application/json
        payload: |-
          {
            "body": "${parameterValues['message']}"
          }
        parameters:
        - label: Issue ID
          name: issue
          description: Issue
          type: string
        - label: Message
          name: message
          description: message
          type: string
      - label: "JIRA: Update Issue"
        type: updJiraIss
        enabled: true
        description: Custom stage that updates an Issue in Jira
        method: PUT
        url: https://<DOMAIN>/rest/api/latest/issue/${parameterValues['issue']}
        customHeaders:
          ## Provide the JIRA credentails that are in base64 encoded USER:PASSWORD/TOKEN
          Authorization: Basic base64{<<USER>>:<<Jira-token>>}
          Content-Type: application/json
        payload: |-
          {
            "update": {
                "summary": [
                    {
                        "set": "${parameterValues['summary']}"
                    }
                ],
                "description": [
                    {
                       "set": "${parameterValues['description']}"
                    }
                ]
            }
          }
        parameters:
        - label: Issue ID
          name: issue
          description: Issue
          type: string
        - label: Summary
          name: summary
          description: summary
          type: string
        - label: Description
          name: description
          description: description
      - label: "JIRA: Transition Issue"
        type: transJiraIss
        enabled: true
        description: Custom stage that transitions an Issue in Jira
        method: POST
        url: https://<DOMAIN>/rest/api/latest/issue/${parameterValues['issue']}/transitions
        customHeaders:
          ## Provide the JIRA credentails that are in base64 encoded USER:PASSWORD/TOKEN
          Authorization: Basic base64{<<USER>>:<<Jira-token>>}
          Content-Type: application/json
        payload: |-
          {
            "transition": {
              "id": "${parameterValues['targetStageID']}"
            }
          }
        parameters:
        - label: Issue ID
          name: issue
          description: Issue
          type: string
        - label: Target Stage ID
          name: targetStageID
          description: Target Stage ID (11 is "To Do", 21 is "In Progress", 31 is "In Review", 41 is "Done")
          type: string
    spinnaker:
      extensibility:
        plugins-root-path: /tmp/plugins
        plugins:
          Opsmx.VerificationGatePlugin:
            enabled: true
            version: 1.0.1
            config:
          Opsmx.VisibilityApprovalPlugin:
            enabled: true
            version: 1.0.1
            config:
          Opsmx.TestVerificationGatePlugin:
            enabled: true
            version: 1.0.1
            config:
          Opsmx.PolicyGatePlugin:
            enabled: true
            version: 1.0.1
            config:
          Opsmx.RbacPlugin:
            enabled: true
            version: 1.0.1
            config:
        repositories:
          opsmx-repo:
            id: opsmx-repo
            url: file:///opt/spinnaker/plugins/plugins.json
            #url: https://raw.githubusercontent.com/opsmx/spinnakerPluginRepository/v3.10.0/plugins.json
    

  echo-local.yml: |-
    rest:
      enabled: true
      endpoints:
       -
        wrap: false
        url: http://oes-sapor.opsmx-isd:8085/oes/echo
---
# Source: oes/charts/spinnaker/templates/configmap/halyard-config.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: isd-spinnaker-halyard-config
  labels:
    app: "isd-spinnaker"
    heritage: "Helm"
    release: "isd"
    chart: "spinnaker-2.2.3"
data:
  install.sh: |
    #!/bin/bash

    # Wait for the Hal daemon to be ready
    export DAEMON_ENDPOINT=http://isd-spinnaker-halyard:8064
    export HAL_COMMAND="hal --daemon-endpoint $DAEMON_ENDPOINT"
    until $HAL_COMMAND --ready; do sleep 10 ; done # end of if not gitops

    # This is performed by post-start script in halyard pod
    # in case gitopsHalyard is enabled
  clean.sh: |
    export HAL_COMMAND='hal --daemon-endpoint http://isd-spinnaker-halyard:8064'
    if $HAL_COMMAND --ready; then
      $HAL_COMMAND deploy clean -q
    fi
  config.sh: |
    # Spinnaker version
    
    $HAL_COMMAND config version edit --version 1.26.6
    

    # Storage
    
    echo spinnakeradmin | $HAL_COMMAND config storage s3 edit \
        --endpoint http://isd-minio:9000 \
        --access-key-id spinnakeradmin \
        --secret-access-key --bucket spinnaker \
        --path-style-access true
    $HAL_COMMAND config storage edit --type s3
    
    
    
    

    # Docker Registry
    $HAL_COMMAND config provider docker-registry enable

    if $HAL_COMMAND config provider docker-registry account get dockerhub; then
      PROVIDER_COMMAND='edit'
    else
      PROVIDER_COMMAND='add'
    fi

    $HAL_COMMAND config provider docker-registry account $PROVIDER_COMMAND dockerhub --address index.docker.io \
       \
      --repositories library/alpine,library/ubuntu,library/centos,library/nginx

    $HAL_COMMAND config provider kubernetes enable

    if $HAL_COMMAND config provider kubernetes account get default; then
      PROVIDER_COMMAND='edit'
    else
      PROVIDER_COMMAND='add'
    fi

    $HAL_COMMAND config provider kubernetes account $PROVIDER_COMMAND default --docker-registries dockerhub \
                --context default --service-account true \
                 \
                --only-spinnaker-managed true \
                 \
                 \
                --omit-namespaces=kube-system,kube-public \
                 \
                 \
                 \
                --provider-version v2
    $HAL_COMMAND config deploy edit --account-name default --type distributed \
                           --location opsmx-isd
    $HAL_COMMAND config deploy ha clouddriver enable
    $HAL_COMMAND config deploy ha echo enable

    
    



    # Enable Authentication by default
    $HAL_COMMAND config security authn ldap edit --url ldap://isd-openldap:389 --user-dn-pattern  'cn={0},dc=example,dc=org'
    $HAL_COMMAND config security authn ldap enable

    # Enable Authorization
    $HAL_COMMAND config security authz disable


    # Use Deck to route to Gate
---
# Source: oes/charts/spinnaker/templates/configmap/halyard-init-script.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: isd-spinnaker-halyard-init-script
  labels:
    app: "isd-spinnaker"
    heritage: "Helm"
    release: "isd"
    chart: "spinnaker-2.2.3"
data:
  init.sh: |

    echo \"Checking for Gitea services\"
    wait_period=0
    while true
    do
    kubectl get po -n opsmx-isd -o jsonpath='{range .items[*]}{..metadata.name}{"\t"}{..containerStatuses..ready}{"\n"}{end}' > /tmp/inst.status
    GITEA=$(grep gitea-0 /tmp/inst.status |grep -v deck | awk '{print $2}')

    wait_period=$(($wait_period+10))
    if [ "$GITEA" == "true" ];
    then
        echo \"Gitea Pod is ready\"
        break
    else
        if [ $wait_period -gt 1800 ];
        then
            echo \"Script is timed out as the Gitea is not ready in 30 min.......\"
            break
        else
            echo \"Waiting for Gitea to be ready\"
            sleep 1m
        fi
    fi
    done
    rm -rf /tmp/spinnaker/repo.json
    gitea_user=`echo $GITEA_USER | sed 's/ *$//g'`
    gitea_pass=`echo $GITEA_PASS | sed 's/ *$//g'`
    basic_auth=$(echo -n $gitea_user:$gitea_pass |base64)
    DYNAMIC_ACCOUNTS_REPO=http://isd-gitea-http.$SPINNAKER_NAMESPACE:3000/$gitea_user/gitea-standard-repo.git
    GIT_USER=$gitea_user
    GIT_TOKEN=$gitea_pass

    echo "Checking if the local gitea repo exists....." 
    curl -k -X GET "http://isd-gitea-http.$SPINNAKER_NAMESPACE:3000/api/v1/users/$gitea_user/repos" >/tmp/spinnaker/repo.json
    checkrepo=$(cat /tmp/spinnaker/repo.json | jq '.[] | select(.name=="gitea-standard-repo")')

        if [ -z "$checkrepo" ]
        then
                echo "Creating a New Local Gitea Repo gitea-standard-repo......."
                curl -k -X POST "http://isd-gitea-http.$SPINNAKER_NAMESPACE:3000/api/v1/user/repos" -H "content-type: application/json" -H "Authorization: Basic $basic_auth" --data '{"name":"'gitea-standard-repo'"}'
                git clone https://github.com/OpsMx/standard-gitops-repo.git -b 3.12 /tmp/spinnaker/test/standard-gitops-repo/
                git clone http://$gitea_user:$gitea_pass@isd-gitea-http.$SPINNAKER_NAMESPACE:3000/$gitea_user/gitea-standard-repo.git /tmp/spinnaker/test/gitea-standard-repo/
                cp -pr /tmp/spinnaker/test/standard-gitops-repo/* /tmp/spinnaker/test/gitea-standard-repo/
                cd /tmp/spinnaker/test/gitea-standard-repo/
                git status
                git add .
                git config user.email support@opsmx.com
                git config user.name $gitea_user
                git commit -m "cloned standard-gitops-repo content"
                git push
                cd
                rm -rf /tmp/spinnaker/test/gitea-standard-repo
                rm -rf /tmp/spinnaker/test/standard-gitops-repo
                rm -rf /tmp/spinnaker/test
                git clone http://$gitea_user:$gitea_pass@isd-gitea-http.$SPINNAKER_NAMESPACE:3000/$gitea_user/gitea-standard-repo.git /tmp/spinnaker/test/

        else
                echo "Local Repo exits...."
                rm -rf /tmp/spinnaker/test/gitea-standard-repo
                git clone http://$gitea_user:$gitea_pass@isd-gitea-http.$SPINNAKER_NAMESPACE:3000/$gitea_user/gitea-standard-repo.git /tmp/spinnaker/test
        fi
        #override the repotye to gitea in order to support pipelin-promotion
        sed -i  s/repo_type=git/repo_type=gitea/ /tmp/spinnaker/test/pipeline-promotion/pipe-promot-config-cm.yaml
        sed -i  s/git_user=/git_user=${GIT_USER}/ /tmp/spinnaker/test/pipeline-promotion/pipe-promot-config-cm.yaml
        sed -i  s/root_folder=/root_folder=pipeline-promotion/ /tmp/spinnaker/test/pipeline-promotion/pipe-promot-config-cm.yaml
    #!/bin/bash -x
    rm -rf /tmp/spinnaker/.hal


    cp -r /tmp/spinnaker/test// /tmp/spinnaker/.hal
    if [ -d "/tmp/spinnaker/test/pipeline-promotion/" ]
    then
       cp -r /tmp/spinnaker/test/pipeline-promotion /tmp/spinnaker/pipeline-promotion
    fi
    rm -rf /tmp/spinnaker/test
    DYNAMIC_ACCOUNTS_REPO=`echo $DYNAMIC_ACCOUNTS_REPO | sed 's/ *$//g'`
    sed -i  s/SPINNAKER_NAMESPACE/${SPINNAKER_NAMESPACE}/ /tmp/spinnaker/.hal/config
    sed -i  s/RELEASE_NAME/isd/g /tmp/spinnaker/.hal/config
    sed -i  s/GIT_USER/${GIT_USER}/g /tmp/spinnaker/.hal/default/profiles/spinnakerconfig.yml
    sed -i  s/GIT_TOKEN/${GIT_TOKEN}/g /tmp/spinnaker/.hal/default/profiles/spinnakerconfig.yml
    sed -i  's|DYNAMIC_ACCOUNTS_REPO|'"${DYNAMIC_ACCOUNTS_REPO}"'|' /tmp/spinnaker/.hal/default/profiles/spinnakerconfig.yml
    sed -i  s%DYN_ACCNT_CONFG_PATH%/%g /tmp/spinnaker/.hal/default/profiles/spinnakerconfig.yml
    sed -i  s/RELEASE_NAME/isd/g /tmp/spinnaker/.hal/default/profiles/rosco-local.yml
    sed -i  s/RELEASE_NAME/isd/g /tmp/spinnaker/.hal/default/service-settings/redis.yml
    yq e '.deploymentConfigurations.[].security.authz.enabled = "false"' /tmp/spinnaker/.hal/config > /tmp/spinnaker/.hal/config1
    mv /tmp/spinnaker/.hal/config1 /tmp/spinnaker/.hal/config
    if [ -f /tmp/spinnaker/.hal/default/profiles/fiat-local.yml ]; then
    sed -i  s/RELEASE_NAME/isd/g /tmp/spinnaker/.hal/default/profiles/fiat-local.yml
    fi
    sed -i  s/SPINNAKER_NAMESPACE/${SPINNAKER_NAMESPACE}/ /tmp/spinnaker/.hal/default/profiles/orca-local.yml
    printf 'server.address: 0.0.0.0\n' > /tmp/config/halyard-local.yml
    if [ -f /tmp/spinnaker/.hal/halyard.yaml ]; then
    cp /tmp/spinnaker/.hal/halyard.yaml /tmp/config
    fi  # git or stash  # Enabled  # End of S3
    # pipeline promotion configuration setup
    #
    ls -lart /home/spinnaker/java-lib/
    if [ -d "/tmp/spinnaker/pipeline-promotion/" ]
    then
      #decrypt_key=$(kubectl get cm bootstrap -o yaml  -n ${SPINNAKER_NAMESPACE}| grep 'password:' | awk '{ print $2}')
      decrypt_key=$(kubectl get secret bootstrap -o jsonpath='{.data.bootstrap\.yml}' -n ${SPINNAKER_NAMESPACE} | base64 -d | grep 'password:' | awk '{ print $2}')
      if [[ $decrypt_key != "" ]];
      then
        for filename in /tmp/spinnaker/pipeline-promotion/*; do
          java -cp "Decryptor.jar:/home/spinnaker/java-lib/*" Decryptor $decrypt_key "$filename"
        done
      mkdir /tmp/spinnaker/pipeline-decrypted/
      mv /tmp/spinnaker/pipeline-promotion/*decrypted.yaml /tmp/spinnaker/pipeline-decrypted/
      kubectl apply -f /tmp/spinnaker/pipeline-promotion/pipe-promot-config-cm.yaml -n ${SPINNAKER_NAMESPACE}
      kubectl apply -f /tmp/spinnaker/pipeline-decrypted/ -n ${SPINNAKER_NAMESPACE}
     fi
    fi
---
# Source: oes/charts/spinnaker/templates/configmap/halyard-overrideurl.yaml
apiVersion: v1
data:
  call_overrides.sh: |
    echo $SPINNAKER_NAMESPACE
    sh /tmp/autoconfig/config_overrideurl.sh spin-gate-overrideurl-gitops
    sh /tmp/autoconfig/config_overrideurl.sh spin-deck-overrideurl-gitops
  config_overrideurl.sh: |
    #!/bin/bash -x

    if [ $# -gt 1 ]
    then
       echo "Invalid input, only one argument expected"
       exit
    fi

    COMPONENT=$1
    EXTERNAL_IP_CHECK_DELAY=1

    check_for_loadBalancer()
    {
        ## Wait for $EXTERNAL_IP_CHECK_DELAY till K8s assins a load Balancer IP to oes-gate
        iter=0
        lapsedTime=0
        while [ $iter -lt 100 ]
        do
          ENDPOINT_IP=$(kubectl get svc $1 -o jsonpath="{.status.loadBalancer.ingress[].ip}")
          if [ ! -z "$ENDPOINT_IP" ];
          then
            echo "Found LoadBalancer IP for" $1
            break
          fi
          sleep 5
          lapsedTime=`expr $lapsedTime + 5`
          if [ $lapsedTime -gt $EXTERNAL_IP_CHECK_DELAY ];
          then
    	echo "Time Lapsed" $lapsedTime
            echo "Timeout! Fetching nodeport IP alternatively"
            break
          fi
          echo "Time Lapsed" $lapsedTime
          iter=`expr $iter + 1`
        done
    }

    case "$COMPONENT" in
      spin-gate)
        ENDPOINT_IP=""
        PORT=8084

        ## Wait for $EXTERNAL_IP_CHECK_DELAY till K8s assins a load Balancer IP to oes-gate
        check_for_loadBalancer spin-gate-lb

        ## If external IP is not available
        if [ -z "$ENDPOINT_IP" ]; then
          ## Fetch the nodePort IP and replace in spinnaker.yaml
          #ENDPOINT_IP=$(kubectl get ep kubernetes -n default -o jsonpath="{.subsets[].addresses[].ip}")
          ENDPOINT_IP=$NODE_IP
          PORT=$(kubectl get svc spin-gate-np -o jsonpath="{.spec.ports[].nodePort}")
          sed -i  s/OVERRIDE_API_URL/$ENDPOINT_IP:$PORT/g /tmp/spinnaker/.hal/config
        else
          ## Substitute spin-gate external IP in hal config
          sed -i  s/OVERRIDE_API_URL/$ENDPOINT_IP:$PORT/g /tmp/spinnaker/.hal/config
        fi
        ;;

      spin-deck)
        ENDPOINT_IP=""
        PORT=9000

        ## Wait for $EXTERNAL_IP_CHECK_DELAY till K8s assins a load Balancer IP to oes-gate
        check_for_loadBalancer spin-deck-lb

        ## If external IP is not available
        if [ -z "$ENDPOINT_IP" ]; then
          ## Fetch the nodePort & nodeport and replace in app-config.js
          ENDPOINT_IP=$NODE_IP
          PORT=$(kubectl get svc spin-deck-np -o jsonpath="{.spec.ports[].nodePort}")
          sed -i  s/OVERRIDE_DECK_URL/$ENDPOINT_IP:$PORT/g /tmp/spinnaker/.hal/config
        else
          ## Substitute spin-deck external IP in hal config
          sed -i  s/OVERRIDE_DECK_URL/$ENDPOINT_IP:$PORT/g /tmp/spinnaker/.hal/config
        fi
        ;;
      override-gate-url)
        ENDPOINT_IP=""
        PORT=8084

        export DAEMON_ENDPOINT=http://isd-spinnaker-halyard:8064
        export HAL_COMMAND="hal --daemon-endpoint $DAEMON_ENDPOINT"

        ## Wait for $EXTERNAL_IP_CHECK_DELAY till K8s assins a load Balancer IP to oes-gate
        check_for_loadBalancer spin-gate-np

        ## If external IP is not available
        if [ -z "$ENDPOINT_IP" ]; then
          ## Fetch the nodePort IP and replace in spinnaker.yaml
          #ENDPOINT_IP=$(kubectl get ep kubernetes -n default -o jsonpath="{.subsets[].addresses[].ip}")
          ENDPOINT_IP=$NODE_IP
          PORT=$(kubectl get svc spin-gate-np -o jsonpath="{.spec.ports[].nodePort}")
          $HAL_COMMAND config security api edit --no-validate --override-base-url http://$ENDPOINT_IP:$PORT
        else
          ## Run hal config edit command to override gate url
          $HAL_COMMAND config security api edit --no-validate --override-base-url http://$ENDPOINT_IP:$PORT
        fi
        ;;
      override-deck-url)
        ENDPOINT_IP=""
        PORT=9000

        export DAEMON_ENDPOINT=http://isd-spinnaker-halyard:8064
        export HAL_COMMAND="hal --daemon-endpoint $DAEMON_ENDPOINT"

        ## Wait for $EXTERNAL_IP_CHECK_DELAY till K8s assins a load Balancer IP to oes-gate
        check_for_loadBalancer spin-deck-np

        ## If external IP is not available
        if [ -z "$ENDPOINT_IP" ]; then
          ## Fetch the nodePort & nodeport and replace in app-config.js
          ENDPOINT_IP=$NODE_IP
          PORT=$(kubectl get svc spin-deck-np -o jsonpath="{.spec.ports[].nodePort}")
          $HAL_COMMAND config security ui edit --no-validate --override-base-url http://$ENDPOINT_IP:$PORT
        else
          ## Run hal config edit command to override deck url
          $HAL_COMMAND config security ui edit --no-validate --override-base-url http://$ENDPOINT_IP:$PORT
        fi
        ;;
      spin-gate-overrideurl-gitops)
        ## Configured ingress host url as override url
          echo "Substituting gate url"
          sed -i 's,PROTOCOL,http,g' /tmp/spinnaker/.hal/config
          sed -i 's,OVERRIDE_API_URL,oes-gate.example.ops.com,g' /tmp/spinnaker/.hal/config
        ;;
      spin-deck-overrideurl-gitops)
        ## Configured ingress host url as override url
          echo "Substituting deck url"
          sed -i 's,OVERRIDE_DECK_URL,spin.example.ops.com,g' /tmp/spinnaker/.hal/config
        ;;
      *)
        echo  COMP=$COMPONENT
        echo "Invalid input:$COMPONENT"
        ;;
    esac

kind: ConfigMap
metadata:
  name: isd-spinnaker-halyard-overrideurl
---
# Source: oes/charts/spinnaker/templates/configmap/secret-decoder.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: isd-spinnaker-spin-secret-decoder
  labels:
    app: "isd-spinnaker"
    heritage: "Helm"
    release: "isd"
    chart: "spinnaker-2.2.3"
data:
  run.sh: |-
    #!/bin/bash
    echo "##########Replacing Secret#########"
    grep -ir encrypted: /tmp/spinnaker/.hal | sort -t: -u -k1,1 |cut -d : -f1 > tmp.list
    while IFS= read -r file; do
    grep encrypted: $file > tmp1.list
    while read line ; do
    echo ${line#*encrypted:} ;
    done < tmp1.list > secret-strings.list
    while read secret ; do
    secretName=${secret%%:*}
    echo "---------$secretName---" 
    keyName=${secret#*:} 
    keyName=${keyName%%\"*}
    keyName=${keyName%% *}
    echo "----------$keyName--"
    #echo "secret Name= $secretName and key is = $keyName"
    #kubectl get secret -o jis
    #echo kubectl --kubeconfig /home/srini/ibm-cloud/staging/ibmstaging.config -n ninja-srini get secret $secretName -o json  jq -r ".data.$keyName"
    jqParam=".data.\"$keyName\""
    value=$(kubectl get secret $secretName -o json | jq -r $jqParam | base64 -d)
    value=$(echo $value | sed -e 's`[][\\/.*^$]`\\&`g')
    #echo "-----------$value---"
    #echo "secret Name= $secretName and key is = $keyName and value is $value"
    sed -i s/encrypted:$secretName:$keyName/$value/g $file
    done < secret-strings.list
    done < tmp.list
    
    echo "########### Replacing Kubeconfigs ############"
    grep encryptedFile /tmp/spinnaker/.hal/config > tmp.list
    while read line ; do
    echo ${line#*encryptedFile:} ;
    done < tmp.list  > secret-files.list
    
    while read secret ; do
    secretName=${secret%%:*} 
    keyName=${secret#*:} 
    keyName=${keyName%%\"*}
    keyName=${keyName%% *}
    echo "secret Name= $secretName and key is = $keyName"
    jqParam=".data.\"$keyName\""
    mkdir -p /tmp/spinnaker/kubeconfigdir
    kubectl get secret $secretName -o json | jq -r $jqParam | base64 -d > /tmp/spinnaker/kubeconfigdir/$keyName
    #echo "secret Name= $secretName and key is = $keyName and value is in $keyName"
    old_value="encryptedFile:$secretName:$keyName"
    new_value="/home/spinnaker/kubeconfigdir/$keyName"
    #echo $old_value
    #echo $new_value
    sed -i "s/${old_value}/$(echo $new_value | sed 's_/_\\/_g')/g" /tmp/spinnaker/.hal/config
    done < secret-files.list
    rm -rf secret-files.list secret-strings.list tmp.list
---
# Source: oes/charts/spinnaker/templates/configmap/service-settings.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: isd-spinnaker-service-settings
  labels:
    app: "isd-spinnaker"
    heritage: "Helm"
    release: "isd"
    chart: "spinnaker-2.2.3"

data:
  clouddriver-caching.yml: 'artifactId: quay.io/opsmxpublic/ubi8-spin-clouddriver:8.0.4-1'
  clouddriver-ro-deck.yml: 'artifactId: quay.io/opsmxpublic/ubi8-spin-clouddriver:8.0.4-1'
  clouddriver-ro.yml: 'artifactId: quay.io/opsmxpublic/ubi8-spin-clouddriver:8.0.4-1'
  clouddriver-rw.yml: 'artifactId: quay.io/opsmxpublic/ubi8-spin-clouddriver:8.0.4-1'
  clouddriver.yml: 'artifactId: quay.io/opsmxpublic/ubi8-spin-clouddriver:8.0.4-1'
  deck.yml: |-
    artifactId: quay.io/opsmxpublic/ubi8-oes-deck:3.5.1
    env:
      API_HOST: http://spin-gate:8084
  echo-scheduler.yml: 'artifactId: quay.io/opsmxpublic/ubi8-spin-echo:2.17.1'
  echo-worker.yml: 'artifactId: quay.io/opsmxpublic/ubi8-spin-echo:2.17.1'
  echo.yml: 'artifactId: quay.io/opsmxpublic/ubi8-spin-echo:2.17.1'
  fiat.yml: 'artifactId: quay.io/opsmxpublic/ubi8-spin-fiat:1.16.0'
  front50.yml: 'artifactId: quay.io/opsmxpublic/ubi8-oes-front50:0.27.1-opa'
  gate.yml: |-
    artifactId: quay.io/opsmxpublic/ubi8-oes-spin-gate:1.22.1
    healthEndpoint: /health
    kubernetes:
      useExecHealthCheck: false
  igor.yml: 'artifactId: quay.io/opsmxpublic/ubi8-spin-igor:1.16.0'
  kayenta.yml: 'artifactId: quay.io/opsmxpublic/ubi8-spin-kayenta:0.21.0'
  orca.yml: 'artifactId: quay.io/opsmxpublic/ubi8-oes-orca:2.20.4'
  redis.yml: |-
    overrideBaseUrl: redis://<EXTERNAL-REDIS-HOST-NAME>:6379
    skipLifeCycleManagement: true
  rosco.yml: 'artifactId: quay.io/opsmxpublic/ubi8-spin-rosco:0.25.0'
---
# Source: oes/charts/spinnaker/templates/configmap/spin-pipeline-import.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: isd-spinnaker-spin-pipeline-import
  labels:
    app: "isd-spinnaker"
    heritage: "Helm"
    release: "isd"
    chart: "spinnaker-2.2.3"
data:
  spin-pipeline-import.sh: |-
    #!/bin/bash
    echo \"Waiting for all Spinnaker Services to come-up\"
    wait_period=0
    while true
    do
    kubectl get po -n opsmx-isd -o jsonpath='{range .items[*]}{..metadata.name}{"\t"}{..containerStatuses..ready}{"\n"}{end}' > /tmp/inst.status
    CLOUDRO=$(grep spin-clouddriver-ro /tmp/inst.status |grep -v deck | awk '{print $2}')
    CLOUDRODECK=$(grep spin-clouddriver-ro-deck /tmp/inst.status | awk '{print $2}')
    CLOUDRW=$(grep spin-clouddriver-rw /tmp/inst.status | awk '{print $2}')
    CLOUDCACHING=$(grep spin-clouddriver-caching /tmp/inst.status | awk '{print $2}')
    DECK=$(grep spin-deck /tmp/inst.status | awk '{print $2}')
    ECHOWORKER=$(grep spin-echo-worker /tmp/inst.status | awk '{print $2}')
    ECHOSCHEDULER=$(grep spin-echo-scheduler  /tmp/inst.status | awk '{print $2}')
    FRONT=$(grep spin-front /tmp/inst.status  | awk '{print $2}')
    GATE=$(grep spin-gate /tmp/inst.status | awk '{print $2}')
    FIAT=$(grep spin-fiat /tmp/inst.status | awk '{print $2}')
    ORCA=$(grep spin-orca /tmp/inst.status | awk '{print $2}')
    SAPORGATE=$(grep sapor-gate /tmp/inst.status | awk '{print $2}')
    OESGATE=$(grep oes-gate /tmp/inst.status | awk '{print $2}')

    wait_period=$(($wait_period+10))
    if [ "$DECK" == "true" ] && [ "$CLOUDCACHING" == "true" ] && [ "$CLOUDRO" == "true" ] && [ "$CLOUDRW" == "true" ] && [ "$CLOUDRODECK" == "true" ] && [ "$FRONT" == "true" ] && [ "$GATE" == "true" ] && [ "$ORCA" == "true" ] && [ "$ECHOWORKER" == "true" ] && [ "$ECHOSCHEDULER" == "true" ] && [ "$SAPORGATE" == "true" ] && [ "$OESGATE" == "true" ];
    then
        echo \"Spinnaker and OES is Installed and ready\"
        mkdir -p /tmp/config/git/
        git -c http.sslVerify=false clone https://github.com/OpsMx/sample-pipelines.git /tmp/config/git/
        cd /tmp/config/git
        cp -p /tmp/config/spin/config .
        sed 's/$/ --config config/' create-app.sh >create-app1.sh
        bash -xe create-app1.sh
        break
    else
        if [ $wait_period -gt 1800 ];
        then
            echo \"Script is timed out as the Spinnaker is not ready in 30 min.......\"
            break
        else
            echo \"Waiting for Spinnaker services to be ready\"
            sleep 1m
        fi
    fi
    done
---
# Source: oes/templates/clouddriver-sidecar/k8sconfig-sync.yaml
apiVersion: v1
data:
  k8config-sync.sh: |
    #!/bin/bash
    export GIT_CLONE_PARAM=$(cat /tmp/secret/gitcloneparam)
    export GIT_URL=$(cat /tmp/secret/dynamicaccountsgituri)
    export DYNAMIC_ACCOUNTS_REPO=$(cat /tmp/secret/dynamicAccRepository)
    rm -rf $DYNAMIC_ACCOUNTS_REPO
    mkdir -p /opsmx
    echo " ####### Cloning the Dynamic Account Repo #################"
    git clone -c http.sslVerify=false $GIT_CLONE_PARAM
    #cd $DYNAMIC_ACCOUNTS_REPO/
    cat $DYNAMIC_ACCOUNTS_REPO///clouddriver-local.yml |grep -i opsmx |awk '{print $2}' |tr -d '"' | awk 'BEGIN{FS="/opsmx/"}{print $2}' > /opsmx/config_files.txt
    for config in $(cat /opsmx/config_files.txt)
    do
    kubectl get secrets $config -o=jsonpath='{.data.*}'|base64 -d > /opsmx/$config
    done
kind: ConfigMap
metadata:
  name: k8config-sync
---
# Source: oes/templates/configmaps/datasource-creation.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: isd-oes-datasource-creation
  labels:
    heritage: "Helm"
    release: "isd"
    chart: "oes-3.12.2"
data:
  datasource-api.sh: |-
    #!/bin/bash
    set -x
    echo \"Waiting for all Spinnaker and OES Services to come-up\"
    wait_period=0
    while true
    do
    kubectl get po -n opsmx-isd -o jsonpath='{range .items[*]}{..metadata.name}{"\t"}{..containerStatuses..ready}{"\n"}{end}' > /tmp/inst.status
    CLOUDRO=$(grep spin-clouddriver-ro /tmp/inst.status |grep -v deck | awk '{print $2}')
    CLOUDRODECK=$(grep spin-clouddriver-ro-deck /tmp/inst.status | awk '{print $2}')
    CLOUDRW=$(grep spin-clouddriver-rw /tmp/inst.status | awk '{print $2}')
    CLOUDCACHING=$(grep spin-clouddriver-caching /tmp/inst.status | awk '{print $2}')
    DECK=$(grep spin-deck /tmp/inst.status | awk '{print $2}')
    ECHOWORKER=$(grep spin-echo-worker /tmp/inst.status | awk '{print $2}')
    ECHOSCHEDULER=$(grep spin-echo-scheduler  /tmp/inst.status | awk '{print $2}')
    FRONT=$(grep spin-front /tmp/inst.status  | awk '{print $2}')
    #GATE=$(grep spin-gate /tmp/inst.status | awk '{print $2}')
    #IGOR=$(grep spin-igor /tmp/inst.status | awk '{print $2}')
    ORCA=$(grep spin-orca /tmp/inst.status | awk '{print $2}')
    #ROSCO=$(grep spin-rosco /tmp/inst.status | awk '{print $2}')
    SAPOR=$(grep oes-sapor /tmp/inst.status | awk '{print $2}')
    PLATFORM=$(grep oes-platform /tmp/inst.status | awk '{print $2}')
    AUTOPILOT=$(grep oes-autopilot /tmp/inst.status | awk '{print $2}')


    wait_period=$(($wait_period+10))

    if [ "$DECK" == "true" ] && [ "$CLOUDCACHING" == "true" ] && [ "$CLOUDRO" == "true" ] && [ "$CLOUDRW" == "true" ] && [ "$CLOUDRODECK" == "true" ] && [ "$FRONT" == "true" ] && [ "$ORCA" == "true" ]  && [ "$ECHOWORKER" == "true" ] && [ "$ECHOSCHEDULER" == "true" ] && [ "$SAPOR" == "true" ] && [ "$PLATFORM" == "true" ] && [ "$AUTOPILOT" == "true" ];
        then
            echo \"Spinnaker and OES services are Up and Ready..\"
            sleep 5
            curl --header "Content-Type: application/json"  --header "x-spinnaker-user: admin" --request POST  --data '{"datasourceType": "OPA", "name": "OPA", "configurationFields": {"endPoint": "opa:8181"}}'   http://oes-platform:8095/platformservice/v2/datasources
            curl --header "Content-Type: application/json"  --header "x-spinnaker-user: admin" --request POST  --data '{"datasourceType": "AUTOPILOT", "name": "Autopilot", "configurationFields": {"username": "admin"} }'   http://oes-platform:8095/platformservice/v2/datasources
            #curl --header "Content-Type: application/json"  --header "x-spinnaker-user: admin" --request POST  --data '{"datasourceType": "ELASTICSEARCH", "name": "elastic-default", "configurationFields": {"endPoint": "https://newoeselastic.opsmx.com", "username": "opsmxuser", "password": "OpsMx@123", "kibanaEndPoint": "https://newoeskibana.opsmx.com", "kibanaPassword": "OpsMx@123", "kibanaUsername": "opsmxuser" }}'   http://oes-platform:8095/platformservice/v2/datasources
            #curl --header "Content-Type: application/json"  --header "x-spinnaker-user: admin" --request POST  --data '{"datasourceType": "PROMETHEUS", "name": "prometheus-default", "configurationFields": {"endPoint": "http://prometheus:9090"} }'   http://oes-platform:8095/platformservice/v2/datasources

            STORAGE_TYPE=gitea
            GITEA_USERNAME=opsmx
            GITEA_PASSWORD=opsmxadmin123
            USERNAME=admin
            PASSWORD=saporadmin
            response=$(curl -s http://oes-sapor:8085/oes/accountsConfig/v3/spinnaker)
            name=$(echo $response | jq '.[].name')
            if [ -z "$name" ];
            then
              if [[ "$STORAGE_TYPE"  ==  "gitea" ]];
              then

              curl -X POST -H "Content-Type: application/json"  -k -d '{"name":"'"$GITEA_USERNAME"'"}' -u $GITEA_USERNAME:$GITEA_PASSWORD http://isd-gitea-http.opsmx-isd:3000/api/v1/users/$GITEA_USERNAME/tokens >token.json
              TOKEN=$(cat token.json | jq '.sha1' -r)

              response=$(curl --header "Content-Type: application/json"  --header "x-spinnaker-user: admin" --request POST http://oes-platform:8095/platformservice/v6/datasource --data '{"datasourceType": "GITHUB", "name": "gitops", "spinEnabled": "false", "configurationFields": {"token": "'$TOKEN'", "username": "", "hostUrl": "http://isd-gitea-http:3000", "url": "http://isd-gitea-http:3000/api/v1/users/opsmx" } }')
              
              id=$(echo $response | jq '.id')
              curl --header "Content-Type: application/json"  --header "x-spinnaker-user: admin" --request POST http://oes-sapor:8085/oes/accountsConfig/v4/spinnaker --data '{"name":"preview-saas","url":"http://sapor-gate:8084","authenticationType":"LDAP","externalAccountFlag":true,"pipelinePromotionFlag":false,"syncAccountFlag":false,"externalAccountConfiguration":{"accountId": "'"${id}"'","accountName":"gitops","provider":"GITHUB","config":{"bucketName":"","region":"","endPoint":"http://isd-gitea-http:3000/'$GITEA_USERNAME'/gitea-standard-repo.git","sourcePath":""}},"pipelinePromotionConfiguration":null,"password":"'"${PASSWORD}"'","userName":"'"${USERNAME}"'"}'
                 break
              fi
            fi

            STORAGE_TYPE=git
            USERNAME=admin
            PASSWORD=saporadmin
            TOKEN=$(echo -n "$USERNAME":"$PASSWORD" | base64)
            response=$(curl -s http://oes-sapor:8085/oes/accountsConfig/v3/spinnaker)
            name=$(echo $response | jq '.[].name')
            if [ -z "$name" ];
            then
              if [[ "$STORAGE_TYPE"  ==  "git" ]];
              then
              response=$(curl --header "Content-Type: application/json"  --header "x-spinnaker-user: admin" --request POST http://oes-platform:8095/platformservice/v6/datasource --data '{"datasourceType": "GITHUB", "name": "gitops", "spinEnabled": "false", "configurationFields": {"token": "git/stash_token", "username": "git/stash_username", "hostUrl": "https://github.com/", "url": "https://api.github.com" } }')
              id=$(echo $response | jq '.id')
              curl --header "Content-Type: application/json"  --header "x-spinnaker-user: admin" --request POST http://oes-sapor:8085/oes/accountsConfig/v4/spinnaker --data '{"name":"preview-saas","url":"http://sapor-gate:8084","authenticationType":"LDAP","externalAccountFlag":true,"pipelinePromotionFlag":false,"syncAccountFlag":false,"externalAccountConfiguration":{"accountId": "'"${id}"'","accountName":"gitops","provider":"GITHUB","config":{"bucketName":"","region":"","endPoint":"https://github.com/OpsMx/standard-gitops-repo.git","sourcePath":""}},"pipelinePromotionConfiguration":null,"password":"'"${PASSWORD}"'","userName":"'"${USERNAME}"'"}'
              #curl --header "Content-Type: application/json"  --header "x-spinnaker-user: admin" --request POST http://oes-sapor:8085/oes/accountsConfig/v3/spinnaker --data '{"name": "preview-saas", "url": "https://oes-gate.example.ops.com", "authenticationType": "LDAP", "token": "'"${TOKEN}"'", "externalAccountFlag": "true","pipelinePromotionFlag": "false","syncAccountFlag": "false", "externalAccountConfiguration": {"accountId": "'"${id}"'","accountName": "gitops", "provider": "GITHUB", "config": {"bucketName": "", "region": "","endPoint": "https://github.com/OpsMx/standard-gitops-repo.git", "sourcePath": "" }}}'
                  break
              fi
              if [[ "$STORAGE_TYPE"  ==  "stash" ]];
              then
                if [[ "" ]]
                then
                  response=$(curl --header "Content-Type: application/json"  --header "x-spinnaker-user: admin" --request POST http://oes-platform:8095/platformservice/v2/datasources --data '{"datasourceType": "BITBUCKET", "name": "gitops-bitbucket", "spinEnabled": "false", "configurationFields": {"authType":"bearer","username": "git/stash_username","token": "git/stash_token","read":"","write":"",  "hostUrl": "https://github.com/OpsMx//standard-gitops-repo.git", "url": "https://api.bitbucket.org/2.0/" } }')
                  id=$(echo $response | jq '.id')
                   curl --header "Content-Type: application/json"  --header "x-spinnaker-user: admin" --request POST http://oes-sapor:8085/oes/accountsConfig/v3/spinnaker --data '{"name": "preview-saas", "url": "http://sapor-gate:8084", "authenticationType": "LDAP", "token": "'"${TOKEN}"'", "externalAccountFlag": "true", "pipelinePromotionFlag": "false","syncAccountFlag": "false", externalAccountConfiguration": {"accountId": "'"${id}"'","accountName": "gitops-bitbucket", "provider": "BITBUCKET", "config": {"bucketName": "", "region": "","endPoint": "https://github.com/OpsMx//standard-gitops-repo.git", "sourcePath": " " }}}'

                  break
                else
                  response=$(curl --header "Content-Type: application/json"  --header "x-spinnaker-user: admin" --request POST http://oes-platform:8095/platformservice/v2/datasources --data '{"datasourceType": "BITBUCKET", "name": "gitops-bitbucket", "spinEnabled": "false", "configurationFields": {"authType":"bearer","username": "git/stash_username","token": "git/stash_token","read":"","write":"", "hostUrl": "https://github.com/OpsMx//standard-gitops-repo.git", "url": "https://api.bitbucket.org/2.0/" } }')
                  id=$(echo $response | jq '.id')
                  curl --header "Content-Type: application/json"  --header "x-spinnaker-user: admin" --request POST http://oes-sapor:8085/oes/accountsConfig/v3/spinnaker --data '{"name": "preview-saas", "url": "http://sapor-gate:8084", "authenticationType": "LDAP", "token": "'"${TOKEN}"'", "externalAccountFlag": "true", "pipelinePromotionFlag":"false","syncAccountFlag":"false", externalAccountConfiguration": {"accountId": "'"${id}"'","accountName": "gitops-bitbucket", "provider": "BITBUCKET", "config": {"bucketName": "", "region": "","endPoint": "https://github.com/OpsMx//standard-gitops-repo.git", "sourcePath": "" }}}'
                  break
                fi
              fi
              if [[ "$STORAGE_TYPE"  ==  "s3" ]];
              then
                 curl --header "Content-Type: application/json"  --header "x-spinnaker-user: admin" --request POST http://oes-platform:8095/platformservice/v2/datasources --data '{"datasourceType":"AMAZONS3","name":"gitops-s3","configurationFields":{"access_id":"AWS_ACCESS_KEY_ID","secret_key":"AWS_SECRET_ACCESS_KEY"},"spinnakerNames":[""],"spinEnabled": "false"} }'
                 curl --header "Content-Type: application/json"  --header "x-spinnaker-user: admin" --request POST http://oes-sapor:8085/oes/accountsConfig/v3/spinnaker --data '{"name": "preview-saas", "url": "http://sapor-gate:8084", "authenticationType": "LDAP", "token": "'"${TOKEN}"'" , "externalAccountFlag": "true", "pipelinePromotionFlag":"false", "syncAccountFlag":"false", externalAccountConfiguration": {"accountName": "gitops-s3","config":{"bucketName":"bucket name.e.g-testbucket","region":"regionofbucket","endPoint":""},"provider": "AMAZONS3"}}'
              fi
            else
              echo "Spinnaker is already Integrated"
              break
            fi
        

    else
        if [ $wait_period -gt 2000 ];
        then
            echo \"Script is timed out as the Spinnaker is not ready yet.......\"
            break
        else
            echo \"Waiting for Spinnaker services to be ready\"
            sleep 1m
        fi
    fi
    done
---
# Source: oes/templates/configmaps/oes-dashboard-configmap.yaml
apiVersion: v1
data:
  dashboard-local.yml: |
    opsmx:
      dashboard:
        installation:
          mode: OES-AP
    standardErrorCodes:
      filePath: /opsmx/conf/standard-error-code.csv
    platformservice.url: http://oes-platform:8095
    autopilot.url: http://oes-autopilot:8090
    oes.sapor.url: http://oes-sapor:8085
    visibilityservice.url: http://oes-visibility:8096
    auditclientservice:
      url: "http://oes-audit-client:8098"
    gateservice:
      url: "http://oes-gate:8084"
    app:
      sync:
        enabled: true
    spinnakerLink: /deck/
    
kind: ConfigMap
metadata:
  name: oes-dashboard-config
  labels:
    app: oes
    component: dashboard
    heritage: "Helm"
    release: "isd"
    chart: "oes-3.12.2"
---
# Source: oes/templates/configmaps/oes-ui-configmap.yaml
apiVersion: v1
data:
  app-config.json: |
    {
        "endPointUrl": "/gate/",
        "setApplicationInterval": 300000,
        "triggerPipeline": false
    }
  help-text.json: "{\n   \"POLICY_LISTING\": {\n      \"HEADER\": \"Policies not found!\",\n
    \     \"BODY\": \"<div >The Policy Management feature allows you to create policies
    to set stringent guidelines for safe and fine grained controls in a CI/CD pipeline.
    This feature gives you to set guard rails by declaring specific policy rules or
    guidelines. For e.g., <strong>Automated Testing should be completed before deployment</strong>
    \ is a rule which must be met when creating a CI/CD pipeline.</div> <br>  <div  >
    \ Static Policy lets users validate the conditions while creating the pipelines,
    whereas Runtime Policy enables users for automated decision making during pipeline
    execution.</div><br> <div > A policy defines a set of conditions that needs to be
    checked. As an example, a policy could be created to define a blackout window period
    (or a moratorium period) for performing production deployments. A moratorium period
    defines the time period within which no production deployments should be performed.
    Any deployment to the production environment during this period will automatically
    be rejected/stopped, if that deployment is triggered during the moratorium period.</div><br><div
    \ > Autopilot uses Open Policy Engine(OPA) for policy definition & execution. OPA
    is a open source, general-purpose policy engine that unifies policy enforcement
    across the stack. It uses a high-level declarative language called Rego that lets
    you specify policy as code and simple APIs to offload policy decision-making from
    your software.</div><br><div  > Click on <strong>New Policy</strong> button to create
    a new policy.</div>\"\n   },\n   \"AGENT_LISTING\": {\n      \"HEADER\": \"No Agents
    found!\",\n      \"BODY\": \"<div><p>The Agent allows Spinnaker installations to
    reach through firewalls in a secure manner,allowing access to private Kubernetes
    clusters as well as reach internal services such as Jenkins and Artifactory. The
    agent is typically used with OpsMx's SaaS Spinnaker offering, where OpsMx hosts
    the Spinnaker installation, but services used by Spinnaker are within a secure area
    owned by the customer.One of the core advantages of using an agent is that the credentials
    do not need to be provided to anyone i.e.credentials remain with - in the cluster
    where deployment is done. </p><p> The Agent is a two part system: a <b> Controller
    </b> runs near Spinnaker, and the <b>Agent</b> runs in the target secure cluster.The
    Agent is configured to communicate with specific services(Kubernetes, Jenkins etc)
    within a customer 's security domain, while the Controller is in Spinnaker's domain.
    </p> <p> The Agent is deployed with a manifest provided by OpsMx.This manifest has
    per - installation credentials to authenticate to the controller,controller address
    etc.Services are configured in the Agent by the customer.URL endpoints.Spinnaker
    account names and credentials are specified to the agent configuration using a service
    configuration.The credentials never leave the agent. </p><p> <b> New Agent </b>
    button is enabled when Spinnaker is configured in <b>Setup->Spinnaker</b>. Click
    on <b> New Agent </b> to create the Agent for your environment.</p></div>\"\n   },\n
    \  \"AGENT_CREATION\": {\n      \"HEADER\": \"Agent\",\n      \"BODY\": \"<p>Adding
    an agent involves the following steps:</p><ul class='helpTextUI'><li>Enter the details
    (Agent Name, Cluster Name and Description) and click save</li> <li>Click <b>Download
    Manifest</b> which appears after save</li> <li>In the remote Kubernetes cluster,
    create service configmap in the default namespace. <span>Examples are available
    <a href='https://github.com/OpsMx/standard-gitops-repo/tree/master/SAMPLES/agent-config'
    target='_blank'>here</a></span> </li> <li>Apply the downloaded manifest in the default
    namespace using <code>kubectl apply -f &lt;downloaded file&gt; </code> <span>Note
    that the agent should be able to reach the LB configured with agent-grpc service</span>
    </li> <li>Check the Setup->Agent screen for the agent connection status</li>  </ul>\",\n
    \     \"AGENT_NAME\": {\n         \"TOOLTIP\": \"Name of the agent with which it
    will referred to\",\n         \"VALIDATION_MESSAGE\": {\n            \"required\":
    \"Agent Name cannot be empty\",\n            \"cannotContainSpace\": \"Agent Name
    cannot contain space\",\n            \"noSpecialCharacters\": \"Allowed special
    character is '-'\",\n            \"startingFromNumber\": \"Agent Name should not
    start with number\",\n            \"agentNameExist\": \"Agent Name already exists\"\n
    \        }\n      },\n    \"BODY\": \"<p>The Agent allows Spinnaker installations
    to reach through firewalls in a secure manner,allowing access to private Kubernetes
    clusters as well as reach internal services such as Jenkins and Artifactory.</p>
    <p>Adding an agent involves the following steps:</p><ul class='helpTextUI'><li>Enter
    the details (Agent Name, Cluster Name and Description) and click save</li> <li>Click
    <b>Download Manifest</b> which appears after save</li> <li>In the remote Kubernetes
    cluster, create service configmap in the default namespace. <span>Examples are available
    <a href='https://github.com/OpsMx/standard-gitops-repo/tree/master/SAMPLES/agent-config'
    target='_blank'>here</a></span> </li> <li>Apply the downloaded manifest in the default
    namespace using <code>kubectl apply -f &lt;downloaded file&gt; </code> <span>Note
    that the agent should be able to reach the LB configured with agent-grpc service</span>
    </li> <li>Check the Setup->Agent screen for the agent connection status</li>  </ul>\",\n
    \   \"CLUSTER_NAME\": {\n         \"TOOLTIP\": \"Name of the remote cluster on which
    agent will be installed on\",\n         \"VALIDATION_MESSAGE\": {\n            \"required\":
    \"Cluster Name cannot be empty\",\n            \"cannotContainSpace\": \"Cluster
    Name cannot contain space\",\n            \"noSpecialCharacters\": \"Allowed special
    character is '-'\",\n            \"startingFromNumber\": \"Cluster Name should not
    start with number\"\n         }\n      },\n      \"DESCRIPTION\": {\n         \"TOOLTIP\":
    \"Short description about the agent\",\n         \"VALIDATION_MESSAGE\": {}\n      },\n
    \     \"CONNECT_TO_SPINNAKER\": {\n         \"TOOLTIP\": \"Select the spinnaker
    instance you want to associate this account to\",\n         \"VALIDATION_MESSAGE\":
    {\n            \"required\": \"Please select Spinnaker\"\n         }\n      }\n
    \  },\n   \"CLOUDPROVIDER_LISTING\": {\n      \"HEADER\": \"No Cloud Providers found!\",\n
    \     \"BODY\": \"<div><p>Providers are integrations to Cloud platforms you deploy
    your applications to.</p> <p>In this section, you’ll register credentials for your
    Cloud platforms. Those credentials are known as Accounts. Autopilot allows you to
    \ create & manage Accounts for different Spinnaker Cloud Providers such as AWS,
    GCP, Kubernetes, etc.</p><p>When Spinnaker is configured for <b>Direct Sync</b>,
    <b>New Accounts</b> button will not be visible.</p><p><b>New Accounts</b> button
    will be enabled when Spinnaker is configured to use External Accounts in <b>Setup->Spinnaker</b>.
    Click on <b>New Accounts</b> button to create an account for your cloud provider.
    \ You can create multiple accounts for the same provider.</p><p>Click on <b>Sync
    Spinnaker Accounts</b> button to sync Cloud Provider accounts with Spinnaker. </p></div>\"\n
    \  },\n   \"CLOUDPROVIDER_CREATION\": {\n      \"HEADER\": \"Cloud Provider\",\n
    \     \"BODY\": \"<p>In this page, you can  create & manage Accounts for different
    Spinnaker Cloud Providers.</p>\",\n      \"AGENT_NAME\": {\n         \"TOOLTIP\":
    \"\",\n         \"VALIDATION_MESSAGE\": {\n            \"required\": \"Agent name
    cannot be empty\",\n            \"cannotContainSpace\": \"Agent name cannot contain
    space\",\n            \"noSpecialCharacters\": \"Allowed special character are ',-'\"\n
    \        }\n      },\n      \"CLOUD_PROVIDER\": {\n         \"TOOLTIP\": \"The cloud
    provider type for which you want to add the account\",\n         \"VALIDATION_MESSAGE\":
    {\n            \"required\": \"Please select Cloud Provider\"\n         }\n      },\n
    \     \"SPINNAKER\": {\n         \"TOOLTIP\": \"The Spinnaker instance with which
    this account would be tied to\",\n         \"VALIDATION_MESSAGE\": {\n            \"required\":
    \"Please select Spinnaker\"\n         }\n      },\n      \"ENVIRONMENT\": {\n         \"TOOLTIP\":
    \"The environment name for the account. Many accounts can share the same environment
    (e.g. dev, test, prod)\",\n         \"VALIDATION_MESSAGE\": {\n            \"required\":
    \"Please select Environment\"\n         }\n      },\n      \"ACCOUNT_NAME\": {\n
    \        \"TOOLTIP\": \"Name of the account to operate on\",\n         \"VALIDATION_MESSAGE\":
    {\n            \"required\": \"Account name cannot be empty\",\n            \"cannotContainSpace\":
    \"Account name cannot contain space\",\n            \"noSpecialCharacters\": \"Allowed
    special character is '-'\"\n         }\n      },\n      \"NAMESPACE\": {\n         \"TOOLTIP\":
    \"A list of namespaces this Spinnaker account can deploy to and will cache (namespaces
    should be 'coma' separated ex: default,dev\",\n         \"VALIDATION_MESSAGE\":
    {\n            \"required\": \"Namespace cannot be empty\",\n            \"cannotContainSpace\":
    \"Namespace cannot contain space\",\n            \"noSpecialCharacters\": \"Special
    characters not allowed except ',-'\"\n         }\n      },\n      \"UPLOAD_KUBECONFIG_FILE\":
    {\n         \"TOOLTIP\": \"The path to your kubeconfig file. By default, it will
    be under the Spinnaker user’s home directory in the typical .kube/config location.\",\n
    \        \"VALIDATION_MESSAGE\": {\n            \"required\": \"File cannot be empty\"\n
    \        }\n      },\n      \"READ\": {\n         \"TOOLTIP\": \"A user must have
    at least one of these roles in order to view this account’s cloud resources.\",\n
    \        \"VALIDATION_MESSAGE\": {\n            \"cannotContainSpace\": \"Read Permissions
    cannot contain space\"\n         }\n      },\n      \"WRITE\": {\n         \"TOOLTIP\":
    \"A user must have at least one of these roles in order to make changes to this
    account’s cloud resources\",\n         \"VALIDATION_MESSAGE\": {\n            \"cannotContainSpace\":
    \"Write Permissions cannot contain space\"\n         }\n      },\n      \"EXECUTE\":
    {\n         \"TOOLTIP\": \"\",\n         \"VALIDATION_MESSAGE\": {\n            \"cannotContainSpace\":
    \"Execute Permissions cannot contain space\"\n         }\n      },\n      \"ACCOUNT_ID\":
    {\n         \"TOOLTIP\": \"Your AWS account ID to manage. Refer http://docs.aws.amazon.com/IAM/latest/UserGuide/console_account-alias.html
    for more information\",\n         \"VALIDATION_MESSAGE\": {\n            \"required\":
    \"Account Id cannot be empty\",\n            \"cannotContainSpace\": \"Account Id
    cannot contain space\"\n         }\n      },\n      \"ROLE\": {\n         \"TOOLTIP\":
    \"If set, Halyard will configure a credentials provider that uses AWS Security Token
    Service to assume the specified role\",\n         \"VALIDATION_MESSAGE\": {\n            \"required\":
    \"Role cannot be empty\",\n            \"cannotContainSpace\": \"Role cannot contain
    space\"\n         }\n      },\n      \"REGIONS\": {\n         \"TOOLTIP\": \"The
    AWS regions this Spinnaker account will manage\",\n         \"VALIDATION_MESSAGE\":
    {\n            \"required\": \"Region cannot be empty\",\n            \"cannotContainSpace\":
    \"Region cannot contain space\"\n         }\n      },\n      \"PRIMARY_ACCOUNT\":
    {\n         \"TOOLTIP\": \"Whether this account is the primary account? If yes then
    provide the access & secret key details.\",\n         \"VALIDATION_MESSAGE\": {}\n
    \     },\n      \"ACCESS_KEY\": {\n         \"TOOLTIP\": \"The default access key
    used to communicate with AWS\",\n         \"VALIDATION_MESSAGE\": {\n            \"required\":
    \"Access key cannot be empty\"\n         }\n      },\n      \"ACCESS_KEY_BAKERY\":
    {\n         \"TOOLTIP\": \"The default access key used for AWS bakery configuration\",\n
    \        \"VALIDATION_MESSAGE\": {\n            \"required\": \"Access Key (Bakery)
    cannot be empty\"\n         }\n      },\n      \"SECRET_KEY\": {\n         \"TOOLTIP\":
    \"The secret key used to communicate with AWS\",\n         \"VALIDATION_MESSAGE\":
    {\n            \"required\": \"Secret key cannot be empty\"\n         }\n      },\n
    \     \"SECRET_KEY_BAKERY\": {\n         \"TOOLTIP\": \"The default secret key used
    for AWS baskery configuration\",\n         \"VALIDATION_MESSAGE\": {\n            \"required\":
    \"Secret Key (Bakery) cannot be empty\"\n         }\n      },\n      \"APP_KEY\":
    {\n         \"TOOLTIP\": \"The appKey (password) of your service principal\",\n
    \        \"VALIDATION_MESSAGE\": {\n            \"required\": \"App key cannot be
    empty\",\n            \"cannotContainSpace\": \"App key cannot contain space\"\n
    \        }\n      },\n      \"CLIENT_ID\": {\n         \"TOOLTIP\": \"The clientId
    (also called appId) of your service principal\",\n         \"VALIDATION_MESSAGE\":
    {\n            \"required\": \"Client Id cannot be empty\",\n            \"cannotContainSpace\":
    \"Client Id cannot contain space\"\n         }\n      },\n      \"DEFAULT_KEYVALUT\":
    {\n         \"TOOLTIP\": \"The name of a KeyVault that contains the user name, password,
    and ssh public key used to create VMs\",\n         \"VALIDATION_MESSAGE\": {\n            \"required\":
    \"Default Keyvault cannot be empty\",\n            \"cannotContainSpace\": \"Default
    Keyvault cannot contain space\"\n         }\n      },\n      \"SUBSCRIPTION_ID\":
    {\n         \"TOOLTIP\": \"The subscriptionId that your service principal is assigned
    to\",\n         \"VALIDATION_MESSAGE\": {\n            \"required\": \"Subscription
    Id cannot be empty\",\n            \"cannotContainSpace\": \"Subscription Id cannot
    contain space\"\n         }\n      },\n      \"TENANT_ID\": {\n         \"TOOLTIP\":
    \"The tenantId that your service principal is assigned to\",\n         \"VALIDATION_MESSAGE\":
    {\n            \"required\": \"Tenant Id cannot be empty\",\n            \"cannotContainSpace\":
    \"Tenant Id cannot contain space\"\n         }\n      },\n      \"GCP_FILE\": {\n
    \        \"TOOLTIP\": \"The path to a JSON service account that Spinnaker will use
    as credentials. This is only needed if Spinnaker is not deployed on a Google Compute
    Engine VM, or needs permissions not afforded to the VM it is running on. Refer https://cloud.google.com/compute/docs/access/service-accounts
    for more information\",\n         \"VALIDATION_MESSAGE\": {\n            \"required\":
    \"File cannot be empty\"\n         }\n      },\n      \"AWS_ACCOUNT_NAME\": {\n
    \        \"TOOLTIP\": \"\",\n         \"VALIDATION_MESSAGE\": {\n            \"required\":
    \"Please Select AWS Account\"\n         }\n      }\n   },\n   \"SPINNAKER_LISTING\":
    {\n      \"HEADER\": \"No Spinnaker Configured!\",\n      \"BODY\": \"<div><p>The
    Spinnaker Setup tab allows you to setup a Spinnaker instance with which you can
    connect Autopilot and sync all the applications from Spinnaker. </p><p>GitOps style
    Spinnaker is suported where in all configuration is maintained in a repository such
    as git.  These optional sections help configure gitOps style Spinnaker:</p> <p><b>Source
    Control for Accounts:</b>  In this section, you can specify the repository for External
    configuration in Spinnaker</p> <p><b>Source Control for Pipeline:</b>In this section,
    you can specify the repository for pipeline gitOps in Spinnaker that allows you
    to save and restore pipelines from a git repository.</p> <p>Click on the <b>Add
    Spinnaker</b> button to add Spinnaker instance</p></div>\"\n   },\n   \"SPINNAKER_SETUP\":
    {\n      \"HEADER\": \"Spinnaker\",\n      \"BODY\": \"<p>In this page you can add
    / update your Spinnaker instance.</p> <p><strong>Fields:</strong></p> <ul class='helpTextUI'>
    <li><strong>Spinnaker Name</strong>: User defined name for Spinnaker instance.<br>
    <span> Example: opsmx-spinnaker</span></li> <li><strong>Spinnaker Gate URL</strong>:
    Gate URL of the Spinnaker instance.<br> <span>Example: https://spinnaker-gate.xyz.com
    or http://oes-gate:8084</span></li> <li><strong>Authentication Type:</strong>: Can
    be LDAP or X509</li> <li><strong>Token: </strong>This is used when Authentication
    Type is LDAP; username & password to LDAP server separated by ':' in base64 format;
    Output of 'echo -ne 'username:password' | base64 -w0'</li>  <li><strong>Password:
    </strong>This is used when Authentication Type is LDAP; Password for P12 File</li>
    <li><strong>P12 File:</strong> This is used when Authentication Type is X509; P12
    File needed for X509/AD Authentication</li> <li><strong>Source Control for Accounts:
    </strong>In this section, you can specify the repository for External configuration
    in Spinnaker</li> <li><strong>Source Control for Pipeline: </strong>In this section,
    you can specify the repository for pipeline gitOps in Spinnaker that allows you
    to save and restore pipelines from a git repository</li> </ul>\",\n      \"SPINNAKER_NAME\":
    {\n         \"TOOLTIP\": \"Name of the Spinnaker instance\",\n         \"VALIDATION_MESSAGE\":
    {\n            \"required\": \"Spinnaker Name cannot be empty\",\n            \"cannotContainSpace\":
    \"Spinnaker Name cannot contain space\",\n            \"noSpecialCharacters\": \"Allowed
    special character is '-'\",\n            \"startingFromNumber\": \"Spinnaker Name
    should not start with number\"\n         }\n      },\n      \"SPINNAKER_GATE_URL\":
    {\n         \"TOOLTIP\": \"Gate Url of the Spinnaker instance\",\n         \"VALIDATION_MESSAGE\":
    {\n            \"required\": \"Spinnaker Gate URL cannot be empty\",\n            \"cannotContainSpace\":
    \"Spinnaker Gate URL cannot contain space\",\n            \"invalidUrl\": \"Spinnaker
    Gate URL is invalid\"\n         }\n      },\n      \"AUTHENTICATION_TYPE\": {\n
    \        \"TOOLTIP\": \"Select the type of authentication for the spinnaker being
    added\",\n         \"VALIDATION_MESSAGE\": {\n            \"required\": \"Please
    select Authentication Type\"\n         }\n      },\n      \"TOKEN\": {\n         \"TOOLTIP\":
    \"Token for Spinnaker authentication\",\n         \"VALIDATION_MESSAGE\": {\n            \"required\":
    \"Token cannot be empty\",\n            \"minlength\": \"Token should be more than
    8 characters\"\n         }\n      },\n      \"PASSWORD\": {\n         \"TOOLTIP\":
    \"Password\",\n         \"VALIDATION_MESSAGE\": {\n            \"required\": \"Password
    cannot be empty\",\n            \"minlength\": \"Password should be more than 8
    characters\"\n         }\n      },\n      \"P12_FILE\": {\n         \"TOOLTIP\":
    \"P12 File\",\n         \"VALIDATION_MESSAGE\": {\n            \"required\": \"P12
    File cannot be empty\"\n         }\n      },\n      \"SYNC_ACCOUNTS\": {\n         \"TOOLTIP\":
    \"Select Mode of synchronisation of Cloud Providers between Autopilot & Spinnaker\",\n
    \        \"VALIDATION_MESSAGE\": {\n            \"required\": \"Please select Sync
    Accounts type\"\n         }\n      },\n      \"ACCOUNTS_PROVIDER\": {\n         \"TOOLTIP\":
    \"Source Control for Halyard Configuration and / or External Account Configuration\",\n
    \        \"VALIDATION_MESSAGE\": {\n            \"required\": \"Please select provider\"\n
    \        }\n      },\n      \"ACCOUNTS_ACCOUNT_NAME\": {\n         \"TOOLTIP\":
    \"Account name of the Source Control\",\n         \"VALIDATION_MESSAGE\": {\n            \"required\":
    \"Please select Account Name\"\n         }\n      },\n      \"ACCOUNTS_REPOSITORY\":
    {\n         \"TOOLTIP\": \"Repository name with full path in the selected Source
    Control Eg., https://github.com/OpsMx/Opsmx-Saas.git\",\n         \"VALIDATION_MESSAGE\":
    {\n            \"required\": \"Repository cannot be empty\",\n            \"cannotContainSpace\":
    \"Repository cannot contain space\",\n            \"invalidUrl\": \"Repository is
    invalid\"\n         }\n      },\n      \"ACCOUNTS_SOURCE_PATH\": {\n         \"TOOLTIP\":
    \"Existing path in the repository\",\n         \"VALIDATION_MESSAGE\": {}\n      },\n
    \     \"ACCOUNTS_REGION\": {\n         \"TOOLTIP\": \"The AWS regions this Spinnaker
    account will manage\",\n         \"VALIDATION_MESSAGE\": {\n            \"required\":
    \"Region cannot be empty\",\n            \"cannotContainSpace\": \"Region cannot
    contain space\",\n            \"startingFromNumber\": \"Region should not start
    with number\"\n         }\n      },\n      \"ACCOUNTS_BUCKET_NAME\": {\n         \"TOOLTIP\":
    \"Bucket Name\",\n         \"VALIDATION_MESSAGE\": {\n            \"required\":
    \"Bucket Name cannot be empty\",\n            \"cannotContainSpace\": \"Bucket Name
    cannot contain space\",\n            \"startingFromNumber\": \"Bucket Name should
    not start with number\"\n         }\n      },\n      \"PIPELINE_PROVIDER\": {\n
    \        \"TOOLTIP\": \"Use this Spinnaker for pipeline promotion.\",\n         \"VALIDATION_MESSAGE\":
    {\n            \"required\": \"Please select provider\"\n         }\n      },\n
    \     \"PIPELINE_ACCOUNT_NAME\": {\n         \"TOOLTIP\": \"\",\n         \"VALIDATION_MESSAGE\":
    {\n            \"required\": \"Please select Account Name\"\n         }\n      },\n
    \     \"PIPELINE_REPOSITORY\": {\n         \"TOOLTIP\": \"\",\n         \"VALIDATION_MESSAGE\":
    {\n            \"required\": \"Repository cannot be empty\",\n            \"cannotContainSpace\":
    \"Repository cannot contain space\",\n            \"invalidUrl\": \"Repository is
    invalid\"\n         }\n      },\n      \"PIPELINE_SOURCE_PATH\": {\n         \"TOOLTIP\":
    \"Existing path in the repository\",\n         \"VALIDATION_MESSAGE\": {}\n      },\n
    \     \"PIPELINE_REGION\": {\n         \"TOOLTIP\": \"\",\n         \"VALIDATION_MESSAGE\":
    {\n            \"required\": \"Region cannot be empty\",\n            \"cannotContainSpace\":
    \"Region cannot contain space\",\n            \"startingFromNumber\": \"Region should
    not start with number\"\n         }\n      },\n      \"PIPELINE_BUCKET_NAME\": {\n
    \        \"TOOLTIP\": \"Bucket Name\",\n         \"VALIDATION_MESSAGE\": {\n            \"required\":
    \"Bucket Name cannot be empty\",\n            \"cannotContainSpace\": \"Bucket Name
    cannot contain space\",\n            \"startingFromNumber\": \"Bucket Name should
    not start with number\"\n         }\n      }\n   },\n   \"INTEGRATOR_LISTING\":
    {\n      \"HEADER\": \"No Integrator found!\",\n      \"BODY\": \"<div><p>Autopilot
    offers integration with many CI/CD Tools. Integrations are grouped under the following
    categories - Artifact, CI, Governance, Monitoring Tools, Notifications, Policy and
    SAST/DAST.</p> <p> Integrations are used to </p> <ul> <li> pull logs & metrics for
    Continuous Verification </li> <li> pull meta data from CI/CD Tools for Informed
    Approvals </li> <li> enforce organizational policies at the time of creating or
    executing a  pipeline. </li> <li> configure integrations in Spinnaker for Artifacts,
    Notifications. etc </li> </ul> <p>Click on the <b>New Integration</b> button to
    add accounts for your CI/CD tools</p> </div>\",\n\n     \"SYNC_SPINNAKER_ACCOUNTS\"
    : {\n        \"TOOLTIP\": \"Push Integration changes to Spinnaker\",\n        \"VALIDATION_MESSAGE\":
    \"\"\n     }\n   },\n   \"PIPELINE_EXECUTION_AUDIT_LISTING\": {\n      \"HEADER\":
    \"Pipeline executions not found!\",\n      \"BODY\": \"<div>This page shows pipeline
    executions coming from a CD Tool such as Spinnaker in a list view. It also contains
    the summary view showing the total number of Pipeline Runs, Successful Runs, Failed
    Runs, Cancelled Runs.</div><br>    <div >Only important fields including Application,
    Service, Pipeline, Status, Start Time and End Time are shown by default. Additional
    fields can be enabled using the Hamburger menu towars the right corner.</div><br>
    <div>Ensure that the Spinnaker is already connected under <strong><a routerLink='/setup/spinnaker'>Setup
    -> Spinnaker</a></strong>. Pipeline executions will start appearing in this page
    after establishing connection to Spinnaker. </div>\",\n      \"TOOLTIP\": {\n         \"EXECUTION_DATA\":
    \"Pipeline is in Running State\",\n         \"CONNECTOR_DATA\": \"Pipeline is in
    Running State\",\n         \"STAGE_DURATION\": \"Pipeline is in Running State\"\n
    \     },\n      \"VALIDATION_MESSAGE\": {\n         \"STAGE_DURATION\": \"No Data
    available to view Stage Duration\"\n      }\n   },\n   \"PIPELINE_AUDIT_LISTING\":
    {\n      \"HEADER\": \"Pipeline updates not found!\",\n      \"BODY\": \"<div>This
    page shows pipeline updates coming from a CD Tool such as Spinnaker in a list view.
    </div> <div >  Ensure that the Spinnaker is already connected under  <strong><a
    routerLink='/setup/spinnaker'>Setup -> Spinnaker</a></strong>. Pipeline updates
    will start appearing in this page after establishing connection to Spinnaker.</div>\"\n
    \  },\n   \"POLICY_AUDIT_LISTING\": {\n      \"HEADER\": \"Policy updates / executions
    not found!\",\n      \"BODY\": \"<div>This page shows policy updates and policy
    executions, along with allowed/denied information, in a list view. Possible uses,
    apart from audit and compliance, includes helping users understand the policies
    that they might be inadvertently trying to break.</div><br> <div>For policy updates,
    ensure that a policy is created/updated under <strong><a routerLink='/policymanagement'>Compliance
    -> Policy Management</a></strong>. For policy execution events, please add a policy
    in a pipeline and execute it.</div>\"\n   },\n   \"POLICY_CREATION\": {\n      \"BODY\":
    \"<p>In this page, you can  define & manage policies.</p><p><strong>Fields</strong>:</p><ul
    class='helpTextUl'><li> <strong>Name:</strong> User defined name for the policy</li><li><strong>Policy
    Type:</strong> Static or Runtime Policy</li><li> <strong>Policy Engine:</strong>
    Policy Engine to be used; currently, only OPA is supported</li> <li><strong>Policy
    Engine Account:</strong> Policy Engine Account for the Credentials </li>        <li><strong>Policy
    File:</strong> File containing the Policy You can upload the file by clicking on
    <strong>Choose File</strong> button. This is optional. If not present, you can enter
    the policy directly in the <strong>Policy Details</strong> field</li><li> <strong>Policy
    Details:</strong> Policy definition</li>                                 <li><strong>Policy
    Permissions:</strong> Enable/disable access to the policy in Autopilot to specific
    usergroup</li></ul>\",\n       \"HEADER\": \"Policy\",\n       \"NAME\": {\n         \"TOOLTIP\":
    \"Policy Name\",\n         \"VALIDATION_MESSAGE\": {\n            \"required\":
    \"Name cannot be empty\",\n            \"cannotContainSpace\": \"Name cannot contain
    space\",\n            \"exists\": \"Name already exists\"\n         }\n      },\n
    \     \"POLICY_DETAILS\": {\n         \"TOOLTIP\": \"Policy Details\",\n         \"VALIDATION_MESSAGE\":
    {\n            \"required\": \"Policy Details cannot be empty\"\n         }\n      },\n
    \     \"POLICY_ENGINE\": {\n         \"TOOLTIP\": \"Supported Policy Account Types\",\n
    \        \"VALIDATION_MESSAGE\": {\n            \"required\": \"Please select Policy
    Account Type\"\n         }\n      },\n      \"POLICY_ENGINE_ACCOUNT\": {\n         \"TOOLTIP\":
    \"Policy Account Names\",\n         \"VALIDATION_MESSAGE\": {\n            \"required\":
    \"Please select Policy Engine Account\"\n         }\n      },\n      \"POLICY_TYPE\":
    {\n         \"TOOLTIP\": \"A static policy lets users validate conditions before
    the start of execution, whereas a Runtime policy enables users for automated decision
    making during execution.\",\n         \"VALIDATION_MESSAGE\": {\n            \"required\":
    \"Please select Policy Engine Type\"\n         }\n      },\n      \"POLICY_DESCRIPTION\":
    {\n         \"TOOLTIP\": \"Policy Description\"\n      },\n      \"POLICY_FILE\":
    {\n         \"TOOLTIP\": \"Policy File\"\n      }\n   },\n   \"VERIFICATION\": {\n
    \     \"HEADER\": \"Verfication Gate executions not found!\",\n      \"BODY\": \"<div><p>The
    Continuous Verification performs automated log and metrics analysis for new   releases
    with built-in unsupervised and supervised machine learning algorithms for risk analysis
    and canary deployments.</p> <p>Continuous Verification is a release verification
    process that provides Dev and Ops engineers an intelligent automated real-time actionable
    risk assessment of a new release deployed. The Continuous Verification verifies
    the latest version of the service comparing to the baseline or prior release after
    production rollout.         The baseline can be a deployment done prior or the current
    deployment during rollout using canary or blue/green or rolling update strategies.</p>
    <p>It leverages unsupervised and supervised machine learning techniques to analyze
    100s of metrics and logs data to perform in-depth analysis of architectural regressions,
    performance, scalability and security violations of new releases in a scalable way
    for enterprises.</p> <p>Autopilot provides a Verification Gate to analyse logs from
    your Target Application and this can be inserted as a Stage in your CI/CD Pipeline.Note
    that one must configure the metric and log datasources, such as Prometheus and Elastic
    before using this functionality.</p> <p>This page shows Verification Gate executions
    in a list view.  </p> <p>Insert Verification Gate to a pipeline in your application
    using <a [routerLink]='['/setup/applications']'><strong>Setup -> Applications</strong></a>.
    When the pipeline is run, the Gate executions will start appearing in this page.</p></div>\",\n
    \     \"LOG_ANALYSIS\": {\n         \"BODY\": \"\",\n         \"SENSITIVITY\": {\n
    \           \"TOOLTIP\": \"Impact of Unexpected Issues on the log scoring\",\n            \"VALIDATION_MESSAGE\":
    {}\n         },\n         \"PERCEIVED_RISK\": {\n            \"TOOLTIP\": \"The
    overall risk associated with the changes in this verification run\",\n            \"VALIDATION_MESSAGE\":
    {}\n         }\n      },\n      \"ANALYSIS_SUMMARY\": {\n         \"LOG_TEMPLATE\":
    {\n            \"TOOLTIP\": \"Log Template\",\n            \"VALIDATION_MESSAGE\":
    {}\n         },\n         \"METRIC_TEMPLATE\": {\n            \"TOOLTIP\": \"Metric
    Template\",\n            \"VALIDATION_MESSAGE\": {}\n         },\n         \"LOG_BASELINE_START_TIME\":
    {\n            \"TOOLTIP\": \"Baseline Start Time\",\n            \"VALIDATION_MESSAGE\":
    {}\n         },\n         \"LOG_BASELINE_END_TIME\": {\n            \"TOOLTIP\":
    \"Baseline End Time\",\n            \"VALIDATION_MESSAGE\": {}\n         },\n         \"LOG_NEW_RELEASE_START_TIME\":
    {\n            \"TOOLTIP\": \"New Release Start Time\",\n            \"VALIDATION_MESSAGE\":
    {}\n         },\n         \"LOG_NEW_RELEASE_END_TIME\": {\n            \"TOOLTIP\":
    \"New Release End Time\",\n            \"VALIDATION_MESSAGE\": {}\n         },\n
    \        \"ANALYSIS_TYPE\": {\n            \"TOOLTIP\": \"Analysis Type\",\n            \"VALIDATION_MESSAGE\":
    {}\n         },\n         \"LOG_STATUS\": {\n            \"TOOLTIP\": \"Log Status\",\n
    \           \"VALIDATION_MESSAGE\": {}\n         },\n         \"LOG_SCORE\": {\n
    \           \"TOOLTIP\": \"Log Score\",\n            \"VALIDATION_MESSAGE\": {}\n
    \        },\n         \"METRIC_STATUS\": {\n            \"TOOLTIP\": \"Metric Status\",\n
    \           \"VALIDATION_MESSAGE\": {}\n         },\n         \"METRIC_SCORE\":
    {\n            \"TOOLTIP\": \"Metric Score\",\n            \"VALIDATION_MESSAGE\":
    {}\n         },\n         \"BASELINE_SIZE\": {\n            \"TOOLTIP\": \"Baseline
    Size\",\n            \"VALIDATION_MESSAGE\": {}\n         },\n         \"NEW_RELEASE_SIZE\":
    {\n            \"TOOLTIP\": \"New Release Size\",\n            \"VALIDATION_MESSAGE\":
    {}\n         },\n         \"BASELINE_LINES\": {\n            \"TOOLTIP\": \"Baseline
    Lines\",\n            \"VALIDATION_MESSAGE\": {}\n         },\n         \"NEW_RELEASE_LINES\":
    {\n            \"TOOLTIP\": \"New Release Lines\",\n            \"VALIDATION_MESSAGE\":
    {}\n         },\n         \"ANALYSIS_DURATION\": {\n            \"TOOLTIP\": \"Analysis
    Duration\",\n            \"VALIDATION_MESSAGE\": {}\n         },\n         \"LIFETIME_HOURS\":
    {\n            \"TOOLTIP\": \"Lifetime Hours\",\n            \"VALIDATION_MESSAGE\":
    {}\n         },\n         \"RECLASSIFICATION_DURATION\": {\n            \"TOOLTIP\":
    \"Reclassification Duration\",\n            \"VALIDATION_MESSAGE\": {}\n         },\n
    \        \"INTERVAL_MINUTES\": {\n            \"TOOLTIP\": \"Interval Minutes\",\n
    \           \"VALIDATION_MESSAGE\": {}\n         },\n         \"REGULAR_EXPRESSION\":
    {\n            \"TOOLTIP\": \"Regular Expression\",\n            \"VALIDATION_MESSAGE\":
    {}\n         },\n         \"RESPONSE_KEY\": {\n            \"TOOLTIP\": \"Response
    Key\",\n            \"VALIDATION_MESSAGE\": {}\n         },\n         \"SCORING_ALGORITHM\":
    {\n            \"TOOLTIP\": \"Scoring Algorithm\",\n            \"VALIDATION_MESSAGE\":
    {}\n         },\n         \"BASELINE_LOGS\": {\n            \"TOOLTIP\": \"Baseline
    Logs\",\n            \"VALIDATION_MESSAGE\": {}\n         },\n         \"NEW_RELEASE_LOGS\":
    {\n            \"TOOLTIP\": \"New Release Logs\",\n            \"VALIDATION_MESSAGE\":
    {}\n         }\n      },\n      \"METRIC_ANALYSIS\": {\n         \"BODY\": \"\"\n
    \     },\n      \"CORRELATION\": {\n         \"BODY\": \"\"\n      }\n   },\n   \"MANUAL_TRIGGER\":
    {\n      \"BODY\": \"<p>Continuous Verification is a REST service that can be deployed
    on premise or use managed cloud service for analysis. Continuous Verification interfaces
    with monitoring systems for logs and metrics and uses the metadata provided in start
    analysis phase to retrieve the logs and metrics for deployment verification. Continuous
    Verification does not interface with the services deployed directly for its analysis.
    \           Deployment Pipeline can be based on Spinnaker or Jenkins for Enterprise
    Continuous Delivery. Verification can also be triggered manually by providing the
    required parameters in this dialog box.</p>\",\n      \"APPLICATION\": {\n         \"TOOLTIP\":
    \"Name of the application\",\n         \"VALIDATION_MESSAGE\": \"\"\n      },\n
    \     \"BASELINE_START_TIME\": {\n         \"TOOLTIP\": \"Time to enable warming
    up of the container\",\n         \"VALIDATION_MESSAGE\": \"\"\n      },\n      \"NEW_RELEASE_START_TIME\":
    {\n         \"TOOLTIP\": \"Intervals in which metric-data is fetched and analysed\",\n
    \        \"VALIDATION_MESSAGE\": \"\"\n      },\n      \"SUCCESSFUL_SCORE\": {\n
    \        \"TOOLTIP\": \"The score under which the Analysis should fail\",\n         \"VALIDATION_MESSAGE\":
    \"\"\n      },\n      \"UNHEALTHY_SCORE\": {\n         \"TOOLTIP\": \"The score
    above which the Analysis should be a pass\",\n         \"VALIDATION_MESSAGE\": \"\"\n
    \     },\n      \"ANALYSIS_LIFETIME\": {\n         \"TOOLTIP\": \"The time in hours
    for which the Canary Analysis should be run\",\n         \"VALIDATION_MESSAGE\":
    \"\"\n      },\n      \"RUN_INFO\": {\n         \"TOOLTIP\": {\n            \"Build
    Info\": \"http://jenkins.opsmx.net:8181/jenkins/job/Dev-visibilityservice-build-branch/770/\",\n
    \           \"Code Repository\": \"https://github.com/OpsMx/visibility-service\",\n
    \           \"Version\": \"v1.09\"\n         },\n         \"VALIDATION_MESSAGE\":
    \"\"\n      },\n      \"SERVICE\": {\n         \"TOOLTIP\": \"Service\",\n         \"VALIDATION_MESSAGE\":
    \"\"\n      },\n      \"TEMPLATE_NAME\": {\n         \"TOOLTIP\": \"Template Name\",\n
    \        \"VALIDATION_MESSAGE\": \"\"\n      },\n      \"GATE\": {\n         \"TOOLTIP\":
    \"Gate\",\n         \"VALIDATION_MESSAGE\": \"\"\n      },\n      \"FILTER_KEY\":
    {\n         \"TOOLTIP\": \"Filter Key\",\n         \"VALIDATION_MESSAGE\": \"\"\n
    \     },\n      \"BASELINE\": {\n         \"TOOLTIP\": \"Baseline\",\n         \"VALIDATION_MESSAGE\":
    \"\"\n      },\n      \"NEW_RELEASE\": {\n         \"TOOLTIP\": \"New Release\",\n
    \        \"VALIDATION_MESSAGE\": \"\"\n      }\n   },\n   \"TEST_VERIFICATON\":
    {\n      \"HEADER\": \"Test Verfication Gate executions not found!\",\n      \"BODY\":
    \"<div> <p>The Continuous Verification performs automated log and metric analysis
    for new releases with built-in unsupervised and supervised machine learning algorithms
    for risk analysis. Autopilot provides a Test Verification Gate to analyse logs from
    your Test Harness and this can be inserted as a Stage in your CI/CD Pipeline. </p>
    \    <p>This page shows Test Verification Gate executions in a list view. </p> <p>Insert
    Test Verification Gate to a pipeline in your application using <a [routerLink]='['/setup/applications']'><strong>Setup
    -> Applications</strong></a>.When the pipeline is run, the Gate executions will
    start appearing in this page.</p> </div>\"\n   },\n   \"VISIBILITY_LISTING\": {\n
    \     \"HEADER\": \" <div><span style='font-size: 16px; font-weight: bold;'>Approval
    Gate executions not found!</span></div>\",\n      \"BODY\": \"<div><p>Autopilot
    provides <strong>approval</strong> mechanism for deployments. To make an informed
    decision regarding pipeline execution, an approver may need to check the data from
    multiple data sources, such as CI Systems, Repositories, SAST/DAST Tools etc. Autopilot
    provides Approval Gate feature which fetches relevant information from multiple
    CI/CD Tools, presents the data in one place, to enable the user to make an quick
    and informed decision on pipeline execution. This Gate can be inserted as a Stage
    in your CI/CD Pipeline. </p> <p>Note that appropriate data sources must be configured
    in the <strong>Integration</strong> view before Approval stage can be used.</p>
    <p>This page shows Approval Gate executions in a list view.</p> <p> Insert Approval
    Gate to a pipeline in your application using <strong><a routerLink='/setup/v2/applications'>Setup
    -> Applications</a></strong>. When the pipeline is run, the Gate executions will
    start appearing in this page. </p> </div>\"\n   },\n   \"VISIBILITY_DETAILS\": {\n
    \     \"APPLICATION_NAME\": {\n         \"TOOLTIP\": \"\",\n         \"VALIDATION_MESSAGE\":
    \"\"\n      },\n      \"SERVICE_NAME\": {\n         \"TOOLTIP\": \"\",\n         \"VALIDATION_MESSAGE\":
    \"\"\n      },\n     \"APPROVAL_BTN_TITLE\": {\n        \"TOOLTIP\":  \"Insufficient
    Permission to execute\",\n        \"VALIDATION_MESSAGE\": \"\"\n     },\n      \"GATE_NAME\":
    {\n         \"TOOLTIP\": \"\",\n         \"VALIDATION_MESSAGE\": \"\"\n      },\n
    \     \"STATUS\": {\n         \"TOOLTIP\": \"\",\n         \"VALIDATION_MESSAGE\":
    \"\"\n      },\n      \"COMMENT\": {\n         \"TOOLTIP\": \"\",\n         \"VALIDATION_MESSAGE\":
    \"\"\n      },\n      \"TRIGGER_URL\": {\n         \"TOOLTIP\": \"\",\n         \"VALIDATION_MESSAGE\":
    \"\"\n      },\n      \"APPROVAL_GROUP\": {\n         \"TOOLTIP\": \"\",\n         \"VALIDATION_MESSAGE\":
    \"\"\n      },\n      \"CONNECTORS\": {\n         \"TOOLTIP\": \"\",\n         \"VALIDATION_MESSAGE\":
    \"\"\n      },\n      \"ACTIVATED_TIME\": {\n         \"TOOLTIP\": \"\",\n         \"VALIDATION_MESSAGE\":
    \"\"\n      },\n      \"REVIEWED_AT\": {\n         \"TOOLTIP\": \"\",\n         \"VALIDATION_MESSAGE\":
    \"\"\n      },\n      \"REVIEWER\": {\n         \"TOOLTIP\": \"\",\n         \"VALIDATION_MESSAGE\":
    \"\"\n      },\n      \"COMMENTS\": {\n         \"TOOLTIP\": \"\",\n         \"VALIDATION_MESSAGE\":
    \"\"\n      }\n   },\n   \"FORM_GRID\": {\n      \"ADD_NEW_ROW\": {\n         \"TOOLTIP\":
    \"Add New Row\",\n         \"VALIDATION_MESSAGE\": \"\"\n      },\n      \"DELETE_ROW\":
    {\n         \"TOOLTIP\": \"Delete row\",\n         \"VALIDATION_MESSAGE\": \"\"\n
    \     }\n   },\n  \"APPLICATION_DASHBOARD\": {\n     \"VERIFICATION_FAILURES\":{\n
    \       \"TOOLTIP\":  \"Total number of Verification Failures including Test Verification
    Failures\",\n        \"VALIDATION_MESSAGE\": \"\" \n     }\n  },\n   \"APPLICATION_LISTING\":
    {\n      \"HEADER\": \"No Applications found!\",\n      \"BODY\": \"<p> You will
    be able to view the applications you have created or imported from a CD Tool such
    as Spinnaker in this page. There could be just one or multiple services in an application.
    Each service can have multiple pipelines and each pipeline can have multiple stages
    needed in order to successfully deploy the application. </p> <p>You can create native
    Autopilot applications or import the applications created in Spinnaker.</p> <p><strong>Spinnaker
    Application</strong>: To import applications from Spinnaker, click on the <strong>Sync
    Spinnaker Applications</strong> button; before doing this, ensure that the Spinnaker
    is already connected under <strong><a  routerLink='/setup/spinnaker'>Setup -> Spinnaker</a></strong></p>
    <p><strong>Autopilot Application</strong>: To create a native Autopilot Application,
    click on the <strong>New Application</strong> button</p>\" ,\n    \"PLACEHOLDER\":
    \"You don't have access to this Page. Please contact your Administrator\",\n    \"SYNC_SPINNAKER\":{\n
    \       \"TOOLTIP\":  \"To be able to work on applications created in Spinnaker,
    you need to import them here\",\n        \"VALIDATION_MESSAGE\": \"\"\n     }\n
    \  },\n   \"START_DEPLOYMENT\": {\n      \"APPLICATION_NAME\": {\n         \"TOOLTIP\":
    \"\",\n         \"VALIDATION_MESSAGE\": {\n            \"required\": \"Application
    Name is required\",\n            \"empty\": \"Please create Spinnaker Application
    to continue\"\n         }\n      },\n      \"SERVICE_NAME\": {\n         \"TOOLTIP\":
    \"\",\n         \"VALIDATION_MESSAGE\": {\n            \"required\": \"Service Name
    is required\",\n            \"empty\": \"Pipelines are not present for this Application\"\n
    \        }\n      },\n      \"START_DEPLOYMENT_BTN\": {\n         \"TOOLTIP\": \"Please
    create Spinnaker Application to 'Start New Deployment'\",\n         \"VALIDATION_MESSAGE\":
    {\n            \"required\": \"Service Name is required\"\n         }\n      }\n
    \  },\n   \"APPLICATION_DETAILS\": {\n      \"HEADER\": \"Application Details\",\n
    \     \"BODY\": \"<ul class='helpTextUI'><li><strong>Application Name</strong>:
    User defined name of the application</li> <li><strong>Description</strong>: Application
    description</li> <li><strong>Email ID</strong>: Your email id</li></ul>\",\n      \"APPLICATION_NAME\":
    {\n         \"TOOLTIP\": \"\",\n         \"VALIDATION_MESSAGE\": {\n            \"exists\":
    \"Application already exists\",\n            \"noSpecialCharacters\": \"Application
    Name cannot contain special characters\",\n            \"cannotContainSpace\": \"Application
    Name cannot contain space\",\n            \"required\": \"Application Name cannot
    be empty\",\n            \"startingFromNumber\": \"Application Name cannot start
    with numbers\",\n            \"maxlength\": \"Application name should not have more
    than 63 characters!\"\n         }\n      },\n      \"APPLICATION_DESCRIPTION\":
    {\n         \"TOOLTIP\": \"\",\n         \"VALIDATION_MESSAGE\": \"\"\n      },\n
    \     \"EMAIL_ID\": {\n         \"TOOLTIP\": \"\",\n         \"VALIDATION_MESSAGE\":
    {\n            \"email\": \"Email Id is invalid\",\n            \"required\": \"Email
    Id cannot be empty\"\n         }\n      }\n   },\n   \"SERVICE_DETAILS\": {\n      \"HEADER\":
    \"Services\",\n      \"BODY\": \"<p>An Application can contain multiple services.
    A service can contain multiple pipelines. When a Service is created, a Pipeline
    with the same name is created automatically. You can add more pipelines by clicking
    on '+' symbol in <strong>Service Pipeline</strong></p>\",\n      \"SERVICE_NAME\":
    {\n         \"TOOLTIP\": \"\",\n         \"VALIDATION_MESSAGE\": {\n            \"exists\":
    \"Service already exists\",\n            \"noSpecialCharacters\": \"Service Name
    cannot contain special characters\",\n            \"cannotContainSpace\": \"Service
    Name cannot contain space\",\n            \"required\": \"Service Name cannot be
    empty\",\n            \"startingFromNumber\": \"Service Name cannot start with number\",\n
    \           \"maxlength\": \"Service name should not have more than 63 characters!\"\n
    \        }\n      },\n      \"SERVICE_PIPELINE\": {\n         \"TOOLTIP\": \"\",\n
    \        \"VALIDATION_MESSAGE\": \"\"\n      },\n      \"ADD_NEW_SERVICE\": {\n
    \        \"TOOLTIP\": \"Add a new Service\",\n         \"VALIDATION_MESSAGE\": \"\"\n
    \     },\n      \"SHOW_OR_HIDE_SERVICE\": {\n         \"TOOLTIP\": \"Show / Hide
    this Service in the Application Dashboard\",\n         \"VALIDATION_MESSAGE\": \"\"\n
    \     },\n      \"DELETE_PIPELINE_ICON\": {\n         \"TOOLTIP\": \"Delete Pipeline
    from Service\",\n         \"VALIDATION_MESSAGE\": \"\"\n      },\n     \"DELETE_PERMISSION\":
    {\n        \"TOOLTIP\": \"Insufficient Permission to Delete this Service\",\n        \"VALIDATION_MESSAGE\":
    \"\"\n     },\n    \"DELETE_SERVICE\": {\n        \"TOOLTIP\": \"Service can be
    deleted on deleting pipelines\",\n        \"VALIDATION_MESSAGE\": \"\"\n    }\n
    \  },\n   \"GROUP_PERMISSION\": {\n      \"APP_PERMISSIONS\": {\n         \"TOOLTIP\":
    \"Authorization definition for this Application\",\n         \"VALIDATION_MESSAGE\":
    {\n            \"groupValid\": \"Groups cannot be empty\",\n            \"permissionsValid\":
    \"Atleast 1 permission should be assigned to the groups\",\n            \"allPermissionForOneGroup\":
    \"Atleast 1 group should have all permissions\"\n         }\n      },\n      \"INTEGRATORS_PERMISSIONS\":
    {\n         \"TOOLTIP\": \"Authorization definition for this Integration\",\n         \"VALIDATION_MESSAGE\":
    \"\"\n      },\n      \"CLOUD_PROVIDER_PERMISSIONS\": {\n        \"TOOLTIP\": \"Authorization
    definition for this Cloud Provider\",\n        \"VALIDATION_MESSAGE\": \"\"\n     },\n
    \     \"AGENT_PERMISSIONS\": {\n         \"TOOLTIP\": \"Authorization definition
    for this Agent\",\n         \"VALIDATION_MESSAGE\": \"\"\n      },\n      \"POLICY_PERMISSIONS\":
    {\n         \"TOOLTIP\": \"Authorization definition for this Policy\",\n         \"VALIDATION_MESSAGE\":
    \"\"\n      },\n      \"ADD_GROUP\": {\n         \"TOOLTIP\": \"Add New Group\",\n
    \        \"VALIDATION_MESSAGE\": \"\"\n      },\n      \"DELETE\": {\n         \"TOOLTIP\":
    \"Delete\",\n         \"VALIDATION_MESSAGE\": \"\"\n      }\n   },\n   \"GATE_DETAILS\":
    {\n      \"HEADER\": \"Gate Configuration\",\n      \"BODY\": \"<p>Select Gates
    from <strong>Existing Gates</strong> dropdown to load Gate Configuration and to
    add new Gate Configuration click the <strong>Add New Gate</strong> button</p> <p>Autopilot
    has the following Gate Types</p> <ul class='helpTextUI'> <li><strong>Approval</strong>:
    Fetches relevant information from multiple CI/CD Tools, presents the data in one
    place, to enable the user to make quick and informed decision on pipeline execution</li>
    <li><strong>Verification</strong>: Analyze logs & metrics from your target application
    to evaluate the risk in software delivery</li> <li><strong>Test Verification</strong>:
    Analyze logs from your Test Harness to evaluate the risk in software delivery</li>
    \ <li><strong>Policy</strong>: Defines a set of conditions that need to be verified
    while creating or executing a CI/CD pipeline</li> </ul>\",\n      \"PIPELINE\":
    {\n         \"TOOLTIP\": \"Shows the structure of how the Gates are stacked in the
    Pipeline\",\n         \"VALIDATION_MESSAGE\": \"\"\n      },\n      \"TYPE\": {\n
    \        \"TOOLTIP\": \"\",\n         \"VALIDATION_MESSAGE\": \"\"\n      },\n      \"EXISITING_GATE\":
    {\n         \"TOOLTIP\": \"\",\n         \"VALIDATION_MESSAGE\": \"\"\n      },\n
    \     \"ENVIRONMENT\": {\n         \"TOOLTIP\": \"Specify Environment for this Gate\",\n
    \        \"VALIDATION_MESSAGE\": {\n            \"required\": \"Environment Name
    is Invalid\"\n         }\n      },\n      \"CUSTOM_ENVIRONMENT_NAME\": {\n         \"TOOLTIP\":
    \"\",\n         \"VALIDATION_MESSAGE\": {\n            \"noSpecialCharacters\":
    \"Environment Name cannot contain special characters\",\n            \"cannotContainSpace\":
    \"Environment Name cannot contain space\",\n            \"required\": \"Environment
    Name cannot be empty\",\n            \"startingFromNumber\": \"Environment Name
    cannot start with number\",\n            \"maxlength\": \"Environment name should
    not have more than 63 characters!\"\n         }\n      },\n      \"GATE_NAME\":
    {\n         \"TOOLTIP\": \"\",\n         \"VALIDATION_MESSAGE\": {\n            \"exists\":
    \"Gate already exists\",\n            \"noSpecialCharacters\": \"Gate Name cannot
    contain special characters\",\n            \"cannotContainSpace\": \"Gate Name cannot
    contain space\",\n            \"required\": \"Gate Name cannot be empty\",\n            \"startingFromNumber\":
    \"Gate Name cannot start with number\",\n            \"maxlength\": \"Gate name
    should not have more than 63 characters!\"\n         }\n      },\n      \"DEPENDS_ON\":
    {\n         \"TOOLTIP\": \"This field determines the placement of the current Gate
    in the Pipeline. This field is not required if there are no Stages in the Pipeline\",\n
    \        \"VALIDATION_MESSAGE\": {\n            \"required\": \"Depends On cannot
    be empty\"\n         }\n      },\n      \"CONNECTOR\": {\n         \"TOOLTIP\":
    \"Tool to gather information for informed Approvals\",\n         \"VALIDATION_MESSAGE\":
    {\n            \"required\": \"Please select Connector\"\n         }\n      },\n
    \     \"ACCOUNT\": {\n         \"TOOLTIP\": \"Account name of the connector\",\n
    \        \"VALIDATION_MESSAGE\": {\n            \"required\": \"Please select Account\"\n
    \        }\n      },\n      \"TEMPLATE\": {\n         \"TOOLTIP\": \"Define the
    specific fields of interest from connector\",\n         \"VALIDATION_MESSAGE\":
    {\n            \"required\": \"Please select Template\"\n         }\n      },\n
    \     \"ADD_NEW_TEMPLATE\": {\n         \"TOOLTIP\": \"Add New Connector\",\n         \"VALIDATION_MESSAGE\":
    \"\"\n      },\n      \"EDIT_TEMPLATE\": {\n         \"TOOLTIP\": \"Edit Template\",\n
    \        \"VALIDATION_MESSAGE\": \"\"\n      },\n      \"VIEW_TEMPLATE\": {\n         \"TOOLTIP\":
    \"View Template\",\n         \"VALIDATION_MESSAGE\": \"\"\n      },\n      \"DELETE_TEMPLATE\":
    {\n         \"TOOLTIP\": \"Delete Template\",\n         \"VALIDATION_MESSAGE\":
    \"\"\n      },\n      \"TEMPLATE_TOOL_TYPE\": {\n         \"TOOLTIP\": \"\",\n         \"VALIDATION_MESSAGE\":
    \"\"\n      },\n      \"TEMPLATE_NAME\": {\n         \"TOOLTIP\": \"\",\n         \"VALIDATION_MESSAGE\":
    {\n            \"noSpecialCharacters\": \"Template Name cannot contain special characters\",\n
    \           \"required\": \"Template Name cannot be empty\",\n            \"startingFromNumber\":
    \"Template Name cannot start with number\",\n            \"maxlength\": \"Template
    Name should not have more than 63 characters!\"\n         }\n      },\n      \"TEMPLATE_DESCRIPTION\":
    {\n         \"TOOLTIP\": \"\",\n         \"VALIDATION_MESSAGE\": \"\"\n      },\n
    \     \"AUTOMATED_APPROVAL\": {\n         \"TOOLTIP\": \"Use predefined conditions
    to Approve or Reject a request. You can configure conditions using Policies.\",\n
    \        \"VALIDATION_MESSAGE\": {\n            \"required\": \"Please select Approval
    Condition\"\n         }\n      },\n      \"APPROVAL_GROUPS\": {\n         \"TOOLTIP\":
    \"Selected groups will be able to review this Approval Gate\",\n         \"VALIDATION_MESSAGE\":
    {\n            \"required\": \"Please select Approval Groups to continue\"\n         }\n
    \     },\n      \"APPROVAL_GROUP_MSG\": {\n         \"TOOLTIP\": \"Selected groups
    should have atleast view access to the application\",\n         \"VALIDATION_MESSAGE\":
    \"\"\n      },\n      \"GATE_SECURITY_SOURCE_URL\": {\n         \"TOOLTIP\": \"Source
    Url\",\n         \"VALIDATION_MESSAGE\": \"\"\n      },\n      \"GATE_SECURITY_SOURCE_URL_COPY\":
    {\n         \"TOOLTIP\": \"Copy Source Url\",\n         \"VALIDATION_MESSAGE\":
    \"\"\n      },\n      \"PAYLOAD_CONSTRAINTS\": {\n         \"TOOLTIP\": \"Payload
    Constraints for Gate Security\",\n         \"VALIDATION_MESSAGE\": \"\"\n      },\n
    \     \"PAYLOAD_CONSTRAINTS_KEY\": {\n         \"TOOLTIP\": \"\",\n         \"VALIDATION_MESSAGE\":
    {\n            \"cannotContainSpace\": \"Key cannot contain space\",\n            \"required\":
    \"Invalid Key\"\n         }\n      },\n      \"LOG_TEMPLATE\": {\n         \"TOOLTIP\":
    \"A collection of all the information needed to run the log analysis\",\n         \"VALIDATION_MESSAGE\":
    \"\"\n      },\n      \"CREATE_GATE_CONFIG_TEMPLATE\": {\n         \"TOOLTIP\":
    \"Create New Template\",\n         \"VALIDATION_MESSAGE\": \"\"\n      },\n      \"EDIT_GATE_CONFIG_TEMPLATE\":
    {\n         \"TOOLTIP\": \"Edit Template\",\n         \"VALIDATION_MESSAGE\": \"\"\n
    \     },\n      \"VIEW_GATE_CONFIG_TEMPLATE\": {\n         \"TOOLTIP\": \"View Template\",\n
    \        \"VALIDATION_MESSAGE\": \"\"\n      },\n      \"DELETE_GATE_CONFIG_TEMPLATE\":
    {\n         \"TOOLTIP\": \"Delete Template\",\n         \"VALIDATION_MESSAGE\":
    \"\"\n      },\n      \"METRIC_TEMPLATE\": {\n         \"TOOLTIP\": \"Information
    needed to run the metric analysis\",\n         \"VALIDATION_MESSAGE\": \"\"\n      },\n
    \     \"POLICY\": {\n         \"TOOLTIP\": \"\",\n         \"VALIDATION_MESSAGE\":
    \"\"\n      },\n     \"DELETE_PERMISSION\":{\n        \"TOOLTIP\": \"Insufficient
    Permission to Delete this Gate\",\n        \"VALIDATION_MESSAGE\": \"\"\n     }\n
    \  },\n   \"LOGGED_INUSER_DETAILS\": {\n      \"HEADER\": \"No Users found\",\n
    \     \"BODY\": \"\"\n   },\n   \"INTEGRATION\": {\n      \"AMAZONS3\": {\n         \"HEADER\":
    \"Amazon S3\",\n         \"BODY\": \"<span><p>Amazon S3 integration can be used
    to configure Spinnaker for Amazon S3.</p><p><strong>Fields</strong>:</p><ul class='helpTextUl'><li><strong>Account
    Name</strong>: User defined name for the Amazon S3 Account <span class='noBr'>(Example:
    opsmx-s3)</span></li><li><strong>Access Key Id</strong>: AWS Access Key Id</li><li><strong>Secret
    Access Key</strong>: AWS Secret Access Key</li><li><strong>Connect to Spinnaker</strong>:
    Toggle to configure Spinnaker for Amazon S3</li><li><strong>Permissions</strong>:
    Enable/disable access to the Amazon S3 account in Autopilot to specific usergroups</li></ul></span>\",\n
    \        \"ACCOUNTNAME\": {\n            \"TOOLTIP\": \"User defined name for the
    Amazon S3 account\",\n            \"VALIDATION_MESSAGE\": {\n               \"noSpecialCharacters\":
    \"Account Name cannot contain special characters other than -\",\n               \"cannotContainSpace\":
    \"Account Name cannot contain space\",\n               \"required\": \"Account Name
    cannot be empty\",\n               \"startingFromNumber\": \"Account Name cannot
    start with numbers\"\n            }\n         },\n         \"ACCESS_ID\": {\n            \"TOOLTIP\":
    \"AWS Access Key Id\",\n            \"VALIDATION_MESSAGE\": {\n               \"required\":
    \"Access Key Id cannot be empty\"\n            }\n         },\n         \"SECRET_KEY\":
    {\n            \"TOOLTIP\": \"AWS Secret Access Key\",\n            \"VALIDATION_MESSAGE\":
    {\n               \"required\": \"Secret Access Key cannot be empty\"\n            }\n
    \        },\n         \"SPINNAKERTOGGLE\": {\n            \"TOOLTIP\": \"\",\n            \"VALIDATION_MESSAGE\":
    {}\n         }\n      },\n      \"ARTIFACTORY\": {\n         \"HEADER\": \"Artifactory\",\n
    \        \"BODY\": \"<span><p>Artifactory integration can be used as a datasource
    for Approval Gate as well as to configure Spinnaker for Artifactory.</p><p><strong>Fields</strong>:</p><ul
    class='helpTextUl'><li><strong>Account Name</strong>: User defined name for the
    Artifactory Account <span class='noBr'>(Example: opsmx-artifactory)</span></li><li><strong>Endpoint</strong>:
    Artifactory URL <span class='noBr'>(Example: https://xyz.myjfrog.com)</span></li><li><strong>Token</strong>:
    Artifactory personal access token. You can find <a href='https://www.jfrog.com/confluence/display/JFROG/Access+Tokens'
    target='_blank'>here</a> how to generate personal access tokens. <span class='autolinebreak'>(Example:
    ZlQDAwMFwvdXNlcnNcL21hZGh1a2FyIiwic2NwIjoiYXBwbGllZC1wZXJtaXNzaW9uc1wvYWRtaW4gYXBpOioiLCJhdWQiOlsiamZydEAqIiwiamZhY0AqIiwiamZldnmbWRAKiJdLCJpc3MiOiJqZmZlQDAAzNzY3MiwiaWF0IjoxNjI5ODY0ODcyLCJqdGkiOiI1ZWFiNjlhYi1hZDY0LTRjOGItOTMyZC0wMDAxMWZiZWU5YWIifQ.tzBgL3fQgZ1dwlLLS2UAT7G)</span></li><li><strong>Connect
    to Spinnaker</strong>: Toggle to configure Spinnaker for Artifactory</li><li><strong>Permissions</strong>:
    Enable/disable access to the Artifactory account in Autopilot to specific usergroups</li></ul></span>\",\n
    \        \"ACCOUNTNAME\": {\n            \"TOOLTIP\": \"User defined name for the
    Artifactory account\",\n            \"VALIDATION_MESSAGE\": {\n               \"noSpecialCharacters\":
    \"Account Name cannot contain special characters other than -\",\n               \"cannotContainSpace\":
    \"Account Name cannot contain space\",\n               \"required\": \"Account Name
    cannot be empty\",\n               \"startingFromNumber\": \"Account Name cannot
    start with numbers\"\n            }\n         },\n         \"ENDPOINT\": {\n            \"TOOLTIP\":
    \"Artifactory URL\",\n            \"VALIDATION_MESSAGE\": {\n               \"required\":
    \"Endpoint cannot be empty\",\n               \"invalidUrl\": \"URL is invalid\"\n
    \           }\n         },\n         \"TOKEN\": {\n            \"TOOLTIP\": \"Artifactory
    Personal Access Token\",\n            \"VALIDATION_MESSAGE\": {\n               \"required\":
    \"Token cannot be empty\"\n            }\n         },\n         \"SPINNAKERTOGGLE\":
    {\n            \"TOOLTIP\": \"\",\n            \"VALIDATION_MESSAGE\": {}\n         }\n
    \     },\n      \"BITBUCKET\": {\n         \"HEADER\": \"Bitbucket Cloud\",\n         \"BODY\":
    \"<span><p>BitBucket Cloud integration can be used as a datasource for Approval
    Gate as well as to configure Spinnaker for BitBucket Cloud.</p><p><strong>Fields</strong>:</p><ul
    class='helpTextUl'><li><strong>Name</strong>: User defined name for the Bitbucket
    Cloud Account <span class='noBr'>(Example: opsmx-bitbucket)</span></li><li><strong>Host
    URL</strong>: BitBucket Cloud URL <span class='noBr'>(Example: https://bitbucket.org)</span></li><li><strong>API
    URL</strong>: This is needed by Autopilot to access Bitbucket Cloud resources such
    as accounts & repositories through API calls <span class='noBr'>(Example: https://api.bitbucket.org/2.0/repositories)</span></li><li><strong>Authentication
    Type</strong>: can be Token or User Name/Password</li><li><strong>User Name</strong>:
    Bitbucket Cloud User Name</li><li><strong>Token</strong>: BitBucket personal access
    token <span class='noBr'>(Example: xCPkVZfxaE9iULmfYYkK)</span></li> <li><strong>Password</strong>:
    Bitbucket Cloud Password</li><li><strong>Connect to Spinnaker</strong>: Toggle to
    configure Spinnaker for Bitbucket Cloud</li><li><strong>Permissions</strong>: Enable/disable
    access to the Bitbucket Account in Autopilot to specific usergroups</li></ul></span>\",\n
    \        \"ACCOUNTNAME\": {\n            \"TOOLTIP\": \"User defined name for the
    BitBucket Cloud account\",\n            \"VALIDATION_MESSAGE\": {\n               \"noSpecialCharacters\":
    \"Account Name cannot contain special characters other than -\",\n               \"cannotContainSpace\":
    \"Account Name cannot contain space\",\n               \"required\": \"Account Name
    cannot be empty\",\n               \"startingFromNumber\": \"Account Name cannot
    start with numbers\"\n            }\n         },\n         \"HOSTURL\": {\n            \"TOOLTIP\":
    \"BitBucket Cloud URL\",\n            \"VALIDATION_MESSAGE\": {\n               \"required\":
    \"Host URL cannot be empty\",\n               \"invalidUrl\": \"URL is invalid\"\n
    \           }\n         },\n         \"APIURL\": {\n            \"TOOLTIP\": \"BitBucket
    Cloud Api URL. This is needed by Autopilot to access Bitbucket Cloud resources such
    as accounts & repositories through API calls\",\n            \"VALIDATION_MESSAGE\":
    {\n               \"required\": \"API URL cannot be empty\",\n               \"invalidUrl\":
    \"URL is invalid\"\n            }\n         },\n         \"AUTHENTICATIONTYPE\":
    {\n            \"TOOLTIP\": \"can be Token or User Name/Password\",\n            \"VALIDATION_MESSAGE\":
    {}\n         },\n         \"TOKEN\": {\n            \"TOOLTIP\": \"BitBucket Cloud
    personal access token\",\n            \"VALIDATION_MESSAGE\": {\n               \"required\":
    \"Token cannot be empty\"\n            }\n         },\n         \"USERNAME\": {\n
    \           \"TOOLTIP\": \"BitBucket Cloud User Name\",\n            \"VALIDATION_MESSAGE\":
    {\n               \"noSpecialCharacters\": \"User Name cannot contain special characters
    other than - and _\",\n               \"cannotContainSpace\": \"User Name cannot
    contain space\",\n               \"required\": \"User Name cannot be empty\",\n
    \              \"startingFromNumber\": \"User Name cannot start with numbers\"\n
    \           }\n         },\n         \"PASSWORD\": {\n            \"TOOLTIP\": \"BitBucket
    Cloud Password\",\n            \"VALIDATION_MESSAGE\": {\n               \"required\":
    \"Password cannot be empty\"\n            }\n         },\n         \"SPINNAKERTOGGLE\":
    {\n            \"TOOLTIP\": \"\",\n            \"VALIDATION_MESSAGE\": {}\n         }\n
    \     },\n      \"BITBUCKET_SERVER\": {\n         \"HEADER\": \"Bitbucket Server\",\n
    \        \"BODY\": \"<span><p>BitBucket Server integration can be used as a datasource
    for Approval Gate as well as to configure Spinnaker for BitBucket Server.</p><p><strong>Fields</strong>:</p><ul
    class='helpTextUl'><li><strong>Account Name</strong>: User defined name for the
    Bitbucket Server Account <span class='noBr'>(Example: opsmx-bitbucket)</span></li><li><strong>Host
    URL</strong>: BitBucket Server URL <span class='noBr'>(Example: https://xyz.mybitbucket.com)</span></li><li><strong>Authentication
    Type</strong>: can be Token or User Name/Password</li><li><strong>User Name</strong>:
    Bitbucket Server User Name</li><li><strong>Token</strong>: BitBucket Server personal
    access token. You can find <a href='https://confluence.atlassian.com/bitbucketserver/personal-access-tokens-939515499.html'
    target='_blank'>here</a> how to generate personal access tokens. <span class='noBr'>(Example:
    DjpMgHmwqUnIvvmljFgqGQ)</span></li><li><strong>Password</strong>: Bitbucket Server
    Password</li><li><strong>Connect to Spinnaker</strong>: Toggle to configure Spinnaker
    for Bitbucket Server</li><li><strong>Permissions</strong>: Enable/disable access
    to the Bitbucket Server account in Autopilot to specific usergroups</li></ul></span>\",\n
    \        \"ACCOUNTNAME\": {\n            \"TOOLTIP\": \"User defined name for the
    Bitbucket Server account\",\n            \"VALIDATION_MESSAGE\": {\n               \"noSpecialCharacters\":
    \"Account Name cannot contain special characters other than -\",\n               \"cannotContainSpace\":
    \"Account Name cannot contain space\",\n               \"required\": \"Account Name
    cannot be empty\",\n               \"startingFromNumber\": \"Account Name cannot
    start with numbers\"\n            }\n         },\n         \"HOSTURL\": {\n            \"TOOLTIP\":
    \"BitBucket Server URL\",\n            \"VALIDATION_MESSAGE\": {\n               \"required\":
    \"Host URL cannot be empty\",\n               \"invalidUrl\": \"URL is invalid\"\n
    \           }\n         },\n         \"AUTHENTICATIONTYPE\": {\n            \"TOOLTIP\":
    \"can be Token or User Name/Password\",\n            \"VALIDATION_MESSAGE\": {}\n
    \        },\n         \"TOKEN\": {\n            \"TOOLTIP\": \"Bitbucket Server
    personal access token\",\n            \"VALIDATION_MESSAGE\": {\n               \"required\":
    \"Token cannot be empty\"\n            }\n         },\n         \"USERNAME\": {\n
    \           \"TOOLTIP\": \"Bitbucket Server User Name\",\n            \"VALIDATION_MESSAGE\":
    {\n               \"noSpecialCharacters\": \"User Name cannot contain special characters
    other than - and _\",\n               \"cannotContainSpace\": \"User Name cannot
    contain space\",\n               \"required\": \"User Name cannot be empty\",\n
    \              \"startingFromNumber\": \"User Name cannot start with numbers\"\n
    \           }\n         },\n         \"PASSWORD\": {\n            \"TOOLTIP\": \"Bitbucket
    Server Password\",\n            \"VALIDATION_MESSAGE\": {\n               \"required\":
    \"Password cannot be empty\"\n            }\n         },\n         \"SPINNAKERTOGGLE\":
    {\n            \"TOOLTIP\": \"\",\n            \"VALIDATION_MESSAGE\": {}\n         }\n
    \     },\n      \"DOCKERHUB\": {\n         \"HEADER\": \"Docker Hub\",\n         \"BODY\":
    \"\",\n         \"ACCOUNTNAME\": {\n            \"TOOLTIP\": \"User defined name
    for the Docker Hub account\",\n            \"VALIDATION_MESSAGE\": {\n               \"noSpecialCharacters\":
    \"Account Name cannot contain special characters other than -\",\n               \"cannotContainSpace\":
    \"Account Name cannot contain space\",\n               \"required\": \"Account Name
    cannot be empty\",\n               \"startingFromNumber\": \"Account Name cannot
    start with numbers\"\n            }\n         },\n         \"TOKEN\": {\n            \"TOOLTIP\":
    \"Dockerhub Personal Access Token\",\n            \"VALIDATION_MESSAGE\": {\n               \"required\":
    \"Token cannot be empty\"\n            }\n         },\n         \"USERNAME\": {\n
    \           \"TOOLTIP\": \"Dockerhub User Name\",\n            \"VALIDATION_MESSAGE\":
    {\n               \"noSpecialCharacters\": \"User Name cannot contain special characters
    other than - and _\",\n               \"cannotContainSpace\": \"User Name cannot
    contain space\",\n               \"required\": \"User Name cannot be empty\",\n
    \              \"startingFromNumber\": \"User Name cannot start with numbers\"\n
    \           }\n         },\n         \"HOSTURL\": {\n            \"TOOLTIP\": \"Dockerhub
    Host URL\",\n            \"VALIDATION_MESSAGE\": {\n               \"required\":
    \"Host URL cannot be empty\",\n               \"invalidUrl\": \"URL is invalid\"\n
    \           }\n         }\n      },\n      \"GITHUB\": {\n         \"HEADER\": \"GitHub\",\n
    \        \"BODY\": \"<span><p>GIT HUB integration can be used as a datasource for
    Approval Gate as well as to configure Spinnaker for GitHub.</p><p><strong>Fields</strong>:</p><ul
    class='helpTextUl'><li><strong>Account Name</strong>: User defined name for the
    GitHub Account<span class='noBr'>(Example: opsmx-github)</span></li><li><strong>Token</strong>:
    GitHub personal access token. You can find <a href='https://docs.github.com/en/authentication/keeping-your-account-and-data-secure/creating-a-personal-access-token'
    target='_blank'>here</a> how to generate personal access tokens. <span class='noBr'>(Example:
    ghp_ln1eJK4yuomnY6JREp72IDJC4Hq6Sm)</span></li><li><strong>User Name</strong>: GitHub
    User Name</li><li><strong>Connect to Spinnaker</strong>: Toggle to configure Spinnaker
    for GitHub</li><li><strong>Permissions</strong>: Enable/disable access to the GIT
    HUB account in Autopilot to specific usergroups</li></ul></span>\",\n         \"ACCOUNTNAME\":
    {\n            \"TOOLTIP\": \"User defined name for the GitHub account\",\n            \"VALIDATION_MESSAGE\":
    {\n               \"noSpecialCharacters\": \"Account Name cannot contain special
    characters other than -\",\n               \"cannotContainSpace\": \"Account Name
    cannot contain space\",\n               \"required\": \"Account Name cannot be empty\",\n
    \              \"startingFromNumber\": \"Account Name cannot start with numbers\"\n
    \           }\n         },\n         \"HOSTURL\": {\n            \"TOOLTIP\": \"GitHub
    Host URL\",\n            \"VALIDATION_MESSAGE\": {\n               \"required\":
    \"Host URL cannot be empty\",\n               \"invalidUrl\": \"URL is invalid\"\n
    \           }\n         },\n         \"URL\": {\n            \"TOOLTIP\": \"GitHub
    Api URL to access resources such as accounts & repositories through API calls.\",\n
    \           \"VALIDATION_MESSAGE\": {\n               \"required\": \"API URL cannot
    be empty\",\n               \"invalidUrl\": \"URL is invalid\"\n            }\n
    \        },\n         \"TOKEN\": {\n            \"TOOLTIP\": \"GitHub Personal Access
    Token. You can generate token (settings -> Developer Settings -> Personal access
    tokens -> generate new Token)\",\n            \"VALIDATION_MESSAGE\": {\n               \"required\":
    \"Token cannot be empty\"\n            }\n         },\n         \"USERNAME\": {\n
    \           \"TOOLTIP\": \"GitHub User Name\",\n            \"VALIDATION_MESSAGE\":
    {\n               \"noSpecialCharacters\": \"User Name cannot contain special characters
    other than - and _\",\n               \"cannotContainSpace\": \"User Name cannot
    contain space\",\n               \"required\": \"User Name cannot be empty\",\n
    \              \"startingFromNumber\": \"User Name cannot start with numbers\"\n
    \           }\n         },\n         \"SPINNAKERTOGGLE\": {\n            \"TOOLTIP\":
    \"\",\n            \"VALIDATION_MESSAGE\": {}\n         }\n      },\n      \"BAMBOO\":
    {\n         \"HEADER\": \"Bamboo CI\",\n         \"BODY\": \" <span><p>Bamboo CI
    integration can be used as a datasource for Approval Gate.</p><p><strong>Fields</strong>:</p><ul
    class='helpTextUl'> <li><strong>Name</strong>: User defined name for the Bamboo
    CI Account <span class='noBr'>(Example: opsmx-bamboo)</span></li><li><strong>Endpoint</strong>:
    Bamboo CI URL <span class='noBr'>(Example: https://xyz.mybamboo.com)</span></li><li><strong>Token</strong>:
    Bamboo CI personal access token. You can find <a href='https://confluence.atlassian.com/bamboo/personal-access-tokens-976779873.html'
    target='_blank'>here</a> how to generate personal access tokens. <span>(Example:
    YmFrwqw0w9r90skfsOk9wcdd014p98kklw==)</span></li><li><strong>User Name</strong>:
    Bamboo CI User Name</li><li><strong>Password</strong>: Bamboo CI Password</li><li><strong>Permissions</strong>:
    Enable/disable access to the Bamboo CI account in Autopilot to specific usergroups</li></ul></span>\",\n
    \        \"ACCOUNTNAME\": {\n            \"TOOLTIP\": \"User defined name for the
    Bamboo CI account\",\n            \"VALIDATION_MESSAGE\": {\n               \"noSpecialCharacters\":
    \"Account Name cannot contain special characters other than -\",\n               \"cannotContainSpace\":
    \"Account Name cannot contain space\",\n               \"required\": \"Account Name
    cannot be empty\",\n               \"startingFromNumber\": \"Account Name cannot
    start with numbers\"\n            }\n         },\n         \"ENDPOINT\": {\n            \"TOOLTIP\":
    \"Bamboo CI URL\",\n            \"VALIDATION_MESSAGE\": {\n               \"required\":
    \"Bamboo End Point cannot be empty\",\n               \"invalidUrl\": \"URL is invalid\"\n
    \           }\n         },\n         \"AUTHENTICATIONTYPE\": {\n            \"TOOLTIP\":
    \"can be Token or User Name/Password\",\n            \"VALIDATION_MESSAGE\": {}\n
    \        },\n         \"TOKEN\": {\n            \"TOOLTIP\": \"Bamboo CI personal
    access token\",\n            \"VALIDATION_MESSAGE\": {\n               \"required\":
    \"Token cannot be empty\"\n            }\n         },\n         \"USERNAME\": {\n
    \           \"TOOLTIP\": \"Bamboo CI User Name\",\n            \"VALIDATION_MESSAGE\":
    {\n               \"noSpecialCharacters\": \"User Name cannot contain special characters
    other than - and _\",\n               \"cannotContainSpace\": \"User Name cannot
    contain space\",\n               \"required\": \"User Name cannot be empty\",\n
    \              \"startingFromNumber\": \"User Name cannot start with numbers\"\n
    \           }\n         },\n         \"PASSWORD\": {\n            \"TOOLTIP\": \"Bamboo
    CI Password\",\n            \"VALIDATION_MESSAGE\": {\n               \"required\":
    \"Password cannot be empty\"\n            }\n         }\n      },\n      \"JENKINS\":
    {\n         \"HEADER\": \"Jenkins\",\n         \"BODY\": \"<span><p>Jenkins integration
    can be used as a datasource for Approval Gate as well as to configure Spinnaker
    for Jenkins.</p><p><strong>Fields</strong>:</p><ul class='helpTextUl'><li><strong>Account
    Name</strong>: User defined name for the Jenkins Account <span class='noBr'>(Example:
    opsmx-jenkins)</span></li><li><strong>Host URL</strong>: Jenkins URL <span class='noBr'>(Example:
    https://xyz.my-jenkins.com/jenkins)</span></li><li><strong>Authentication Type</strong>:
    can be Token or User Name/Password    </li><li><strong>Token</strong>: Jenkins personal
    access token. You can find <a href='https://www.jenkins.io/doc/book/using/using-credentials/'
    target='_blank'>here</a> how to generate personal access tokens. <span>(Example:
    77d67609a841b1811a114b7fbfa109b3c2)</span></li><li><strong>User Name</strong>: Jenkins
    User Name</li><li><strong>Password</strong>: Jenkins Password</li><li><strong>Connect
    to Spinnaker</strong>: Toggle to configure Spinnaker for Jenkins</li><li><strong>Permissions</strong>:
    Enable/disable access to the Jenkins account in Autopilot to specific usergroups</li></ul></span>\",\n
    \        \"ACCOUNTNAME\": {\n            \"TOOLTIP\": \"User defined name for the
    Jenkins account\",\n            \"VALIDATION_MESSAGE\": {\n               \"noSpecialCharacters\":
    \"Account Name cannot contain special characters other than -\",\n               \"cannotContainSpace\":
    \"Account Name cannot contain space\",\n               \"required\": \"Account Name
    cannot be empty\",\n               \"startingFromNumber\": \"Account Name cannot
    start with numbers\"\n            }\n         },\n         \"HOSTURL\": {\n            \"TOOLTIP\":
    \"Jenkins URL\",\n            \"VALIDATION_MESSAGE\": {\n               \"required\":
    \"Host URL cannot be empty\",\n               \"invalidUrl\": \"URL is invalid\"\n
    \           }\n         },\n         \"AUTHENTICATIONTYPE\": {\n            \"TOOLTIP\":
    \"can be Token or User Name/Password\",\n            \"VALIDATION_MESSAGE\": {}\n
    \        },\n         \"TOKEN\": {\n            \"TOOLTIP\": \"Jenkins personal
    access token\",\n            \"VALIDATION_MESSAGE\": {\n               \"required\":
    \"Token cannot be empty\"\n            }\n         },\n         \"USERNAME\": {\n
    \           \"TOOLTIP\": \"Jenkins User Name\",\n            \"VALIDATION_MESSAGE\":
    {\n               \"noSpecialCharacters\": \"User Name cannot contain special characters
    other than - and _\",\n               \"cannotContainSpace\": \"User Name cannot
    contain space\",\n               \"required\": \"User Name cannot be empty\",\n
    \              \"startingFromNumber\": \"User Name cannot start with numbers\"\n
    \           }\n         },\n         \"PASSWORD\": {\n            \"TOOLTIP\": \"Jenkins
    Password\",\n            \"VALIDATION_MESSAGE\": {\n               \"required\":
    \"Password cannot be empty\"\n            }\n         },\n         \"SPINNAKERTOGGLE\":
    {\n            \"TOOLTIP\": \"\",\n            \"VALIDATION_MESSAGE\": {}\n         }\n
    \     },\n      \"JIRA\": {\n         \"HEADER\": \"Jira\",\n         \"BODY\":
    \"\",\n         \"ACCOUNTNAME\": {\n            \"TOOLTIP\": \"User defined name
    for the Jira account\",\n            \"VALIDATION_MESSAGE\": {\n               \"noSpecialCharacters\":
    \"Account Name cannot contain special characters other than -\",\n               \"cannotContainSpace\":
    \"Account Name cannot contain space\",\n               \"required\": \"Account Name
    cannot be empty\",\n               \"startingFromNumber\": \"Account Name cannot
    start with numbers\"\n            }\n         },\n         \"EMAIL\": {\n            \"TOOLTIP\":
    \"Jira Email Id\",\n            \"VALIDATION_MESSAGE\": {\n               \"email\":
    \"Email Id is invalid\",\n               \"required\": \"Email Id cannot be empty\"\n
    \           }\n         },\n         \"TOKEN\": {\n            \"TOOLTIP\": \"Jira
    Personal Access Token\",\n            \"VALIDATION_MESSAGE\": {\n               \"required\":
    \"Token cannot be empty\"\n            }\n         },\n         \"HOSTURL\": {\n
    \           \"TOOLTIP\": \"Jira Host URL\",\n            \"VALIDATION_MESSAGE\":
    {\n               \"required\": \"Host URL cannot be empty\",\n               \"invalidUrl\":
    \"URL is invalid\"\n            }\n         },\n         \"SPINNAKERTOGGLE\": {\n
    \           \"TOOLTIP\": \"\",\n            \"VALIDATION_MESSAGE\": {}\n         }\n
    \     },\n      \"SERVICENOW\": {\n         \"HEADER\": \"Service Now\",\n         \"BODY\":
    \"\",\n         \"ACCOUNTNAME\": {\n            \"TOOLTIP\": \"User defined name
    for the Service Now account\",\n            \"VALIDATION_MESSAGE\": {\n               \"noSpecialCharacters\":
    \"Account Name cannot contain special characters other than -\",\n               \"cannotContainSpace\":
    \"Account Name cannot contain space\",\n               \"required\": \"Account Name
    cannot be empty\",\n               \"startingFromNumber\": \"Account Name cannot
    start with numbers\"\n            }\n         },\n         \"USERNAME\": {\n            \"TOOLTIP\":
    \"Service Now User Name\",\n            \"VALIDATION_MESSAGE\": {\n               \"noSpecialCharacters\":
    \"User Name cannot contain special characters other than - and _\",\n               \"cannotContainSpace\":
    \"User Name cannot contain space\",\n               \"required\": \"User Name cannot
    be empty\",\n               \"startingFromNumber\": \"User Name cannot start with
    numbers\"\n            }\n         },\n         \"PASSWORD\": {\n            \"TOOLTIP\":
    \"Service Now Password\",\n            \"VALIDATION_MESSAGE\": {\n               \"required\":
    \"Password cannot be empty\"\n            }\n         },\n         \"HOSTURL\":
    {\n            \"TOOLTIP\": \"Service Now Host URL\",\n            \"VALIDATION_MESSAGE\":
    {\n               \"required\": \"Host URL cannot be empty\",\n               \"invalidUrl\":
    \"URL is invalid\"\n            }\n         }\n      },\n      \"APPDYNAMICS\":
    {\n         \"HEADER\": \"APPDYNAMICS\",\n         \"BODY\": \"\",\n         \"ACCOUNTNAME\":
    {\n            \"TOOLTIP\": \"User defined name for the APPDYNAMICS account\",\n
    \           \"VALIDATION_MESSAGE\": {\n               \"noSpecialCharacters\": \"Account
    Name cannot contain special characters other than -\",\n               \"cannotContainSpace\":
    \"Account Name cannot contain space\",\n               \"required\": \"Account Name
    cannot be empty\",\n               \"startingFromNumber\": \"Account Name cannot
    start with numbers\"\n            }\n         },\n         \"CONTROLLERHOST\": {\n
    \           \"TOOLTIP\": \"APPDYNAMICS Controller Host\",\n            \"VALIDATION_MESSAGE\":
    {\n               \"required\": \"Controller Host  cannot be empty\",\n               \"invalidUrl\":
    \"URL is invalid\"\n            }\n         },\n         \"TEMPORARYACCESSTOKEN\":
    {\n            \"TOOLTIP\": \"APPDYNAMICS Personal Temporary Access Token\",\n            \"VALIDATION_MESSAGE\":
    {\n               \"required\": \"Temporary Access Token cannot be empty\"\n            }\n
    \        }\n      },\n      \"CLOUDWATCH\": {\n         \"HEADER\": \"AWS-CLOUDWATCH\",\n
    \        \"BODY\": \"\",\n         \"ACCOUNTNAME\": {\n            \"TOOLTIP\":
    \"User defined name for the AWS-CLOUDWATCH account\",\n            \"VALIDATION_MESSAGE\":
    {\n               \"noSpecialCharacters\": \"Account Name cannot contain special
    characters other than -\",\n               \"cannotContainSpace\": \"Account Name
    cannot contain space\",\n               \"required\": \"Account Name cannot be empty\",\n
    \              \"startingFromNumber\": \"Account Name cannot start with numbers\"\n
    \           }\n         },\n         \"ACCESS_ID\": {\n            \"TOOLTIP\":
    \"AWS-CLOUDWATCH Access Key Id\",\n            \"VALIDATION_MESSAGE\": {\n               \"required\":
    \"Access Key Id cannot be empty\"\n            }\n         },\n         \"SECRET_KEY\":
    {\n            \"TOOLTIP\": \"AWS-CLOUDWATCH Secret Access Key\",\n            \"VALIDATION_MESSAGE\":
    {\n               \"required\": \"Secret Access Key cannot be empty\"\n            }\n
    \        }\n      },\n      \"DATADOG\": {\n         \"HEADER\": \"DATADOG\",\n
    \        \"BODY\": \"\",\n         \"ACCOUNTNAME\": {\n            \"TOOLTIP\":
    \"User defined name for the DATADOG account\",\n            \"VALIDATION_MESSAGE\":
    {\n               \"noSpecialCharacters\": \"Account Name cannot contain special
    characters other than -\",\n               \"cannotContainSpace\": \"Account Name
    cannot contain space\",\n               \"required\": \"Account Name cannot be empty\",\n
    \              \"startingFromNumber\": \"Account Name cannot start with numbers\"\n
    \           }\n         },\n         \"API_KEY\": {\n            \"TOOLTIP\": \"DATADOG
    Api Key\",\n            \"VALIDATION_MESSAGE\": {\n               \"required\":
    \"Application Key cannot be empty\"\n            }\n         },\n         \"APPLICATION_KEY\":
    {\n            \"TOOLTIP\": \"DATADOG Application Key\",\n            \"VALIDATION_MESSAGE\":
    {\n               \"required\": \"Application Key cannot be empty\"\n            }\n
    \        }\n      },\n      \"DYNATRACE\": {\n         \"HEADER\": \"Dynatrace\",\n
    \        \"BODY\": \"\",\n         \"ACCOUNTNAME\": {\n            \"TOOLTIP\":
    \"User defined name for the Dynatrace account\",\n            \"VALIDATION_MESSAGE\":
    {\n               \"noSpecialCharacters\": \"Account Name cannot contain special
    characters other than -\",\n               \"cannotContainSpace\": \"Account Name
    cannot contain space\",\n               \"required\": \"Account Name cannot be empty\",\n
    \              \"startingFromNumber\": \"Account Name cannot start with numbers\"\n
    \           }\n         },\n         \"END_POINT\": {\n            \"TOOLTIP\":
    \"Dynatrace URL\",\n            \"VALIDATION_MESSAGE\": {\n               \"required\":
    \"Url cannot be empty\",\n               \"invalidUrl\": \"URL is invalid\"\n            }\n
    \        },\n         \"API_TOKEN\": {\n            \"TOOLTIP\": \"Dynatrace Personal
    Access Token\",\n            \"VALIDATION_MESSAGE\": {\n               \"required\":
    \"Api Token cannot be empty\"\n            }\n         }\n      },\n      \"ELASTICSEARCH\":
    {\n         \"HEADER\": \"Elasticsearch\",\n         \"BODY\": \"\",\n         \"ACCOUNTNAME\":
    {\n            \"TOOLTIP\": \"User defined name for the Elasticsearch account\",\n
    \           \"VALIDATION_MESSAGE\": {\n               \"noSpecialCharacters\": \"Account
    Name cannot contain special characters other than -\",\n               \"cannotContainSpace\":
    \"Account Name cannot contain space\",\n               \"required\": \"Account Name
    cannot be empty\",\n               \"startingFromNumber\": \"Account Name cannot
    start with numbers\"\n            }\n         },\n         \"ENDPOINT\": {\n            \"TOOLTIP\":
    \"ElasticSearch End Point\",\n            \"VALIDATION_MESSAGE\": {\n               \"required\":
    \"Elastic End Point cannot be empty\",\n               \"invalidUrl\": \"URL is
    invalid\"\n            }\n         },\n         \"USERNAME\": {\n            \"TOOLTIP\":
    \"ElasticSearch User Name\",\n            \"VALIDATION_MESSAGE\": {\n               \"noSpecialCharacters\":
    \"User Name cannot contain special characters other than - and _\",\n               \"cannotContainSpace\":
    \"User Name cannot contain space\",\n               \"startingFromNumber\": \"User
    Name cannot start with numbers\"\n            }\n         },\n         \"PASSWORD\":
    {\n            \"TOOLTIP\": \"ElasticSearch Password\",\n            \"VALIDATION_MESSAGE\":
    {\n               \"required\": \"Password cannot be empty\"\n            }\n         },\n
    \        \"KIBANAENDPOINT\": {\n            \"TOOLTIP\": \"ElasticSearch Kibana
    End Point\",\n            \"VALIDATION_MESSAGE\": {\n               \"required\":
    \"Kibana End Point cannot be empty\",\n               \"invalidUrl\": \"URL is invalid\"\n
    \           }\n         },\n         \"KIBANAUSERNAME\": {\n            \"TOOLTIP\":
    \"ElasticSearch Kibana User Name\",\n            \"VALIDATION_MESSAGE\": {\n               \"noSpecialCharacters\":
    \"Kibana User Name cannot contain special characters other than - and _\",\n               \"cannotContainSpace\":
    \"Kibana User Name cannot contain space\",\n               \"required\": \"Kibana
    User Name cannot be empty\",\n               \"startingFromNumber\": \"Kibana User
    Name cannot start with numbers\"\n            }\n         },\n         \"KIBANAPASSWORD\":
    {\n            \"TOOLTIP\": \"ElasticSearch Kibana Password\",\n            \"VALIDATION_MESSAGE\":
    {\n               \"required\": \"Kibana Password cannot be empty\"\n            }\n
    \        }\n      },\n      \"GRAPHITE\": {\n         \"HEADER\": \"Graphite\",\n
    \        \"BODY\": \"\",\n         \"ACCOUNTNAME\": {\n            \"TOOLTIP\":
    \"User defined name for the Graphite account\",\n            \"VALIDATION_MESSAGE\":
    {\n               \"noSpecialCharacters\": \"Account Name cannot contain special
    characters other than -\",\n               \"cannotContainSpace\": \"Account Name
    cannot contain space\",\n               \"required\": \"Account Name cannot be empty\",\n
    \              \"startingFromNumber\": \"Account Name cannot start with numbers\"\n
    \           }\n         },\n         \"URL\": {\n            \"TOOLTIP\": \"Graphite
    End Point\",\n            \"VALIDATION_MESSAGE\": {\n               \"required\":
    \"End Point cannot be empty\",\n               \"invalidUrl\": \"URL is invalid\"\n
    \           }\n         }\n      },\n      \"GRAYLOG\": {\n         \"HEADER\":
    \"GRAYLOG\",\n         \"BODY\": \"\",\n         \"ACCOUNTNAME\": {\n            \"TOOLTIP\":
    \"User defined name for the GRAYLOG account\",\n            \"VALIDATION_MESSAGE\":
    {\n               \"noSpecialCharacters\": \"Account Name cannot contain special
    characters other than -\",\n               \"cannotContainSpace\": \"Account Name
    cannot contain space\",\n               \"required\": \"Account Name cannot be empty\",\n
    \              \"startingFromNumber\": \"Account Name cannot start with numbers\"\n
    \           }\n         },\n         \"ENDPOINT\": {\n            \"TOOLTIP\": \"GrayLog
    End Point\",\n            \"VALIDATION_MESSAGE\": {\n               \"required\":
    \"End Point cannot be empty\",\n               \"invalidUrl\": \"URL is invalid\"\n
    \           }\n         },\n         \"TOKEN\": {\n            \"TOOLTIP\": \"GrayLog
    Personal Access Token\",\n            \"VALIDATION_MESSAGE\": {\n               \"required\":
    \"Token cannot be empty\"\n            }\n         }\n      },\n      \"NEWRELIC\":
    {\n         \"HEADER\": \"New Relic\",\n         \"BODY\": \"\",\n         \"ACCOUNTNAME\":
    {\n            \"TOOLTIP\": \"User defined name for the New Relic account\",\n            \"VALIDATION_MESSAGE\":
    {\n               \"noSpecialCharacters\": \"Account Name cannot contain special
    characters other than -\",\n               \"cannotContainSpace\": \"Account Name
    cannot contain space\",\n               \"required\": \"Account Name cannot be empty\",\n
    \              \"startingFromNumber\": \"Account Name cannot start with numbers\"\n
    \           }\n         },\n         \"APIKEY\": {\n            \"TOOLTIP\": \"NewRelic
    Api Key\",\n            \"VALIDATION_MESSAGE\": {\n               \"required\":
    \"Token cannot be empty\"\n            }\n         },\n         \"APPLICATIONKEY\":
    {\n            \"TOOLTIP\": \"NewRelic Application Key\",\n            \"VALIDATION_MESSAGE\":
    {\n               \"required\": \"Token cannot be empty\"\n            }\n         },\n
    \        \"ACCOUNTID\": {\n            \"TOOLTIP\": \"NewRelic Account Id\",\n            \"VALIDATION_MESSAGE\":
    {\n               \"required\": \"Token cannot be empty\"\n            }\n         },\n
    \        \"QUERYKEY\": {\n            \"TOOLTIP\": \"NewRelic Query Key\",\n            \"VALIDATION_MESSAGE\":
    {\n               \"required\": \"Token cannot be empty\"\n            }\n         }\n
    \     },\n      \"PROMETHEUS\": {\n         \"HEADER\": \"Prometheus\",\n         \"BODY\":
    \"\",\n         \"ACCOUNTNAME\": {\n            \"TOOLTIP\": \"User defined name
    for the Prometheus account\",\n            \"VALIDATION_MESSAGE\": {\n               \"noSpecialCharacters\":
    \"Account Name cannot contain special characters other than -\",\n               \"cannotContainSpace\":
    \"Account Name cannot contain space\",\n               \"required\": \"Account Name
    cannot be empty\",\n               \"startingFromNumber\": \"Account Name cannot
    start with numbers\"\n            }\n         },\n         \"ENDPOINT\": {\n            \"TOOLTIP\":
    \"Prometheus End Point\",\n            \"VALIDATION_MESSAGE\": {\n               \"required\":
    \"End Point cannot be empty\",\n               \"invalidUrl\": \"URL is invalid\"\n
    \           }\n         },\n         \"USERNAME\": {\n            \"TOOLTIP\": \"Prometheus
    User Name\",\n            \"VALIDATION_MESSAGE\": {\n               \"noSpecialCharacters\":
    \"User Name cannot contain special characters other than - and _\",\n               \"cannotContainSpace\":
    \"User Name cannot contain space\",\n               \"required\": \"User Name cannot
    be empty\",\n               \"startingFromNumber\": \"User Name cannot start with
    numbers\"\n            }\n         },\n         \"PASSWORD\": {\n            \"TOOLTIP\":
    \"Prometheus Password\",\n            \"VALIDATION_MESSAGE\": {\n               \"required\":
    \"Password cannot be empty\"\n            }\n         }\n      },\n      \"SPLUNK\":
    {\n         \"HEADER\": \"Splunk\",\n         \"BODY\": \"\",\n         \"ACCOUNTNAME\":
    {\n            \"TOOLTIP\": \"User defined name for the Splunk account\",\n            \"VALIDATION_MESSAGE\":
    {\n               \"noSpecialCharacters\": \"Account Name cannot contain special
    characters other than -\",\n               \"cannotContainSpace\": \"Account Name
    cannot contain space\",\n               \"required\": \"Account Name cannot be empty\",\n
    \              \"startingFromNumber\": \"Account Name cannot start with numbers\"\n
    \           }\n         },\n         \"END_POINT\": {\n            \"TOOLTIP\":
    \"Splunk Splunk URL\",\n            \"VALIDATION_MESSAGE\": {\n               \"required\":
    \"Splunk Url  cannot be empty\",\n               \"invalidUrl\": \"URL is invalid\"\n
    \           }\n         },\n         \"PASSWORD\": {\n            \"TOOLTIP\": \"Splunk
    Password\",\n            \"VALIDATION_MESSAGE\": {\n               \"required\":
    \"Password cannot be empty\"\n            }\n         },\n         \"USER_NAME\":
    {\n            \"TOOLTIP\": \"Splunk User Name\",\n            \"VALIDATION_MESSAGE\":
    {\n               \"noSpecialCharacters\": \"Account Name cannot contain special
    characters other than -\",\n               \"cannotContainSpace\": \"Account Name
    cannot contain space\",\n               \"required\": \"Account Name cannot be empty\",\n
    \              \"startingFromNumber\": \"Account Name cannot start with numbers\"\n
    \           }\n         },\n         \"DASHBOARD_ENDPOINT\": {\n            \"TOOLTIP\":
    \"Splunk DashBoard URL\",\n            \"VALIDATION_MESSAGE\": {\n               \"required\":
    \"Splunk DashBoard Url cannot be empty\",\n               \"invalidUrl\": \"URL
    is invalid\"\n            }\n         }\n      },\n      \"STACKDRIVER\": {\n         \"HEADER\":
    \"Stackdriver\",\n         \"BODY\": \"\",\n         \"ACCOUNTNAME\": {\n            \"TOOLTIP\":
    \"User defined name for the Stackdriver account\",\n            \"VALIDATION_MESSAGE\":
    {\n               \"noSpecialCharacters\": \"Account Name cannot contain special
    characters other than -\",\n               \"cannotContainSpace\": \"Account Name
    cannot contain space\",\n               \"required\": \"Account Name cannot be empty\",\n
    \              \"startingFromNumber\": \"Account Name cannot start with numbers\"\n
    \           }\n         },\n         \"KEY_FILE\": {\n            \"TOOLTIP\": \"Stackdriver
    Encrypted Key file\",\n            \"VALIDATION_MESSAGE\": {\n               \"required\":
    \"Encrypted Key File cannot be empty\"\n            }\n         }\n      },\n      \"SUMOLOGIC\":
    {\n         \"HEADER\": \"Sumo Logic\",\n         \"BODY\": \"\",\n         \"ACCOUNTNAME\":
    {\n            \"TOOLTIP\": \"User defined name for the Sumologic account\",\n            \"VALIDATION_MESSAGE\":
    {\n               \"noSpecialCharacters\": \"Account Name cannot contain special
    characters other than -\",\n               \"cannotContainSpace\": \"Account Name
    cannot contain space\",\n               \"required\": \"Account Name cannot be empty\",\n
    \              \"startingFromNumber\": \"Account Name cannot start with numbers\"\n
    \           }\n         },\n         \"ACCESSID\": {\n            \"TOOLTIP\": \"sumologic
    Access Id. You can generate Access Id (Administration > Security > Access Keys)\",\n
    \           \"VALIDATION_MESSAGE\": {\n               \"required\": \"Access Id
    cannot be empty\"\n            }\n         },\n         \"ACCESSKEY\": {\n            \"TOOLTIP\":
    \"sumologic Access Key. You can generate Access Id (Administration > Security >
    Access Keys)\",\n            \"VALIDATION_MEeSSAGE\": {\n               \"required\":
    \"Access Key cannot be empty\"\n            }\n         },\n         \"ZONE\": {\n
    \           \"TOOLTIP\": \"sumologic Zone\",\n            \"VALIDATION_MESSAGE\":
    {\n               \"noSpecialCharacters\": \"Zone cannot contain special characters
    other than -\",\n               \"cannotContainSpace\": \"Zone cannot contain space\",\n
    \              \"required\": \"Zone cannot be empty\",\n               \"startingFromNumber\":
    \"Zone cannot start with numbers\"\n            }\n         }\n      },\n    \"VMWARETANZU\":{\n
    \     \"HEADER\": \"VMWare Tanzu Observability\",\n      \"BODY\":\"\",\n      \"ACCOUNTNAME\":{\n
    \       \"TOOLTIP\":\"User defined name for the VMWare Tanzu Observability account\",\n
    \       \"VALIDATION_MESSAGE\":{\n      \"noSpecialCharacters\": \"Account Name
    cannot contain special characters other than -\",\n      \"cannotContainSpace\":\"Account
    Name cannot contain space\",\n      \"required\":\"Account Name cannot be empty\",\n
    \     \"startingFromNumber\": \"Account Name cannot start with numbers\"\n    }\n
    \     },\n       \"END_POINT\":{\n        \"TOOLTIP\":\"VMWare Tanzu Observability
    URL\",\n        \"VALIDATION_MESSAGE\":{\n          \"required\":\"Url cannot be
    empty\",\n          \"invalidUrl\": \"URL is invalid\"\n        }\n      },\n      \"EMAIL\":{\n
    \       \"TOOLTIP\":\"VMWare Tanzu Observability Email Id\",\n        \"VALIDATION_MESSAGE\":{\n
    \         \"email\":\"Email Id is invalid\",\n          \"required\":\"Email Id
    cannot be empty\"\n        }\n      },\n      \"API_TOKEN\":{\n        \"TOOLTIP\":\"VMWare
    Tanzu Observability Personal Access Token\",\n        \"VALIDATION_MESSAGE\":{\n
    \         \"required\":\"Api Token cannot be empty\"\n        }\n      }\n    },\n
    \     \"MSTEAMS\": {\n         \"HEADER\": \"Microsoft Teams\",\n         \"BODY\":
    \"\"\n      },\n      \"SLACK\": {\n         \"HEADER\": \"Slack\",\n         \"BODY\":
    \"\",\n         \"ACCOUNTNAME\": {\n            \"TOOLTIP\": \"User defined name
    for the Slack account\",\n            \"VALIDATION_MESSAGE\": {\n               \"noSpecialCharacters\":
    \"Account Name cannot contain special characters other than -\",\n               \"cannotContainSpace\":
    \"Account Name cannot contain space\",\n               \"required\": \"Account Name
    cannot be empty\",\n               \"startingFromNumber\": \"Account Name cannot
    start with numbers\"\n            }\n         },\n         \"BOTNAME\": {\n            \"TOOLTIP\":
    \"Slack Bot Name\",\n            \"VALIDATION_MESSAGE\": {\n               \"noSpecialCharacters\":
    \"Bot Name cannot contain special characters other than -\",\n               \"cannotContainSpace\":
    \"Bot Name cannot contain space\",\n               \"required\": \"Bot Name cannot
    be empty\",\n               \"startingFromNumber\": \"Bot Name cannot start with
    numbers\"\n            }\n         },\n         \"TOKEN\": {\n            \"TOOLTIP\":
    \"Slack Personal Access Token\",\n            \"VALIDATION_MESSAGE\": {\n               \"required\":
    \"Token cannot be empty\"\n            }\n         },\n         \"SPINNAKERTOGGLE\":
    {\n            \"TOOLTIP\": \"\",\n            \"VALIDATION_MESSAGE\": {}\n         }\n
    \     },\n      \"OPA\": {\n         \"HEADER\": \"OPA\",\n         \"BODY\": \"\",\n
    \        \"ACCOUNTNAME\": {\n            \"TOOLTIP\": \"User defined name for the
    OPA account\",\n            \"VALIDATION_MESSAGE\": {\n               \"noSpecialCharacters\":
    \"Account Name cannot contain special characters other than -\",\n               \"cannotContainSpace\":
    \"Account Name cannot contain space\",\n               \"required\": \"Account Name
    cannot be empty\",\n               \"startingFromNumber\": \"Account Name cannot
    start with numbers\"\n            }\n         },\n         \"ENDPOINT\": {\n            \"TOOLTIP\":
    \"OPA End Point\",\n            \"VALIDATION_MESSAGE\": {\n               \"required\":
    \"End Point cannot be empty\",\n               \"invalidUrl\": \"URL is invalid\"\n
    \           }\n         }\n      },\n      \"AQUAWAVE\": {\n         \"HEADER\":
    \"Aqua Wave\",\n         \"BODY\": \"\",\n         \"ACCOUNTNAME\": {\n            \"TOOLTIP\":
    \"User defined name for the Aqua Wave account\",\n            \"VALIDATION_MESSAGE\":
    {\n               \"noSpecialCharacters\": \"Account Name cannot contain special
    characters other than -\",\n               \"cannotContainSpace\": \"Account Name
    cannot contain space\",\n               \"required\": \"Account Name cannot be empty\",\n
    \              \"startingFromNumber\": \"Account Name cannot start with numbers\"\n
    \           }\n         },\n         \"USERNAME\": {\n            \"TOOLTIP\": \"Aqua
    Wave User Name\",\n            \"VALIDATION_MESSAGE\": {\n               \"noSpecialCharacters\":
    \"User Name cannot contain special characters other than - and _\",\n               \"cannotContainSpace\":
    \"User Name cannot contain space\",\n               \"required\": \"User Name cannot
    be empty\",\n               \"startingFromNumber\": \"User Name cannot start with
    numbers\"\n            }\n         },\n         \"TOKEN\": {\n            \"TOOLTIP\":
    \"Aqua Wave Personal Access Token\",\n            \"VALIDATION_MESSAGE\": {\n               \"required\":
    \"Token cannot be empty\"\n            }\n         }\n      },\n      \"APPSCAN\":
    {\n         \"HEADER\": \"HCL AppScan\",\n         \"BODY\": \"\",\n         \"ACCOUNTNAME\":
    {\n            \"TOOLTIP\": \"User defined name for the HCL AppScan account\",\n
    \           \"VALIDATION_MESSAGE\": {\n               \"noSpecialCharacters\": \"Account
    Name cannot contain special characters other than -\",\n               \"cannotContainSpace\":
    \"Account Name cannot contain space\",\n               \"required\": \"Account Name
    cannot be empty\",\n               \"startingFromNumber\": \"Account Name cannot
    start with numbers\"\n            }\n         },\n         \"TOKEN\": {\n            \"TOOLTIP\":
    \"Appscan Personal Access Token\",\n            \"VALIDATION_MESSAGE\": {\n               \"required\":
    \"Token cannot be empty\"\n            }\n         }\n      },\n      \"JFROG\":
    {\n         \"HEADER\": \"JFrog XRay Scanning\",\n         \"BODY\": \"\",\n         \"ACCOUNTNAME\":
    {\n            \"TOOLTIP\": \"User defined name for the JFrog XRay Scanning account\",\n
    \           \"VALIDATION_MESSAGE\": {\n               \"noSpecialCharacters\": \"Account
    Name cannot contain special characters other than -\",\n               \"cannotContainSpace\":
    \"Account Name cannot contain space\",\n               \"required\": \"Account Name
    cannot be empty\",\n               \"startingFromNumber\": \"Account Name cannot
    start with numbers\"\n            }\n         },\n         \"ENDPOINT\": {\n            \"TOOLTIP\":
    \"JFrog URL\",\n            \"VALIDATION_MESSAGE\": {\n               \"required\":
    \"Endpoint cannot be empty\",\n               \"invalidUrl\": \"URL is invalid\"\n
    \           }\n         },\n         \"TOKEN\": {\n            \"TOOLTIP\": \"JFrog
    Personal Access Token\",\n            \"VALIDATION_MESSAGE\": {\n               \"required\":
    \"Token cannot be empty\"\n            }\n         }\n      },\n      \"PRISMACLOUD\":
    {\n         \"HEADER\": \"Prisma Cloud\",\n         \"BODY\": \"\",\n         \"ACCOUNTNAME\":
    {\n            \"TOOLTIP\": \"User defined name for the Prisma Cloud account\",\n
    \           \"VALIDATION_MESSAGE\": {\n               \"noSpecialCharacters\": \"Account
    Name cannot contain special characters other than -\",\n               \"cannotContainSpace\":
    \"Account Name cannot contain space\",\n               \"required\": \"Account Name
    cannot be empty\",\n               \"startingFromNumber\": \"Account Name cannot
    start with numbers\"\n            }\n         },\n         \"HOSTURL\": {\n            \"TOOLTIP\":
    \"Prisma Cloud Host URL\",\n            \"VALIDATION_MESSAGE\": {\n               \"required\":
    \"Host URL cannot be empty\",\n               \"invalidUrl\": \"URL is invalid\"\n
    \           }\n         },\n         \"APPLICATIONURL\": {\n            \"TOOLTIP\":
    \"Prisma Cloud Application URL\",\n            \"VALIDATION_MESSAGE\": {\n               \"required\":
    \"Application URL cannot be empty\",\n               \"invalidUrl\": \"URL is invalid\"\n
    \           }\n         },\n         \"ACCESSKEYID\": {\n            \"TOOLTIP\":
    \"Prisma Cloud Access Key Id\",\n            \"VALIDATION_MESSAGE\": {\n               \"required\":
    \"Access Key Id cannot be empty\"\n            }\n         },\n         \"SECRETKEY\":
    {\n            \"TOOLTIP\": \"Prisma Cloud Secret Key\",\n            \"VALIDATION_MESSAGE\":
    {\n               \"required\": \"Secret Key cannot be empty\"\n            }\n
    \        }\n      },\n      \"SONARQUBE\": {\n         \"HEADER\": \"SonarQube\",\n
    \        \"BODY\": \"\",\n         \"ACCOUNTNAME\": {\n            \"TOOLTIP\":
    \"User defined name for the SonarQube account\",\n            \"VALIDATION_MESSAGE\":
    {\n               \"noSpecialCharacters\": \"Account Name cannot contain special
    characters other than -\",\n               \"cannotContainSpace\": \"Account Name
    cannot contain space\",\n               \"required\": \"Account Name cannot be empty\",\n
    \              \"startingFromNumber\": \"Account Name cannot start with numbers\"\n
    \           }\n         },\n         \"HOSTURL\": {\n            \"TOOLTIP\": \"Sonarqube
    Host URL\",\n            \"VALIDATION_MESSAGE\": {\n               \"required\":
    \"Host URL cannot be empty\",\n               \"invalidUrl\": \"URL is invalid\"\n
    \           }\n         },\n         \"TOKEN\": {\n            \"TOOLTIP\": \"Sonarqube
    Personal Access Token\",\n            \"VALIDATION_MESSAGE\": {\n               \"required\":
    \"Token cannot be empty\"\n            }\n         }\n      },\n      \"AUTOPILOT\":
    {\n         \"HEADER\": \"Autopilot\",\n         \"BODY\": \"\",\n         \"ACCOUNTNAME\":
    {\n            \"TOOLTIP\": \"User defined name for the Autopilot account\",\n            \"VALIDATION_MESSAGE\":
    {\n               \"noSpecialCharacters\": \"Account Name cannot contain special
    characters other than -\",\n               \"cannotContainSpace\": \"Account Name
    cannot contain space\",\n               \"required\": \"Account Name cannot be empty\",\n
    \              \"startingFromNumber\": \"Account Name cannot start with numbers\"\n
    \           }\n         },\n         \"USERNAME\": {\n            \"TOOLTIP\": \"
    Autopilot User Name\",\n            \"VALIDATION_MESSAGE\": {\n               \"noSpecialCharacters\":
    \"User Name cannot contain special characters other than - and _\",\n               \"cannotContainSpace\":
    \"User Name cannot contain space\",\n               \"required\": \"User Name cannot
    be empty\",\n               \"startingFromNumber\": \"User Name cannot start with
    numbers\"\n            }\n         }\n      }\n   },\n   \"UNCHANGED_FORM\": \"Form
    is unchanged. Please make modifications in the form to enable the button.\",\n   \"INVALID_FORM\":
    \"Few fields are mandatory or invalid. Please fill the form to enable the button.\",\n
    \  \"NO_WRITE_ACCESS\": \"You have only read permission. Please check with your
    administrator for updating permissions.\",\n   \"METRIC_TEMPLATE\": {\n      \"APM_INFRA\":
    {\n         \"TEMPLATE_NAME\": {\n            \"TOOLTIP\": \"Metric Template Name\",\n
    \           \"VALIDATION_MESSAGE\": {\n               \"required\": \"Template Name
    cannot be empty\"\n            }\n         },\n         \"APM_MONITORING_PROVIDER\":
    {\n            \"TOOLTIP\": \"Data source for Risk Analysis\",\n            \"VALIDATION_MESSAGE\":
    {}\n         },\n         \"APM_ACCOUNT\": {\n            \"TOOLTIP\": \"APM Account\",\n
    \           \"VALIDATION_MESSAGE\": {}\n         },\n         \"APM_APPLICATION\":
    {\n            \"TOOLTIP\": \"APM Application\",\n            \"VALIDATION_MESSAGE\":
    {}\n         },\n         \"APM_API_SELECTION\": {\n            \"TOOLTIP\": \"APM
    API Selection\",\n            \"VALIDATION_MESSAGE\": {}\n         },\n         \"INFRA_MONITORING_PROVIDER\":
    {\n            \"TOOLTIP\": \"Data source for Risk Analysis\",\n            \"VALIDATION_MESSAGE\":
    {}\n         },\n         \"INFRA_ACCOUNT\": {\n            \"TOOLTIP\": \"Infrastructure
    Account\",\n            \"VALIDATION_MESSAGE\": {}\n         },\n         \"INFRA_METRIC_GROUPS\":
    {\n            \"TOOLTIP\": \"Infrastructure Metric Groups\",\n            \"VALIDATION_MESSAGE\":
    {}\n         },\n         \"FILTER_KEY\": {\n            \"TOOLTIP\": \"Filter Key\",\n
    \           \"VALIDATION_MESSAGE\": {\n               \"required\": \"Filter Key
    cannot be empty\"\n            }\n         },\n         \"BASELINE\": {\n            \"TOOLTIP\":
    \"Baseline\",\n            \"VALIDATION_MESSAGE\": {\n               \"required\":
    \"Baseline cannot be empty\"\n            }\n         },\n         \"NEW_RELEASE\":
    {\n            \"TOOLTIP\": \"New Release\",\n            \"VALIDATION_MESSAGE\":
    {\n               \"required\": \"New Release cannot be empty\"\n            }\n
    \        },\n         \"NORMALIZATION\": {\n            \"TOOLTIP\": \"Apply load
    based normalization\",\n            \"VALIDATION_MESSAGE\": {}\n         },\n         \"THRESHOLD\":
    {\n            \"TOOLTIP\": \"Threshold for Metric failure\",\n            \"VALIDATION_MESSAGE\":
    {}\n         },\n         \"SPECIFY_CRITICAL_WATCHLIST\": {\n            \"TOOLTIP\":
    \"Specify critical/watchlist for metrics\",\n            \"VALIDATION_MESSAGE\":
    {}\n         }\n      },\n      \"CUSTOM\": {\n         \"TEMPLATE_NAME\": {\n            \"TOOLTIP\":
    \"Template Name\",\n            \"VALIDATION_MESSAGE\": {\n               \"required\":
    \"Template Name cannot be empty\"\n            }\n         },\n         \"DATA_SOURCE\":
    {\n            \"TOOLTIP\": \"Data source for Risk Analysis\",\n            \"VALIDATION_MESSAGE\":
    {\n              \"required\":\"Data source cannot be empty\"\n           }\n         },\n
    \        \"ACCOUNT\": {\n            \"TOOLTIP\": \"Account\",\n            \"VALIDATION_MESSAGE\":
    {\n              \"required\":\"Account cannot be empty\"\n           }\n         },\n
    \        \"FILTER_KEY\": {\n            \"TOOLTIP\": \"Filter Key\",\n            \"VALIDATION_MESSAGE\":
    {\n               \"required\": \"Filter Key cannot be empty\"\n            }\n
    \        },\n         \"BASELINE\": {\n            \"TOOLTIP\": \"Baseline\",\n
    \           \"VALIDATION_MESSAGE\": {\n               \"required\": \"Baseline cannot
    be empty\"\n            }\n         },\n         \"NEW_RELEASE\": {\n            \"TOOLTIP\":
    \"New Release\",\n            \"VALIDATION_MESSAGE\": {\n               \"required\":
    \"New Release cannot be empty\"\n            }\n         },\n         \"ADD_NEW_QUERY\":
    {\n            \"TOOLTIP\": \"Add New Query\",\n            \"VALIDATION_MESSAGE\":
    {}\n         },\n         \"QUERY_SELECTION\": {\n            \"TOOLTIP\": \"Query
    Selection\",\n            \"VALIDATION_MESSAGE\": {}\n         },\n         \"QUERY_NAME\":
    {\n            \"TOOLTIP\": \"Query Name\",\n            \"VALIDATION_MESSAGE\":
    {\n               \"required\": \"Query Name cannot be empty\"\n            }\n
    \        },\n         \"QUERY_STRING\": {\n            \"TOOLTIP\": \"Query String\",\n
    \           \"VALIDATION_MESSAGE\": {\n               \"required\": \"Query String
    cannot be empty\"\n            }\n         },\n         \"RISK_DIRECTION\": {\n
    \           \"TOOLTIP\": \"Risk Direction\",\n            \"VALIDATION_MESSAGE\":
    {}\n         },\n         \"THRESHOLD\": {\n            \"TOOLTIP\": \"Threshold\",\n
    \           \"VALIDATION_MESSAGE\": {}\n         },\n         \"CRITICAL\": {\n
    \           \"TOOLTIP\": \"Critical\",\n            \"VALIDATION_MESSAGE\": {}\n
    \        },\n         \"WATCHLIST\": {\n            \"TOOLTIP\": \"Watchlist\",\n
    \           \"VALIDATION_MESSAGE\": {}\n         },\n         \"WEIGHT\": {\n            \"TOOLTIP\":
    \"Weight\",\n            \"VALIDATION_MESSAGE\": {}\n         }\n      }\n   },\n
    \  \"USAGE_INSIGHTS\": {\n      \"APPLICATIONS\": {\n         \"TOOLTIP\": \"Application\"\n
    \     },\n      \"PIPELINES\": {\n         \"TOOLTIP\": \"Pipelines\"\n      },\n
    \     \"PIPELINES_WITH_INTELLIGENT_GATES\": {\n         \"TOOLTIP\": \"Pipelines
    with Intelligent Gates\"\n      },\n      \"INTELLIGENT_GATES_BREAKDOWN\": {\n         \"TOOLTIP\":
    \"Intelligent Gates Breakdown\"\n      },\n      \"GATES_USED\": {\n         \"TOOLTIP\":
    \"Gates Used\"\n      },\n      \"USERS\": {\n         \"TOOLTIP\": \"Users\"\n
    \     }\n   },\n   \"DELIVERY_INSIGHTS\": {\n      \"PIPELINES\": {\n         \"TOOLTIP\":
    \"Pipelines\"\n      },\n      \"MOST_ACTIVE_PIPELINES\": {\n         \"TOOLTIP\":
    \"Most Active Pipelines\"\n      },\n      \"MOST_SUCCESSFUL_PIPELINES\": {\n         \"TOOLTIP\":
    \"Most Successful Pipelines\"\n      },\n      \"MOST_FAILED_PIPELINES\": {\n         \"TOOLTIP\":
    \"Most Failed Pipelines\"\n      },\n      \"FASTEST_PIPELINES\": {\n         \"TOOLTIP\":
    \"Fastest Pipelines \"\n      },\n      \"SLOWEST_PIPELINES\": {\n         \"TOOLTIP\":
    \"Slowest Pipelines \"\n      },\n      \"MANUAL_JUDGEMENT\": {\n         \"TOOLTIP\":
    \"Manual Judgement\"\n      }\n   },\n   \"ACCESS_MANAGEMENT\": {\n      \"ADMINISTRATOR\":
    {\n         \"INFO\":\"Super Administrator Groups will not appear in the dropdown
    since their Access Permissions cannot be modified.<br> Administrators will have
    full Access to all Resources.\",\n         \"TOOLTIP\": \"Groups with Administration
    Permissions\"\n       },\n      \"USER_ROLE_LISTING\": {\n         \"HEADER\": \"ROLE
    MANAGEMENT\",\n         \"BODY\": \"Users should be assigned user roles only if
    they need global access to one or more resources.\"\n      },\n      \"USER_ROLE_CREATION\":
    {\n         \"ROLENAME\": {\n            \"TOOLTIP\": \"\",\n            \"VALIDATION_MESSAGE\":
    {\n               \"required\": \"Role Name cannot be empty\"\n            }\n         },\n
    \        \"USER_GROUPS\": {\n            \"TOOLTIP\": \"\",\n            \"VALIDATION_MESSAGE\":
    {\n               \"required\": \"Groups cannot be empty\"\n            }\n         },\n
    \        \"PERMISSIONS\": {\n            \"VALIDATION_MESSAGE\": {\n               \"required\":
    \"Atleast one feature has to be enabled with permissions\"\n            }\n         }\n
    \     },\n      \"FEATURE_VISIBILTY_LISTING\":{\n         \"HEADER\": \"FEATURE
    FLAG MANAGEMENT\",\n         \"BODY\":\"'Feature Visibilty' is for special cases
    where one or more User Groups need to have exclusive permission for certain feature.
    Say, 'Compliance Team' only should have access to Policies. So, when a feature flag
    is enabled for a User Group, this feature is automatically denied for all other
    users. Normally, most User Groups will not have any feature flag enabled.\"\n       },\n
    \     \"FEATURE_VISIBILTY_CREATION\": {\n           \"ROLENAME\":{\n             \"TOOLTIP\":
    \"\",\n             \"VALIDATION_MESSAGE\": {\n               \"required\":\"Role
    Name cannot be empty\"\n              }\n           },\n          \"USER_GROUPS\":{\n
    \           \"TOOLTIP\": \"\",\n            \"VALIDATION_MESSAGE\": {\n            \"required\":\"Groups
    cannot be empty\"\n               }\n           },\n          \"PERMISSIONS\":{\n
    \           \"VALIDATION_MESSAGE\":{\n             \"required\":\"Atleast one feature
    has to be enabled\"\n              }\n           }\n        } \n   },\n   \"LOG_TEMPLATE\":
    {\n      \"STRING_PATTERN\": {\n         \"TOOLTIP\": \"String Pattern\",\n         \"VALIDATION_MESSAGE\":
    {\n            \"required\": \"String Pattern cannot be empty\"\n         }\n      },\n
    \     \"LOG_TOPICS\":{\n        \"TOOLTIP\" :\"Strings that appear in logs with
    their characterization\"\n        },\n        \"LOG_TAGS\":{\n           \"TOOLTIP\"
    :\"Create custom tags based on business logic.\"\n        },\n      \"CHARACTERIZATION_TOPIC\":
    {\n         \"TOOLTIP\": \"Characterization Topic\",\n         \"VALIDATION_MESSAGE\":
    {\n            \"required\": \"Characterization Topic cannot be empty\"\n         }\n
    \     },\n      \"TYPE\": {\n         \"TOOLTIP\": \"Type\",\n         \"VALIDATION_MESSAGE\":
    {}\n      },\n      \"ENABLE_CLUSTER_TAG\": {\n         \"TOOLTIP\": \"Create custom
    tags based on business logic.\",\n         \"VALIDATION_MESSAGE\": {}\n      },\n
    \     \"CLUSTER_TAG_STRING\": {\n         \"TOOLTIP\": \"The string pattern that
    appears in logs\",\n         \"VALIDATION_MESSAGE\": {\n            \"required\":
    \"Cluster Tag String cannot be empty\"\n         }\n      },\n      \"CLUSTER_TAG\":
    {\n         \"TOOLTIP\": \"Cluster Tag\",\n         \"VALIDATION_MESSAGE\": {\n
    \           \"required\": \"Cluster Tag cannot be empty\"\n         }\n      },\n
    \     \"LOG_TEMPLATE_NAME\": {\n         \"TOOLTIP\": \"Log Template Name\",\n         \"VALIDATION_MESSAGE\":
    {\n            \"required\": \"Template Name cannot be empty\"\n         }\n      },\n
    \     \"PROVIDER\": {\n         \"TOOLTIP\": \"Data source for Risk Analysis\",\n
    \        \"VALIDATION_MESSAGE\": {\n            \"required\": \"Provider cannot
    be empty\"\n         }\n      },\n      \"LOG_ACCOUNT\": {\n         \"TOOLTIP\":
    \"Account of the Log provider; Refer Integrations tab under Setup\",\n         \"VALIDATION_MESSAGE\":
    {\n            \"required\": \"Log Account cannot be empty\"\n         }\n      },\n
    \     \"QUERY_FILTER_KEY\": {\n         \"TOOLTIP\": \"Unique Key which identify
    logs to be processed in the Index\",\n         \"VALIDATION_MESSAGE\": {\n            \"required\":
    \"Query Filter Key cannot be empty\"\n         }\n      },\n      \"BASELINE\":
    {\n         \"TOOLTIP\": \"Unique value which identify baseline logs in the Index\",\n
    \        \"VALIDATION_MESSAGE\": {\n            \"required\": \"Baseline cannot
    be empty\"\n         }\n      },\n      \"NEW_RELEASE\": {\n         \"TOOLTIP\":
    \"Unique value which identify New Release logs in the Index\",\n         \"VALIDATION_MESSAGE\":
    {\n            \"required\": \"New Release cannot be empty\"\n         }\n      },\n
    \     \"RESPONSE_KEYWORDS\": {\n         \"TOOLTIP\": \"Field name in the Index
    containing logs to be processed\",\n         \"VALIDATION_MESSAGE\": {\n            \"required\":
    \"Response Keywords cannot be empty\"\n         }\n      },\n      \"TIMESTAMP_KEY\":
    {\n         \"TOOLTIP\": \"Unique Key which identify the timestamp for log; this
    field is optional; by default, it is @timestamp for elasticsearch and timestamp
    for graylog\",\n         \"VALIDATION_MESSAGE\": {}\n      },\n      \"AUTOBASELINE\":
    {\n         \"TOOLTIP\": \"ML based learning of the baseline from historic analysis\",\n
    \        \"VALIDATION_MESSAGE\": {}\n      },\n      \"CONTEXTUAL_CLUSTER\": {\n
    \        \"TOOLTIP\": \"Enable/disable cluster of unexpected events in similar context\",\n
    \        \"VALIDATION_MESSAGE\": {}\n      },\n      \"CONTEXTUAL_WINDOW_SIZE\":
    {\n         \"TOOLTIP\": \"Number of Log events to be seen in a Context. Allowed
    size in between 25 and 50\",\n         \"VALIDATION_MESSAGE\": {\n            \"max\":
    \"Allowed size is in between 25 to 50\",\n            \"min\": \"Allowed size is
    in between 25 to 50\"\n         }\n      },\n      \"INFO_CLUSTER_SCORING\": {\n
    \        \"TOOLTIP\": \"Enabling this option will include INFO clusters in scoring\",\n
    \        \"VALIDATION_MESSAGE\": {}\n      },\n      \"SENSITIVITY\": {\n         \"TOOLTIP\":
    \"Impact of Unexpected Issues on the log scoring\",\n         \"VALIDATION_MESSAGE\":
    {\n            \"required\": \"Sensitivity cannot be empty\"\n         }\n      },\n
    \     \"SCORING_ALGORITHM\": {\n         \"TOOLTIP\": \"Scoring Algorithm for Risk
    Analysis\",\n         \"VALIDATION_MESSAGE\": {}\n      },\n      \"LOG_GROUP\":
    {\n         \"TOOLTIP\": \"Group of log streams that share the same retention, monitoring,
    and access control settings\",\n         \"VALIDATION_MESSAGE\": {\n            \"required\":
    \"Log Group cannot be empty\"\n         }\n      },\n      \"LOG_STREAM\": {\n         \"TOOLTIP\":
    \"Sequence of log events that share the same source\",\n         \"VALIDATION_MESSAGE\":
    {\n            \"required\": \"Log Stream cannot be empty\"\n         }\n      },\n
    \     \"REGION\": {\n         \"TOOLTIP\": \"Geographic area where AWS data center\",\n
    \        \"VALIDATION_MESSAGE\": {\n            \"required\": \"Region cannot be
    empty\"\n         }\n      },\n      \"INDEX_PATTERN\": {\n         \"TOOLTIP\":
    \"Index containing logs for processing\",\n         \"VALIDATION_MESSAGE\": {\n
    \           \"required\": \"Intex Pattern cannot be empty\"\n         }\n      },\n
    \     \"CUSTOM_REGEX\": {\n         \"TOOLTIP\": \"Custom Regular Expression to
    filter the logs\",\n         \"VALIDATION_MESSAGE\": {}\n      },\n      \"REGULAR_EXPRESSION\":
    {\n         \"TOOLTIP\": \"Sequence of characters that specifies a search pattern\",\n
    \        \"VALIDATION_MESSAGE\": {}\n      },\n      \"RESPONSE_KEY\": {\n         \"TOOLTIP\":
    \"Field name in the Index where regex to be searched\",\n         \"VALIDATION_MESSAGE\":
    {}\n      },\n      \"STREAM_ID\": {\n         \"TOOLTIP\": \"The streams are a
    mechanism to route messages into categories in realtime while they are processed\",\n
    \        \"VALIDATION_MESSAGE\": {\n            \"required\": \"Stream ID cannot
    be empty\"\n         }\n      },\n      \"NAMESPACE\": {\n         \"TOOLTIP\":
    \"Namespace\",\n         \"VALIDATION_MESSAGE\": {\n            \"required\": \"Namespace
    cannot be empty\"\n         }\n      },\n      \"TEST_CASE_KEY\": {\n         \"TOOLTIP\":
    \"Field in the log index which holds the test case names\",\n         \"VALIDATION_MESSAGE\":
    {\n            \"required\": \"Test Case Key cannot be empty\"\n         }\n      },\n
    \     \"TEST_SUITE_KEY\": {\n         \"TOOLTIP\": \"Field in the log index which
    \ holds the test suite names\",\n         \"VALIDATION_MESSAGE\": {\n            \"required\":
    \"Test Suite Key cannot be empty\"\n         }\n      }\n   }\n}    \n"
kind: ConfigMap
metadata:
  name: oes-ui-config
  labels:
    app: oes
    component: ui
    heritage: "Helm"
    release: "isd"
    chart: "oes-3.12.2"
---
# Source: oes/templates/configmaps/oes-ui-nginxconf.yaml
apiVersion: v1
data:
  nginx.conf: |
    # For more information on configuration, see:
    #   * Official English Documentation: http://nginx.org/en/docs/
    #   * Official Russian Documentation: http://nginx.org/ru/docs/
  
    user nginx;
    worker_processes auto;
    error_log /var/log/nginx/error.log debug;
    pid /tmp/nginx.pid;
  
    # Load dynamic modules. See /usr/share/doc/nginx/README.dynamic.
    include /usr/share/nginx/modules/*.conf;
  
    events {
        worker_connections 1024;
    }
  
    http {
        log_format  main  '$remote_addr - $remote_user [$time_local] "$request" '
                          '$status $body_bytes_sent "$http_referer" '
                          '"$http_user_agent" "$http_x_forwarded_for"';
  
        access_log  /var/log/nginx/access.log  main;
  
        sendfile            on;
        tcp_nopush          on;
        tcp_nodelay         on;
        keepalive_timeout   65;
        types_hash_max_size 2048;
  
        include             /etc/nginx/mime.types;
        default_type        application/octet-stream;
  
        # Load modular configuration files from the /etc/nginx/conf.d directory.
        # See http://nginx.org/en/docs/ngx_core_module.html#include
        # for more information.
        include /etc/nginx/conf.d/*.conf;
  
        server {
            listen       8080 default_server;
            #listen       [::]:8080 default_server;
            server_name  _;
            root /var/www/html;
  
            # Load configuration files for the default server block.
            include /etc/nginx/default.d/*.conf;
  
            location ^~ /deck {
              proxy_pass http://spin-deck:9000/ ;
            }
  
            location ^~ /plugin-manifest.json {
              proxy_pass http://spin-deck:9000 ;
            }
  
            location ^~ /gate/ {
              proxy_pass http://oes-gate:8084/ ;
            }
  
            location ^~ /application {
              proxy_pass http://oes-ui:8080 ;
            }
  
            location ^~ /ui {
              try_files $uri $uri/ /ui/index.html;
            }
  
            # Go to Gate if you don't know what to do
            location / {
              proxy_pass http://oes-gate:8084/ ;
            }
  
  
        }
    }

kind: ConfigMap
metadata:
  name: oes-ui-nginxconf
  labels:
    app: oes
    component: ui
    heritage: "Helm"
    release: "isd"
    chart: "oes-3.12.2"
---
# Source: oes/templates/configmaps/opa-persist.yaml
apiVersion: v1
data:
  opa-persist.sh: |
    wait_period=0
    while true
    do
    kubectl get po -n opsmx-isd -o jsonpath='{range .items[*]}{..metadata.name}{"\t"}{..containerStatuses..ready}{"\n"}{end}' > /tmp/inst.status
    SAPOR=$(grep oes-sapor /tmp/inst.status | awk '{print $2}')
    PLATFORM=$(grep oes-platform /tmp/inst.status | awk '{print $2}')

    wait_period=$(($wait_period+10))

    if [ "$SAPOR" == "true" ] && [ "$PLATFORM" == "true" ];
    then
      echo \"Spinnaker and OES services are Up and Ready..\"
      set -x
      sleep 5
      BASEURL=$GATEURL
      USERPASS="-u ${GATEUSER}:${GATEPASS}"
      curl $USERPASS $BASEURL/oes/v1/policies/list > listofpolicies.json
      #Get the policy NAMES
      [ -s "listofpolicies.json" ] && (cat listofpolicies.json | jq .[] | jq -r .policyName > policies) || sleep infinity
      #for each NAME
      while read -e name; do
        #Get content
        curl $USERPASS $BASEURL/oes/v1/policy/$name > tmp.json

        #Get Policy ID
        ID=`cat tmp.json|jq .response | jq '.policyId'`
        #Delete Policy ID
        cat tmp.json|jq .response | jq 'del(.policyId)'  > update.json

        #update
        curl $USERPASS -X PUT -H "Content-Type: application/json" -d @update.json $BASEURL/oes/v1/policy/$ID
      done <  policies
      sleep infinity
      #endFOR
    else
      if [ $wait_period -gt 2000 ];
      then
          echo \"Script is timed out as the OES is not ready yet.......\"
          break
      else
          echo \"Waiting for OES services to be ready\"
          sleep 1m
      fi
    fi
    done
kind: ConfigMap
metadata:
  name: opa-persist
---
# Source: oes/templates/configmaps/standard-error-codes.yaml
apiVersion: v1
data:
  standard-error-codes.csv: |-
    standardErrorCodesMapping.ISD-IsEmpty-400-01 = ISD-IsEmpty-400-01 : {0} - {1} is empty. Please provide the {1}.
    standardErrorCodesMapping.ISD-IsNull-400-02 = ISD-IsNull-400-02 : {0} - {1} is null. Please provide the {1}.
    standardErrorCodesMapping.ISD-MustBeAlphanumericName-400-03 = ISD-MustBeAlphanumericName-400-03 : {0} - {1} should be alphanumeric without any special characters !
    standardErrorCodesMapping.ISD-ExceedsMaxStringLength-400-04 = ISD-ExceedsMaxStringLength-400-04 : {0} - {1} should not have more than {2} characters.
    standardErrorCodesMapping.ISD-NotConfigured-400-05 = ISD-NotConfigured-400-05 : {0} - {1} is not configured. Please configure the {1} !
    standardErrorCodesMapping.ISD-PolicyNotProvided-400-06 = ISD-PolicyNotProvided-400-06 : {0} - Policies are mandatory for automated approval gate.
    standardErrorCodesMapping.ISD-EmptyKeyOrValueInJson-400-07 = ISD-EmptyKeyOrValueInJson-400-07 : {0} - {1} is missing in json !
    standardErrorCodesMapping.ISD-UnableToParseJSON-400-08 = ISD-UnableToParseJSON-400-08 : {0} - Unable to parse Json. Please provide a valid json with required data !
    standardErrorCodesMapping.ISD-MustBeANumber-400-09 = ISD-MustBeANumber-400-09 : {0} - {1} must be a number : {2}
    standardErrorCodesMapping.ISD-Unauthorized-401-01 = ISD-Unauthorized-401-01 : {0} - {1} not authorized {2}.
    standardErrorCodesMapping.ISD-Unauthorized-401-02 = ISD-Unauthorized-401-02 : {0} - User group not found for user : {1}.
    standardErrorCodesMapping.ISD-NotAdmin-401-03 = ISD-NotAdmin-401-03 : {0} - {1} is not an admin !
    standardErrorCodesMapping.ISD-IsNotFound-404-01 = ISD-IsNotFound-404-01 : {0} - {1} not found : {2}
    standardErrorCodesMapping.ISD-NoData-404-02 = ISD-NoData-404-02 : {0} - No data found for {1}
    standardErrorCodesMapping.ISD-DoesNotExist-404-03 = ISD-DoesNotExist-404-03 : {0} - {1} does not exist {2}.
    standardErrorCodesMapping.ISD-AlreadyExists-409-01 = ISD-AlreadyExists-409-01 : {0} - {1} already exists: {2}
    standardErrorCodesMapping.ISD-FailedToDelete-412-01 = ISD-FailedToDelete-412-01 : {0} - Unable to delete {1} as {1} is already in use !
    standardErrorCodesMapping.ISD-FailedToDeletePolicy-412-02 = ISD-FailedToDeletePolicy-412-02 : {0} - Unable to delete policy as it is already in use for {1} gate !
    standardErrorCodesMapping.ISD-FailedToUpdate-412-03 = ISD-FailedToUpdate-412-03 : {0} - Unable to update {1} as {1} is already in use !
    standardErrorCodesMapping.ISD-InvalidURL-422-01 = ISD-InvalidURL-422-01 : {0} - The requested {1} URL is invalid !
    standardErrorCodesMapping.ISD-ConnectionOrAuthenticationFailed-422-02 = ISD-ConnectionOrAuthenticationFailed-422-02 : {0} - {1} connection or authentication failed : HTTP status {2}
    standardErrorCodesMapping.ISD-InvalidCredentials-422-03 = ISD-InvalidCredentials-422-03 : {0} - {1} credentials are invalid !
    standardErrorCodesMapping.ISD-InvalidEndpoint-422-04 = ISD-InvalidEndpoint-422-04 : {0} - {1} endpoint is invalid !
    standardErrorCodesMapping.ISD-InvalidEndpointOrCredentials-422-05 = ISD-InvalidEndpointOrCredentials-422-05 : {0} - {1} endpoint or credentials are invalid !
    standardErrorCodesMapping.ISD-UsernameOrPasswordIsBlank-422-06 = ISD-UsernameOrPasswordIsBlank-422-06 : {0} - {Username} is blank but {Password) is supplied. Both must be present or blank.
    standardErrorCodesMapping.ISD-UnknownDatasource-422-07 = ISD-UnknownDatasource-422-07 : {0} - Unknown datasource or datasource is currently not supported : {1}
    standardErrorCodesMapping.ISD-InvalidProvider-422-08 = ISD-InvalidProvider-422-08 : {0} - {1} provider is invalid !
    standardErrorCodesMapping.ISD-InvalidPath-422-09 = ISD-InvalidPath-422-09 : {0} - {1} path is invalid !
    standardErrorCodesMapping.ISD-UnableToAddStage-424-01 = ISD-UnableToAddStage-424-01 : {0} - Unable to add stage in {1} !
    standardErrorCodesMapping.ISD-UnableToDelete-424-02 = ISD-UnableToDelete-424-02 : {0} - Unable to delete {1} while analysis is under process !
    standardErrorCodesMapping.ISD-ShouldBeNumber-500-01 = ISD-ShouldBeNumber-500-01 : {0} - {1} should be an number !
    standardErrorCodesMapping.ISD-ShouldBePositiveNumber-500-02 = ISD-ShouldBePositiveNumber-500-02 : {0} - {1} should be an positive number !
    standardErrorCodesMapping.ISD-UnableToFetch-500-03 = ISD-UnableToFetch-500-03 : {0} - Unable to fetch {1} from database. Please try after some time !
    standardErrorCodesMapping.ISD-UnableToCreate-500-04 = ISD-UnableToCreate-500-04 : {0} - Unable to create {1} !
    standardErrorCodesMapping.ISD-UnableToDelete-500-05 = ISD-UnableToDelete-500-05 : {0} - Unable to delete {1} !
    standardErrorCodesMapping.ISD-UnableToUpdate-500-06 = ISD-UnableToUpdate-500-06 : {0} - Unable to update {1} !
kind: ConfigMap
metadata:
  labels:
    app: oes
  name: standard-error-codes-config
---
# Source: oes/templates/forwarder/oes-forwarder-config.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: opsmx-controller-controller1
  labels:
    agent.opsmx.com/name: controller1
    agent.opsmx.com/role: controller
    heritage: "Helm"
    release: "isd"
    chart: "oes-3.12.2"
data:
  configFile: |
    serviceHostname: opsmx-controller-controller1
    agentHostname: controller.exampleopsmx.net
    remoteCommandHostname: controller.exampleopsmx.net
    controlHostname: opsmx-controller-controller1
    #agentAdvertisePort: "443"
    serviceAuth:
      currentKeyName: "public.pem"
      headerMutationKeyName: "public.pem"
---
# Source: oes/templates/pipeline-promotion/pipe-promot-config-cm.yaml
apiVersion: v1
data:
  repo.properties: |
    #properties file for pipeline promotion scripts

    # Common Stuff
    repo_type=git
    repo_name=repo_name
    root_folder=pipeline/
    #S3 Specific
    export AWS_ACCESS_KEY_ID=access_key
    export AWS_SECRET_ACCESS_KEY=secret_key

    #git mandatory patameters
    git_url=example.repo.com
    git_project=project_name
    git_user=username
    git_branch=samplerepo
    #git_password=
    #API
    git_api_url=https://api.github.com/repos  # bitbucket

    #Auto PR requirements
    merge_branch=false
    auto_merge=false
    git_approve_user=approver_user
    target_branch=master

    #optional
    #git_user_email=krish@company.com

    #delete pipeLine
    delete_on_sync_spin=
    delete_on_sync_repo=
    #git_approve_user_password=
    #git_secret_sshkey=
kind: ConfigMap
metadata:
  creationTimestamp: null
  name: pipe-promot-config
---
# Source: oes/templates/pipeline-promotion/pipe-promot-scripts-cm.yaml
apiVersion: v1
data:
  bitbucket.sh: "#!/bin/bash\n\n#this script funtions only work for bitbucket central
    repository\n\n#this script funtions only work for git repo\n#env variables needed
    for this to work are as below\n#***git_url=\"example.bitbucket.com\" make sure
    you dont add http/https or / in the url\n#****git_repo=\"pipelinepromotion\" repo
    to be pushed/download pipeline json files from\n#***git_project=\"kes\" project
    key is needed to clone/push/pull merge code\n#***git_user=\"tes.user\" user is
    needed for cloning and pusing changes (stash does not support only access key)\n#***git_branch=\"testbranch\"
    the branch to which the code should be merged with\n#***merge_branch=false if
    true then provide all the below env variables\n#   git_secret_token=\"dafjaljoahfoasjoijso\"
    needed to create pull requests should be the git_users secret token\n#   git_pr_token=\"slkdfjaljoajfopaj\"
    this is approver token to approve pull requests / you can also provide approver
    password here.\n#   git_approve_user=\"test.approver\"  username of the pull request
    approver\n#   git_password=\"adjoowddaw\" make sure your password does not include
    special characters like # @*/. special characters cause git clone command to fail
    with https\n#\n#  repo_type=\"stash\" for selfhosted bitbucket server please use
    stash as repo type\n#***root_folder=\"path/to/pipeline-promotion/folder\" folder
    to be selected in the repo to which the pipeline jobs to be pushed\n#***command=upload
    for running specific job -\n#                                         upload -
    to upload spinnaker pipeline json files to repo\n#                                         download
    - to download pipeline json file from repo and apply on spinnaker\n#***spinnaker_applications=\"testapp,sampleapp\"
    application needed to collect the pipeline information\n#spinnaker_pipelines=\"\"
    provide pipelines to be collected, if nothing given, all the pipelines of the
    application are collected\n#git_secret_sshkey=\"sshkey\" ssh key if you want to
    clone repo with ssh protocol\n\n# note *** env variables are mandatory to work
    with the script\n\nsource scripts/git.sh\ngit_bitbucket_api=$git_api_url\npr_id=0\napprove_pr_bitbucket(){\n
    \ approve_req=$(curl -X POST -u $git_approve_user:$git_pr_token \\\n  $git_bitbucket_api${git_project}/${git_repo}/pullrequests/${pr_id}/approve
    -o -I -L -s -w \"%{http_code}\")\n  echo $approve_req\n  if [[ $approve_req ==
    \"200\" ]];then\n    echo \"merge request approved successfully\"\n  else\n    echo
    \"FAIL: failed to approve the request \"\n    exit 1\n  fi\n}\n\nmerge_pr_bitbucket(){\n\n
    \ merge_req=$(curl  -X POST -u $git_user:$git_secret_token   \\\n  $git_bitbucket_api${git_project}/${git_repo}/pullrequests/${pr_id}/merge
    -o -I -L -s -w \"%{http_code}\")\n  echo $merge_req\n  if [[ $merge_req == 200
    \ ]]; then\n    echo \"merged pr successfully\"\n  elif [[ $merge_req == 202 ]];
    then\n    echo \"merging is in progress will be merged in less than a min\"\n
    \ else\n    echo \"FAILED: failed to merge $merge_pr\"\n    exit 1\nfi\n}\ncreate_pr_bitbucket(){\n\n\tlocal
    output=$(curl  -X POST -H \"Content-Type: application/json\" -u $git_user:$git_secret_token
    \  $git_bitbucket_api${git_project}/${git_repo}/pullrequests -d '{\n    \"title\":
    \"merging '$git_branch' to '$target_branch'\",\n    \"source\": {\n            \"branch\":
    {\n                \"name\": \"'$git_branch'\"\n            }\n        },\n        \"destination\":
    {\n            \"branch\": {\n                \"name\": \"'$target_branch'\"\n
    \           }\n        }\n}')\n  echo $output\n  echo $output > pr_response.json\n
    \ grep  \"There are no changes to be pulled\" pr_response.json\n  if [ \"$?\"
    = 0 ]\n  then\n    echo \"master branch is already up-to-date\"\n    exit 0\n
    \ else\n    pr_id=$(cat  pr_response.json| jq '(.id)' | sed 's/\\\"//g')\n    if
    [ $? = 0 ]; then\n      echo \"successfully created pull request \"\n      #rm
    -f pr_response.json\n    else\n      echo \"ERROR: failed to raise pull request
    $output\"\n      exit 1\n  fi\nfi\n}\n\nsync_spin_to_bitbucket(){\n  setup_git\n
    \ sync_spin_to_git\n  if [[ $merge_branch == \"true\" && $target_branch != \"\"
    && ($git_branch != $target_branch)  ]];then\n    if [[ $git_api_url_port != \"\"
    ]];then\n      git_bitbucket_api=$git_bitbucket_api:$git_api_url_port\n      create_pr_bitbucket\n
    \     if [[ $auto_merge == \"true\" ]]; then\n        approve_pr_bitbucket\n        sleep
    5\n        merge_pr_bitbucket\n      fi\n    else\n      create_pr_bitbucket\n
    \     if [[ $auto_merge == \"true\" ]]; then\n        approve_pr_bitbucket\n        sleep
    5\n        merge_pr_bitbucket\n      fi\n    fi\n  fi\n}\n"
  deployer.sh: "#!/bin/bash\necho \"In deployer.sh\"\nSBASE=scripts\nsource config/repo.properties\nBRANCH_NAME_UI=$(echo
    $branch_ui | sed 's/[][]//g')\necho $BRANCH_NAME_UI\nif [ -z \"$BRANCH_NAME_UI\"
    ]\n        then\n           echo \"Not Provided the Branch in the spinnaker UI....Continuing
    with the default branch specified in configmap\"\n           echo $git_branch\n
    else\n      echo \"Provided the User defined Branch in spinnaker UI\"\n      git_branch=$BRANCH_NAME_UI\n
    \     echo $git_branch\nfi\nROOT_FOLDER_UI=$(echo $rootfolder_ui | sed 's/[][]//g')\necho
    $ROOT_FOLDER_UI\nif [ -z \"$ROOT_FOLDER_UI\" ]\n        then\n           echo
    \"Not Provided the Save Path in the spinnaker UI....Continuing with the default
    path specified in configmap\"\n           echo $root_folder\n else\n      echo
    \"Provided the User defined Branch in spinnaker UI\"\n      root_folder=$ROOT_FOLDER_UI\n
    \     echo $root_folder\nfi\n\nsource $SBASE/spin.sh\nsource $SBASE/stash.sh\nsource
    $SBASE/s3.sh\nsource $SBASE/github.sh\nsource $SBASE/bitbucket.sh\necho \"Sourcing
    complete\"\nsync_repo_from_spinnaker(){\n\tif [[ $repo_type = \"s3\" ]];\n \tthen\n\t
    \  upload_spin_to_s3\n\telif [[ $repo_type = \"stash\" ]]; then\n\t\tsync_spin_to_stash\n
    \ elif [[ $repo_type == \"bitbucket\" ]]; then\n\t\tsync_spin_to_bitbucket\n\telif
    [[ $repo_type = \"git\" ]]; then\n\t\tsync_spin_to_github\n\telif [[ $repo_type
    = \"gitea\" ]]; then\n                sync_spin_to_github\n\telse\n\t\techo \"Not
    specified Repo type\"\n\t\texit 5\n\tfi\n}\nsync_spinnaker_from_repo(){\n\tif
    [[ $repo_type = \"s3\" ]];\n \tthen\n\t   sync_from_s3_spin\n\telif [[ $repo_type
    = \"stash\" || $repo_type = \"git\" || $repo_type = \"bitbucket\" ]]; then\n\t\tsync_git_to_spin\n\tfi\n}\n\nif
    [[ \"$command\" == \"download\" ]]; then\n\tsync_spinnaker_from_repo\nelif [[
    \"$command\" == \"upload\" ]]; then\n        echo \"executing upload\"\n\t#statement\n\tsync_repo_from_spinnaker\nelse\n\techo
    \"ERROR: unknown command\"\n\nfi\necho \"Done executing\"\n"
  git.sh: "#!/bin/bash\nsource scripts/spin.sh\n\ngit_repo=$repo_name\ntempdir=\"/tmp/\"\npull_requred=false\nif
    [[ $git_branch == \"\" ]]\nthen\n  git_branch=\"master\"\nfi\nsetup_git() {\n
    \ echo \"Setting up the Git \"\n  local name=${git_user:-spinnaker}\n  local email=${git_user_email:-phani@opsmx.io}\n
    \ git config --global user.email \"$email\"\n  git config --global user.name \"$name\"\n}\nvalidate_clone()
    {\n\tif [ $? == 0 ]\n\tthen\n\t\techo \"Cloning done ${git_repo}\"\n\telse\n\t\techo
    \"Cloning failed with repo ${git_repo}, Please check credentials and repo access....\"\n\t\texit
    5\n\tfi\n}\ngit_clone_http() {\n  echo \"cloning $git_project/$git_repo over https\"\n
    \ if [[ $repo_type == \"git\" || $repo_type == \"bitbucket\" ]]; then\n    clone_result=$(git
    clone https://$git_user:${git_secret_token}@${git_url}/${git_project}/${git_repo}.git
    $tempdir/$git_repo 2> /dev/null)\n    validate_clone\n  elif [[ $repo_type ==
    \"gitea\" ]]; then\n    clone_result=$(git clone http://$git_user:${git_secret_token}@${git_url}/${git_project}/${git_repo}.git
    $tempdir/$git_repo 2> /dev/null)\n    validate_clone\n  elif [[ $repo_type ==
    \"stash\" ]]; then\n    #statements\n    if [[ $git_url_port != \"\" ]]; then\n
    \     clone_result=$(git  clone https://$git_user:${git_secret_token}@${git_url}:$git_url_port/scm/${git_project}/$git_repo.git
    $tempdir/$git_repo 2> /dev/null)\n      validate_clone\n    else\n      clone_result=$(git
    \ clone https://$git_user:${git_secret_token}@${git_url}/scm/${git_project}/$git_repo.git
    $tempdir/$git_repo 2> /dev/null)\n      validate_clone\n    fi\n  fi\n  #echo
    $clone_result\n}\nload_ssh(){\n\tmkdir /home/opsmx/.ssh\n\tcp /etc/git-secret/git_secret_sshkey
    ~/.ssh/id_rsa\n\tchmod 400 ~/.ssh/id_rsa\n\tssh-keyscan github.com >> ~/.ssh/known_hosts\n}\ngit_clone_ssh(){\n
    \ echo \"cloning $git_project/$git_repo over ssh\"\n  if [[ $repo_type == \"git\"
    || $repo_type == \"bitbucket\" ]]\n  then\n\t  load_ssh\n\t  clone_result=$(git
    clone git@${git_url}:${git_project}/$git_repo.git $tempdir/$git_repo 2> /dev/null)\n\t
    \ validate_clone\n  elif [[ $repo_type == \"stash\" && $git_url_port != \"\" ]];
    then\n    #statements\n    clone_result=$(git clone ssh://git@${git_url}:$git_url_port/${git_project}/$git_repo.git
    $tempdir/$git_repo 2> /dev/null)\n  else\n\n    clone_result=$(git clone ssh://git@${git_url}:${git_project}/$git_repo.git
    $tempdir/$git_repo $tempdir/$git_repo 2> /dev/null)\n  fi\n  #echo $clone_result\n}\n\ngit_add_file()
    {\n  local file=$1\n  git add $file\n}\n\ngit_add_all() {\n  git add $1\n}\ngit_tag_all()
    {\n  git tag -a Backup-$TAGSTAMP -m \"$msg\"\n  git push --tags\n}\n\ngit_delete_file()
    {\n  local file=$1\n  git rm $file\n}\n\ngit_checkout_branch(){\n  all_branches=$(git
    branch -r| grep -w  origin/$git_branch)\n  echo $all_lbranches\n  if [[ $all_branches
    != \"\" ]]\n  then\n    branch_checkout_result=$(git checkout $git_branch)\n    echo
    $branch_checkout_result\n    pull_requred=true\n  else\n    git checkout -b $git_branch\n
    \ fi\n\n}\ngit_add_all(){\n\n\tgit add $1\n\n}\ngit_commit_all() {\n  local branch=$git_branch\n
    \ local msg=\"checking application and pipeline raw data\"\n if [ \"$pull_requred\"
    = true ]; then\n   git pull origin $branch --no-edit\n   if [ \"$?\" != \"0\"
    ];then\n     echo \"[ERROR]: Failed to pull $branch upstream.\"\n     exit 1\n
    \ fi\nfi\n  opts=\"\"\n  if [ \"$git_commit_sign\" == \"true\" ]; then\n    opts=\"-s\"\n
    \ fi\n  #git commit $opts -a -m $msg\n  git commit -m \"$msg\"\n  git push --set-upstream
    origin $branch\n  if [ \"$?\" != \"0\" ];then\n    echo \"[ERROR]: Failed to push
    $branch upstream.\"\n    exit 1\n  fi\n}\n\nsync_spin_to_git() {\n\n  echo \"In
    upload function which copies spinnaker application and pipeline from spinnaker
    to repo\"\n\n  local user_root_folder=$root_folder\n\n  if [ \"$git_secret_sshkey\"
    != \"\" ]; then\n    git_clone_ssh\n  elif [ \"$git_secret_token\" != \"\" ];
    then\n    git_clone_http\n  else\n    echo \"git cloning requires either a git_aws_secret_key
    to be set or git_aws_secret_token\"\n   exit 5\n  fi\n\n  projectdir=$tempdir/$git_repo\n
    \ cd $projectdir\n  #We are done, get update git\n  git_checkout_branch\n  if
    [ -z $spinnaker_applications ]\n  then\n          spin application list > app.json\n
    \         spinnaker_app=$(cat app.json | jq -r '[.[].name]| @csv' | sed 's/\",\"/,/g;
    s/^\"\\|\"$//g')\n          rm -rf app.json\n          get_pipelines_data  $spinnaker_app\n
    \ else\n          get_pipelines_data  $spinnaker_applications\n    fi\n  git_add_all
    $root_folder\n  git_commit_all\n  return 0\n}\nsync_git_to_spin(){\n  setup_git\n
    \ if [ \"$git_secret_sshkey\" != \"\" ]; then\n    git_clone_ssh\n  elif [ \"$git_secret_token\"
    != \"\" ]; then\n    git_clone_http\n  else\n    echo \"git cloning requires either
    a git_aws_secret_key to be set or git_aws_secret_token\"\n   exit 5\n  fi\n  projectdir=$tempdir/$git_repo\n
    \ cd $projectdir\n  git_checkout_branch\n  syncup_spin\n}\n"
  github.sh: |
    #!/bin/bash

    #this script funtions only work for github central repository

    #this script funtions only work for git repo
    #env variables needed for this to work are as below
    #***git_url="example.bitbucket.com" make sure you dont add http/https or / in the url
    #****git_repo="pipelinepromotion" repo to be pushed/download pipeline json files from
    #***git_project="kes" project key is needed to clone/push/pull merge code
    #***git_user="tes.user" user is needed for cloning and pusing changes (stash does not support only access key)
    #***git_branch="testbranch" the branch to which the code should be merged with
    #***merge_branch=false if true then provide all the below env variables
    #   git_secret_token="dafjaljoahfoasjoijso" needed to create pull requests should be the git_users secret token
    #   git_pr_token="slkdfjaljoajfopaj" this is approver token to approve pull requests / you can also provide approver password here.
    #   git_approve_user="test.approver"  username of the pull request approver
    #   git_password="adjoowddaw" make sure your password does not include special characters like # @*/. special characters cause git clone command to fail with https
    #
    #  repo_type="stash" for selfhosted bitbucket server please use stash as repo type
    #***root_folder="path/to/pipeline-promotion/folder" folder to be selected in the repo to which the pipeline jobs to be pushed
    #***command=upload for running specific job -
    #                                         upload - to upload spinnaker pipeline json files to repo
    #                                         download - to download pipeline json file from repo and apply on spinnaker
    #***spinnaker_applications="testapp,sampleapp" application needed to collect the pipeline information
    #spinnaker_pipelines="" provide pipelines to be collected, if nothing given, all the pipelines of the application are collected
    #git_secret_sshkey="sshkey" ssh key if you want to clone repo with ssh protocol

    # note *** env variables are mandatory to work with the script

    source scripts/git.sh
    git_hub_api_url=$git_api_url
    approve_pr_github(){
      approve_req=$(curl -o -I -L -s -w "%{http_code}" -X POST -H "Accept: application/vnd.github.v3+json" -u $git_approve_user:$git_pr_token  $git_hub_api_url/$git_user/${git_repo}/pulls/${pr_id}/reviews \
      -d '{"body": "Spinnaker says LGTM","event": "APPROVE"}')
      echo $approve_req
      if [[ $approve_req == "200" ]];then
        echo "merge request approved successfully"
      else
        echo "FAIL: failed to approve the request $"
        exit 1
      fi
    }

    merge_pr_github(){

      merge_req=$(curl -o -I -L -s -w "%{http_code}" -X PUT -H "Accept: application/vnd.github.v3+json" -u $git_user:$git_secret_token $git_hub_api_url/$git_user/${git_repo}/pulls/${pr_id}/merge)
      echo $merge_req
      if [[ $merge_req == "200" ]]; then
        echo "merged pr successfully"
      else
        echo "FAILED: failed to merge $merge_pr"
        exit 1
    fi
    }

    create_pr_github(){

      local output=$(curl  -X POST -H "Accept: application/vnd.github.v3+json" -u $git_user:$git_secret_token $git_hub_api_url/${git_user}/${git_repo}/pulls \
      -d '{"title": "pull request to merge '$git_branch' to master","body": "pull request to merge latest pipleine jobs information to '$target_branch'", "head": "'${git_branch}'","base": "'$target_branch'"}')
      if [ "$?" != 0 ]
      then
        echo "master branch is already up-to-date"
        exit 0
      else
        echo $output
        echo $output > pr_response.json
        errors=$(cat  pr_response.json| jq '(.errors)' | sed 's/\"//g')
        if [[ $errors != null ]]; then
          echo "ERROR: failed to raise pull request $errors"
          exit 1
        fi
        pr_id=$(cat  pr_response.json| jq '(.number)' | sed 's/\"//g')
        if [[  $pr_id != ""  ]]; then
          echo "successfully created pull request "
        else
          echo "ERROR: failed to raise pull request $output"
          exit 1
      fi
    fi
    }

    sync_spin_to_github(){
      setup_git
      sync_spin_to_git
      if [[ $merge_branch == "true" && $target_branch != "" && ($git_branch != $target_branch)  ]];then
        if [[ $git_api_url_port != "" ]];then
          git_hub_api_url=$git_hub_api_url:$git_api_url_port

          create_pr_github
          if [[ $auto_merge == "true" ]]; then
            approve_pr_github
            merge_pr_github
          fi
        else
          create_pr_github
          if [[ $auto_merge == "true" ]]; then
            approve_pr_github
            merge_pr_github
          fi
        fi
      fi
    }
  s3.sh: |
    #!/bin/bash
    source scripts/spin.sh
    absolute_path="$(dirname $(readlink -f $0))"

    # s3_folder=folder/in/s3/bucket if not given script uploads to root folder or the s3 bucket
    # ***bucket_name=testenvpipelinebucket "bucktet name to upload pipeline configuration"
    # ***AWS_ACCESS_KEY_ID="SKJGIHOBGIHIHOOH" access key to access s3 bucket
    # ***AWS_SECRET_ACCESS_KEY="sdfjlasj2e334234sdljflsjflsd98y9sy/0UVv6eCg" secret to access s3 bucket
    # ***repo_type=s3 provide repo type as s3
    #***command=upload for running specific job -
    #                                         upload - to upload spinnaker pipeline json files to repo
    #                                         download - to download pipeline json file from repo and apply on spinnaker
    #***spinnaker_applications="testapp,sampleapp" application needed to collect the pipeline information
    #spinnaker_pipelines="" provide pipelines to be collected, if nothing given, all the pipelines of the application are collected


    # note *** env variables are mandatory to work with the script
    s3_folder=$root_folder
    tempdir="/tmp/"
    bucket_name=$repo_name
    create_bucket(){
      #to create a bucket in s3 bucket name needed
            aws s3 mb s3://$bucket_name
            if [ $? != 0 ]; then
                    echo "[ERROR]: Failed to create s3 bucket  might be aleady existing"
            fi
    }

    list_bucket(){
      # to llst bucket objects
         aws s3 ls s3://$bucket_name/
             if [ $? != 0 ]; then
              echo "[ERROR]: Failed to list s3 bucket "
          fi
    }

    list_application_folder(){
      # to list an object folder
            aws ls s3://$bucket_name/${s_folder}/$1 | awk '{print $4}'
    }

    upload_spin_to_s3(){
      # get the pipeline data from spinnaker and store in root_folder
      echo APP $spinnaker_applications
      if [ -z $spinnaker_applications ]
      then
              spin application list > app.json
              spinnaker_app=$(cat app.json | jq -r '[.[].name]| @csv' | sed 's/","/,/g; s/^"\|"$//g')
              rm -rf app.json
              get_pipelines_data $spinnaker_app

     else
              get_pipelines_data $spinnaker_applications
     fi

    #  get_pipelines_data
      #upload spinnaker pipelines data and upload to s3 folder
      aws s3 cp $tempdir/$bucket_name/$s3_folder s3://$bucket_name/$s3_folder --recursive
      if [ "$?" != 0 ]; then
              echo "[ERROR]: Failed to upload to bucket" $bucket_name
      else
              echo "uploaded to bucket successfully"
      fi
    }
    sync_from_s3_spin(){

      echo "downloading  spinnaker application pipelines configuration"

      aws s3 sync  s3://$bucket_name/$s3_folder $tempdir$s3_folder
      #apply configuration in spinnaker
      syncup_spin
    }

    delete_s3_object(){
      #delete an object in bucket
            aws rm s3://$bucket_name/${s3_folder}/${application_name}/  --recursive
            if [ $? != 0 ]; then
                    echo "[ERROR]: Failed to delete s3 application folder "
            else
                    echo "created bucket successfully"
            fi
    }
  spin.sh: "#!/bin/bash\n#source $(dirname $0)/git.sh\ntempdir=\"/tmp/\"\n\n#spinnaker_applications=\"sampleapp\"\nget_app_pipelines(){\n\tspin
    pipeline list --application $1  > tmp.json\n\tif [ \"$?\" != \"0\" ]; then\n\t\t\techo
    \"ERROR: spin pipeline list --application $1\"\n\t\t\treturn 1\n\tfi\n\tcat tmp.json
    | jq '.[] | (.name)' | sed 's/\\\"//g' > pipelines_in_application.list\n\tcat
    tmp.json | jq '.[] | (.id)' | sed 's/\\\"//g' > pipelines_guid.list\n\trm tmp.json\n}\n\n\nlive_backup_spin()
    {\n\n#This function will backup existing spinnaker data and store it in local
    for further comparison\n\n  if [[ $repo_type = \"s3\" ]]; then\n\t\tprojectdir=$tempdir/$root_folder\n\telse\n\t\tprojectdir=$tempdir/${git_repo}/$root_folder\n
    \ fi\n\tlive_projectdir_workdir=$projectdir/live_backup\n\n  if [ -d \"$live_projectdir_workdir\"
    ]\n  then\n    echo \"given live_spinnaker_project_work_dir is present\"\n  else\n
    \   echo \"given live_spinnaker_project_work_dir is not present therefore creating
    it\"\n    mkdir -p \"$projectdir/live_backup\"\n  fi\n\n  cd $live_projectdir_workdir\n\n
    \ spinnaker_app=$spinnaker_applications\n  IFS=',' read -r -a spinnaker_app_array
    <<< \"$spinnaker_app\"\n\n\n  spinnaker_pipe=$spinnaker_pipelines\n  IFS=',' read
    -r -a spinnaker_pipe_array <<< \"$spinnaker_pipe\"\n\n  for (( m=0; m<${#spinnaker_app_array[@]};
    m++ )); do\n     sourceApp=${spinnaker_app_array[$m]}\n     echo -e \"Processing
    application $sourceApp\\n\"\n     mkdir -p $sourceApp ; cd $sourceApp\n\t\t        #
    Get into the correct directory\n     spin -k pipeline list --application $sourceApp
    \ > tmp.json\n     if [ \"$?\" != \"0\" ]; then\n         echo \"ERROR: spin pipeline
    list --application $sourceApp\"\n         return 1\n     fi\n     cat tmp.json
    | jq '.[] | (.name)' | sed 's/\\\"//g' > live_pipelines_in_application.list\n
    \    cat tmp.json | jq '.[] | (.id)' | sed 's/\\\"//g' > live_pipelines_guid.list\n
    \    rm tmp.json\n\n     spin -k application get $sourceApp  > $sourceApp.json\n
    \    if [ \"$?\" != \"0\" ]; then\n         echo \"ERROR: spin application get
    $sourceApp\"\n         return 1\n     fi\n\n     if [[ ${#spinnaker_pipe_array[@]}
    > 0 ]]; then\n         for (( p=0; p<${#spinnaker_pipe_array[@]}; p++ )); do\n
    \           pipeLine=${spinnaker_pipe_array[$p]}\n            echo -e \"    Processing
    pipeline $pipeLine\\n\"\n            # Check if pipeline exists\n            existingPipe=`grep
    \\^${pipeLine}\\$ live_pipelines_in_application.list`\n            if [[ \"$existingPipe\"
    == \"${pipeLine}\" ]]; then\n               spin -k pipeline get --application
    $sourceApp  --name \"$pipeLine\" > \"$pipeLine.json\"\n               if [ \"$?\"
    != \"0\" ]; then\n                   echo \"ERROR: spin spin pipeline get --application
    $sourceApp  --name \\\"$pipeLine\\\"\"\n                   return 1\n               fi\n
    \           else\n               echo \"WARNING: pipeline=${pipeLine} not found
    in application=$sourceApp ... skipping\"\n            fi\n         done\n     else
    # No pipelines defined, get all the pipelines\n         while read -r line; do\n
    \           echo -e \"    Processing pipeline $line\\n\"\n            spin -k
    pipeline get --application $sourceApp --name \"$line\" > \"$line.json\"\n            if
    [ \"$?\" != \"0\" ]; then\n                echo \"ERROR: spin spin pipeline get
    --application $sourceApp  --name $line\"\n                return 1\n            fi\n
    \        done < live_pipelines_in_application.list\n     fi\n      cd ..\n  done\n
    \ return 0\n}\n\ndelete_odd_pipelines() {\n  #Delete the additional pielines that
    are in spinnaker and not in git\n   for (( m=0; m<${#spinnaker_app_array[@]};
    m++ )); do\n\t   sourceApp=${spinnaker_app_array[$m]}\n\t   if [ -f \"$projectdir/live_backup/$sourceApp/odd_pipeline.txt\"
    ]; then\n             if [ ! -s \"$projectdir/live_backup/$sourceApp/odd_pipeline.txt\"
    ]; then\n\t     echo \"no new pipelines to delete\"\n             else\n           echo
    \"============ Delete pipeline in $sourceApp Application =============\"\n\n\t
    \  while IFS= read -r pipelinename; do\n           echo \"Deleting the pipeline
    $pipelinename\"\n\t   spin -k pipeline delete --name $pipelinename --application
    $sourceApp\n           done < $projectdir/live_backup/$sourceApp/odd_pipeline.txt\n\n\t
    \  rm -rf $projectdir/live_backup/$sourceApp/odd_pipeline.txt\n\n   fi\n   fi\ndone\n\n}\n#Create
    default parameterconfig-files\ncreate_default_params() {\n    targetDir=${1:-default-config}\n
    \   echo \"Processing pipelines and creating output in $targetDir\"\n    mkdir
    -p $targetDir\n    for json in *.json ; do\n      [[ -f \"$json\" ]] || continue\n
    \     echo \"\tprocessing $json\"\n      cat \"$json\" | jq '.parameterConfig
    | reduce .[] as $p  ({};.Parameters += {($p.name): $p.default})'  >  $targetDir/tmp-param.json
    2>/dev/null\n      cat \"$json\" | jq '.triggers[0] '  >  $targetDir/tmp-trig.json
    2>/dev/null\n\n      if [[ `cat $targetDir/tmp-trig.json | wc -c` -gt 5 ]]\n      then\n
    \       cat $targetDir/tmp-param.json | jq '.triggerValues=$pp' --argfile pp $targetDir/tmp-trig.json
    > $targetDir/\"$json\" 2>/dev/null\n      else\n        cp  $targetDir/tmp-param.json
    $targetDir/\"$json\"\n      fi\n    done\n    rm -f $targetDir/tmp-param.json\n
    \   rm -f $targetDir/tmp-trig.json\n    #Remove all files with zero size\n    echo
    \"Removing files that do not have any parameters defined\"\n    find $targetDir
    -type f -size -4c -delete # No parameterConfig in the file\n    #find $targetDir
    -type f -size -4c -print -delete # No parameterConfig in the file\n}\n\nequate_pipelines_in_app()
    {\n\n #This function will comapre the applications and pipelines in git and spinnaker
    and gives the additional pipelines data\n\n  IFS=',' read -r -a spinnaker_app_array
    <<< \"$spinnaker_app\"\n\n  IFS=',' read -r -a spinnaker_pipe_array <<< \"$spinnaker_pipe\"\n\n
    \ for (( m=0; m<${#spinnaker_app_array[@]}; m++ )); do\n     sourceApp=${spinnaker_app_array[$m]}\n\n
    \    touch $projectdir/live_backup/$sourceApp/odd_pipeline_id.txt\n\n\t\t echo
    $projectdir\n\t\t echo $git_project_work_dir\n\t\t echo $sourceApp\n     diff
    $projectdir/$git_project_work_dir/$sourceApp/pipelines_guid.list $projectdir/live_backup/$sourceApp/live_pipelines_guid.list
    | awk '{print $2}' | sed 1d > $projectdir/live_backup/$sourceApp/odd_pipeline_id.txt\n\n
    \    #list all existing spinnaker pipelines with app as reference\n     spin -k
    pipeline list --application $sourceApp > $projectdir/live_backup/$sourceApp/$sourceApp-pipeline_list.json\n
    \    touch $projectdir/live_backup/$sourceApp/odd_pipeline.txt\n\n     while IFS=
    read -r id; do\n     #Extract the pipeline names using guids as reference\n     cat
    $projectdir/live_backup/$sourceApp/$sourceApp-pipeline_list.json | jq '.[] | select
    (.id==\"'$id'\") | .name' -r >> $projectdir/live_backup/$sourceApp/odd_pipeline.txt\n
    \    done < $projectdir/live_backup/$sourceApp/odd_pipeline_id.txt\n  done\n}\n\nsyncup_spin()
    {\n  echo \"In Download function that updates the spinnaker instance with the
    contents in repo\"\n\n  #Backup of existing spinnaker pipelines with guids\n  live_backup_spin\n\n
    \ #Compare guids of existing pipelines and pipelines in git and provide names
    of additional pipelines\n  equate_pipelines_in_app\n\n  #Delete the extra pipelines(pipelines
    in spinnaker and not in git)\n\tif [[ $delete_on_sync_spin == \"true\" ]]; then\n\t\tdelete_odd_pipelines\n\tfi\n\n\tif
    [[ $repo_type = \"s3\" ]]; then\n\t\tprojectdir=$tempdir/$root_folder\n\t\techo
    \"project dir at synup spin $projectdir\"\n\telse\n\n\t\tprojectdir=$tempdir/${git_repo}/$root_folder\n\tfi\n
    \ if [ -d \"$projectdir\" ]\n  then\n    echo \"given git_project_work_dir is
    present\"\n  else\n    echo \"given git_project_work_dir is not present therefore
    creating it\"\n    mkdir -p \"$projectdir/$git_project_work_dir\"\n  fi\n\n  cd
    $projectdir\n  spinnaker_app=$spinnaker_applications\n  IFS=',' read -r -a spinnaker_app_array
    <<< \"$spinnaker_app\"\n\n  spinnaker_pipe=$spinnaker_pipelines\n  #IFS=',' read
    -r -a spinnaker_pipe_array <<< \"k8s-deploy\"\n  IFS=',' read -r -a spinnaker_pipe_array
    <<< \"$spinnaker_pipe\"\n\n  echo $projectdir\n  for (( m=0; m<${#spinnaker_app_array[@]};
    m++ )); do\n     sourceApp=${spinnaker_app_array[$m]}\n     echo -e \"Processing
    application $sourceApp\\n\"\n     cd $sourceApp              # Get into the correct
    directory\n     if [ \"$?\" != \"0\" ]; then\n         echo \"ERROR: Unable to
    change to application directory: $sourceApp\"\n         return 1\n     fi\n\n
    \    #Create the application by default, we can have flag to for this later\n
    \    spin -k application save -f $sourceApp.json\n     retVal=$?\n     if [[ \"$retVal\"
    != \"0\" && \"$ignore_errors\" == \"false\" ]]; then\n         echo \"ERROR: spin
    application save $sourceApp\"\n         return 1\n     elif [[ \"$retVal\" !=
    \"0\" && \"$ignore_errors\" == \"true\" ]]; then\n         echo \"ERROR: spin
    application save $sourceApp, continuing\"\n         cd ..\n         continue\n
    \    fi\n     #sleep 30 # Give a few seconds after application creation\n\n     if
    [[ ${#spinnaker_pipe_array[@]} > 0 ]]; then\n         for (( p=0; p<${#spinnaker_pipe_array[@]};
    p++ )); do\n            pipeLine=${spinnaker_pipe_array[$p]}\n            echo
    -e \"    Processing pipeline $pipeLine\\n\"\n            # Check if pipeline file
    \ exists\n            if [ -f \"$pipeLine.json\" ]; then\n                #Update
    parameterConfig\n                if [[ \"$pipelineconfig\" == \"true\" ]]; then\n\n
    \                   mkdir -p temp\n                    update_params \"$pipeLine.json\"\n
    \                   rm -rf temp\n                fi\n               spin -k pipeline
    save --file \"$pipeLine.json\"\n               retVal=$?\n               if [[
    \"$retVal\" != \"0\" && \"$ignore_errors\" == \"false\" ]]; then\n                   echo
    \"ERROR: spin pipeline save --file $pipeLine.json\"\n                   return
    1\n               elif [[ \"$retVal\" != \"0\" && \"$ignore_errors\" == \"true\"
    ]]; then\n                   echo \"ERROR: spin pipeline save --file $pipeLine.json,
    continuing\"\n                   continue\n               fi\n            else\n
    \              echo \"WARNING: pipeline=${pipeLine} not found in application=$sourceApp
    ... skipping\"\n            fi\n         done\n     else # No pipelines defined,
    get all the pipelines\n         while read -r line; do\n            [[ -f \"$line.json\"
    ]] || continue\n            pipeLine=$line\n            echo -e \"    Processing
    pipeline $pipeLine\\n\"\n\n            #Update parameterConfig\n            if
    [[ \"$pipelineconfig\" == \"true\" ]]; then\n\t\t\t\t\t\t\techo \"in pipelineconfig
    else\"\n                mkdir -p temp\n                update_params \"$pipeLine.json\"\n
    \               #rm -rf temp\n            fi\n\n            echo `realpath $pipeLine.json`\n\t\t\t\t\t\tif
    test -f \"$pipeLine.json\"; then\n\t\t\t\t\t\t\tspin -k pipeline save --file \"$pipeLine.json\"\n\t\t\t\t\t\tfi\n\n
    \           retVal=$?\n            if [[ \"$retVal\" != \"0\" && \"$ignore_errors\"
    == \"false\"  ]]; then\n                echo \"ERROR: spin pipeline save --file
    $pipeLine.json\"\n                return 1\n            elif [[ \"$retVal\" !=
    \"0\" && \"$ignore_errors\" == \"true\" ]]; then\n                echo \"ERROR:
    spin pipeline save --file $pipeLine.json, continuing\"\n                continue\n
    \           fi\n           sleep 10 # Slow it down\n         done < pipelines_in_application.list\n
    \    fi\n     cd ..\n  done\n\n}\nget_pipelines_data(){\n\techo $1 \t\n\tlocal
    \ spinnaker_app=$1\n        IFS=',' read -r -a spinnaker_app_array <<< \"$spinnaker_app\"\n
    \       spinnaker_pipe=$spinnaker_pipelines\n        #IFS=',' read -r -a spinnaker_pipe_array
    <<< \"k8s-deploy\"\n        IFS=',' read -r -a spinnaker_pipe_array <<< \"$spinnaker_pipe\"\n\n\t\t\t\tif
    [[ $root_folder == \"\" ]]; then\n\t\t\t\t\troot_folder=\".\"\n\t\t\t\tfi\n        for
    (( m=0; m<${#spinnaker_app_array[@]}; m++ )); do\n     sourceApp=${spinnaker_app_array[$m]}\n
    \    echo -e \"Processing application $sourceApp\\n\"\n\n\t\t echo \"get pipelines
    data $root_folder\"\n     mkdir -p $tempdir/$git_repo/${root_folder}/$sourceApp
    ; cd $tempdir/$git_repo/${root_folder}/$sourceApp              # Get into the
    correct directory\n\n     get_app_pipelines $sourceApp\n     spin application
    get $sourceApp  > $sourceApp.json\n     if [ \"$?\" != \"0\" ]; then\n         echo
    \"ERROR: spin application get $sourceApp\"\n         return 1\n     fi\n     if
    [[ ${#spinnaker_pipe_array[@]} > 0 ]]; then\n         for (( p=0; p<${#spinnaker_pipe_array[@]};
    p++ )); do\n            pipeLine=${spinnaker_pipe_array[$p]}\n            echo
    -e \"    Processing pipeline $pipeLine\\n\"\n            # Check if pipeline exists\n
    \           existingPipe=`grep \\^${pipeLine}\\$ pipelines_in_application.list`\n
    \           if [[ \"$existingPipe\" == \"${pipeLine}\" ]]; then\n               spin
    pipeline get --application $sourceApp  --name \"$pipeLine\" > \"$pipeLine.json\"\n\n
    \              if [ \"$?\" != \"0\" ]; then\n                   echo \"ERROR:
    spin spin pipeline get --application $sourceApp  --name \\\"$pipeLine\\\"\"\n
    \                  return 1\n               fi\n            else\n               echo
    \"WARNING: pipeline=${pipeLine} not found in application=$sourceApp ... skipping\"\n
    \           fi\n         done\n     else # No pipelines defined, get all the pipelines\n
    \        while read -r line; do\n            echo -e \"    Processing pipeline
    $line\\n\"\n            spin pipeline get --application $sourceApp --name \"$line\"
    > \"$line.json\"\n            if [ \"$?\" != \"0\" ]; then\n                echo
    \"ERROR: spin spin pipeline get --application $sourceApp  --name $line\"\n                return
    1\n            fi\n\n         done < pipelines_in_application.list\n     fi\n
    \    if [[ \"$pipelinecreateconf\" == \"true\" ]]; then\n        create_default_params\n
    \    fi\n     cd -\n  done\n}\n\ndownload_spin() {\n  echo \"In Download function
    that updates the spinnaker instance with the contents in git\"\n  local user_root_folder=$root_folder\n\n
    \ if [ \"$git_secret_sshkey\" != \"\" ]; then\n    git_clone_ssh_change $user_root_folder
    $git_repo $git_project\n  elif [ \"$git_secret_token\" != \"\" ]; then\n    git_clone_http
    $user_root_folder $git_repo $git_project\n  else\n    echo \"git cloning requires
    either a git_secret_sshkey to be set or git_secret_token\"\n   exit 5\n  fi\n\n
    \ projectdir=$HOME/$git_project\n  cd $projectdir\n\n  spinnaker_app=$spinnaker_applications\n
    \ IFS=',' read -r -a spinnaker_app_array <<< \"$spinnaker_app\"\n\n  spinnaker_pipe=$spinnaker_pipelines\n
    \ #IFS=',' read -r -a spinnaker_pipe_array <<< \"k8s-deploy\"\n  IFS=',' read
    -r -a spinnaker_pipe_array <<< \"$spinnaker_pipe\"\n\n\n  for (( m=0; m<${#spinnaker_app_array[@]};
    m++ )); do\n     sourceApp=${spinnaker_app_array[$m]}\n     echo -e \"Processing
    application $sourceApp\\n\"\n     cd $sourceApp              # Get into the correct
    directory\n     if [ \"$?\" != \"0\" ]; then\n         echo \"ERROR: Unable to
    change to application directory: $sourceApp\"\n         return 1\n     fi\n\n
    \    #Create the application by default, we can have flag to for this later\n
    \    spin application save -f $sourceApp.json\n     retVal=$?\n     if [[ \"$retVal\"
    != \"0\" && \"$ignore_errors\" == \"false\" ]]; then\n         echo \"ERROR: spin
    application save $sourceApp\"\n         return 1\n     elif [[ \"$retVal\" !=
    \"0\" && \"$ignore_errors\" == \"true\" ]]; then\n         echo \"ERROR: spin
    application save $sourceApp, continuing\"\n         cd ..\n         continue\n
    \    fi\n     sleep 30 # Give a few seconds after application creation\n\n     if
    [[ ${#spinnaker_pipe_array[@]} > 0 ]]; then\n         for (( p=0; p<${#spinnaker_pipe_array[@]};
    p++ )); do\n            pipeLine=${spinnaker_pipe_array[$p]}\n            echo
    -e \"    Processing pipeline $pipeLine\\n\"\n            # Check if pipeline file
    \ exists\n            if [ -f \"$pipeLine.json\" ]; then\n                #Update
    parameterConfig\n                if [[ \"$pipelineconfig\" == \"true\" ]]; then\n
    \                   mkdir -p temp\n                    update_params \"$pipeLine.json\"\n
    \                   rm -rf temp\n                fi\n               spin pipeline
    save --file \"$pipeLine.json\"\n               retVal=$?\n               if [[
    \"$retVal\" != \"0\" && \"$ignore_errors\" == \"false\" ]]; then\n                   echo
    \"ERROR: spin pipeline save --file $pipeLine.json\"\n                   return
    1\n               elif [[ \"$retVal\" != \"0\" && \"$ignore_errors\" == \"true\"
    ]]; then\n                   echo \"ERROR: spin pipeline save --file $pipeLine.json,
    continuing\"\n                   continue\n               fi\n            else\n
    \              echo \"WARNING: pipeline=${pipeLine} not found in application=$sourceApp
    ... skipping\"\n            fi\n         done\n     else # No pipelines defined,
    get all the pipelines\n         while read -r line; do\n            [[ -f \"$line.json\"
    ]] || continue\n            pipeLine=$line\n            echo -e \"    Processing
    pipeline $pipeLine\\n\"\n\n            #Update parameterConfig\n            if
    [[ \"$pipelineconfig\" == \"true\" ]]; then\n                mkdir -p temp\n                update_params
    \"$pipeLine.json\"\n                #rm -rf temp\n            fi\n            spin
    pipeline save --file \"$pipeLine.json\"\n            retVal=$?\n            if
    [[ \"$retVal\" != \"0\" && \"$ignore_errors\" == \"false\"  ]]; then\n                echo
    \"ERROR: spin pipeline save --file $pipeLine.json\"\n                return 1\n
    \           elif [[ \"$retVal\" != \"0\" && \"$ignore_errors\" == \"true\" ]];
    then\n                echo \"ERROR: spin pipeline save --file $pipeLine.json,
    continuing\"\n                continue\n            fi\n            sleep 10 #
    Slow it down\n         done < pipelines_in_application.list\n     fi\n     cd
    ..\n  done\n\n}\n\nupdate_params() {\n    confDir=${pipelineconfigdir}\n    if
    [ ! -d \"$confDir\" ] ; then\n      echo \"Directory specified for configuratio
    ($confDir) not found in application directory\"\n      return\n    fi\n    if
    [ ! -f \"$confDir/$json\" ] ; then\n      echo \"INFO: No configuration found
    for $json in $confDir\"\n      return\n    fi\n    json=\"$1\"\n    echo \"Processing
    pipeline ($json) and updating pipelines as per configuration in $confDir\"\n    #Extract
    .parameterConfig\n    cat \"$json\" | jq '.parameterConfig' > temp/\"config-$json\"\n
    \   #Replace parameters\n    cat temp/\"config-$json\" | jq -f /home/opsmx/scripts/replace-params.jq
    --argfile pp $confDir/\"$json\" > temp/\"updated-config-$json\"\n\n    #Replace
    .parameterConfig\n    cat \"$json\" | jq  '.parameterConfig=$uc' --argfile uc
    temp/\"updated-config-$json\" > temp/\"$json\"\n\n    ########################################################################\n
    \   #Extract 1st trigger\n    cat  temp/\"$json\"| jq '.triggers[0]' > temp/tmp-trig.json\n
    \   #Update first trigger\n    cat temp/tmp-trig.json | jq 'if $pp.triggerValues
    != null then . * $pp.triggerValues else . end'  --argfile pp $confDir/\"$json\"
    \ > temp/updated-tmp-trig.json\n    #Update pipeline-json with updated trigger\n
    \   if [[ `cat temp/updated-tmp-trig.json | wc -c` -gt 5 ]]\n    then\n      cat
    temp/\"$json\" | jq '.triggers[0]=$pp' --argfile pp temp/updated-tmp-trig.json
    > temp/final-replaced.json\n      cp temp/final-replaced.json \"$json\"\n    else\n
    \     cp  temp/\"$json\" \"$json\"\n    fi\n    ########################################################################\n}\n"
  stash.sh: "#!/bin/bash\n\n#this script funtions only work for self hosted bitbucketserver/stash
    central repository\n#env variables needed for this to work are as below\n#***git_url=\"example.bitbucket.com\"
    make sure you dont add http/https or / in the url\n#****git_repo=\"pipelinepromotion\"
    repo to be pushed/download pipeline json files from\n#***git_project=\"kes\" project
    key is needed to clone/push/pull merge code\n#***git_user=\"tes.user\" user is
    needed for cloning and pusing changes (stash does not support only access key)\n#git_password=\"adjoowddaw\"
    make sure your password does not include special characters like # @*/. special
    characters cause git clone command to fail with https\n#***git_branch=\"testbranch\"
    the branch to which the code should be merged with\n#***merge_branch=false if
    true then provide all the below env variables\n#   git_secret_token=\"dafjaljoahfoasjoijso\"
    needed to create pull requests should be the git_users secret token\n#   git_pr_token=\"slkdfjaljoajfopaj\"
    this is approver token to approve pull requests / you can also provide approver
    password here.\n#   git_approve_user=\"test.approver\"  username of the pull request
    approver\n#\n# repo_type=\"stash\" for selfhosted bitbucket server please use
    stash as repo type\n#***root_folder=\"path/to/pipeline-promotion/folder\" folder
    to be selected in the repo to which the pipeline jobs to be pushed\n#***command=upload
    for running specific job -\n#                                         upload -
    to upload spinnaker pipeline json files to repo\n#                                         download
    - to download pipeline json file from repo and apply on spinnaker\n#***spinnaker_applications=\"testapp,sampleapp\"
    application needed to collect the pipeline information\n#spinnaker_pipelines=\"\"
    provide pipelines to be collected, if nothing given, all the pipelines of the
    application are collected\n#git_secret_sshkey=\"sshkey\" ssh key if you want to
    clone repo with ssh protocol\n\n# note *** env variables are mandatory to work
    with the script\n\nsource scripts/git.sh\ngit_repo=$repo_name\npr_id=0\npr_version=0\napprove_pr_stash(){\n
    \ approve_req=$(curl -k -o -I -L -s -w \"%{http_code}\"  -X POST -H \"Content-Type:
    application/json\" -u $git_approve_user:$git_pr_token \\\n  https://$git_api_url/${git_project}/repos/${git_repo}/pull-requests/${pr_id}/approve)\n
    \ echo $approve_req\n  if [[ $approve_req == \"200\" ]];then\n    echo \"merge
    request approved successfully\"\n  else\n    echo \"FAIL: failed to approve the
    request \"\n    exit 1\n  fi\n}\n\nmerge_pr_stash(){\n\n  merge_req=$(curl -k
    -o -I -L -s -w \"%{http_code}\"  -X POST -H \"Content-Type: application/json\"
    -u $git_user:$git_secret_token   \\\n  https://$git_api_url/${git_project}/repos/${git_repo}/pull-requests/${pr_id}/merge?version=$pr_version)\n
    \ echo $merge_req\n  if [ $merge_req == \"200\" ]; then\n    echo \"merged pr
    successfully\"\n  else\n    echo \"FAILED: failed to merge $merge_pr\"\n    exit
    1\nfi\n}\ncreate_pr_stash(){\n\n\tlocal output=$(curl -k -X POST -H \"Content-Type:
    application/json\" -u $git_user:$git_secret_token   https://$git_api_url/${git_project}/repos/${git_repo}/pull-requests
    -d '{\n    \"title\": \"merging '\"$git_branch\"' to '\"$target_branch\"'\",\n
    \   \"description\": \"changes from spinnaker pipeline jobs are to be merged to
    master\",\n    \"state\": \"OPEN\",\n    \"open\": true,\n    \"closed\": false,\n
    \   \"fromRef\": {\n        \"id\": \"refs/heads/'\"${git_branch}\"'\",\n        \"repository\":
    {\n            \"slug\": \"'\"${git_repo}\"'\",\n            \"name\": null,\n
    \           \"project\": {\n                \"key\": \"'\"${git_project}\"'\"\n
    \           }\n        }\n    },\n    \"toRef\": {\n        \"id\": \"refs/heads/'\"$target_branch\"'\",\n
    \       \"repository\": {\n            \"slug\": \"'\"${git_repo}\"'\",\n            \"name\":
    null,\n            \"project\": {\n                \"key\": \"'\"${git_project}\"'\"\n
    \           }\n        }\n    },\n    \"locked\": false\n}')\n  echo $output\n
    \ echo $output > pr_response.json\n  grep  \"is already up-to-date with branch\"
    pr_response.json\n  if [ \"$?\" = 0 ]\n  then\n    echo \"master branch is already
    up-to-date\"\n    exit 0\n  else\n    pr_id=$(cat  pr_response.json| jq '(.id)'
    | sed 's/\\\"//g')\n    pr_version=$(cat pr_response.json | jq '(.version)' |
    sed 's/\\\"//g')\n\n    if [ $? = 0 ]; then\n      echo \"successfully created
    pull request \"\n      #rm -f pr_response.json\n    else\n      echo \"ERROR:
    failed to raise pull request $output\"\n      exit 1\n  fi\nfi\n}\n\nsync_spin_to_stash(){\n
    \ #setup git configuration using email and username\n  setup_git\n  #upload spinnaker
    configuration to git\n  sync_spin_to_git\n  #check if custom port is being used
    for repo\n  if [[ $merge_branch == \"true\" && $target_branch != \"\" && ($git_branch
    != $target_branch)  ]];then\n    if [[ $git_api_url_port != \"\" ]];then\n      git_api_url=$git_api_url:$git_api_url_port\n
    \     create_pr_stash\n      if [[ $auto_merge == \"true\" ]]; then\n        approve_pr_stash\n
    \       merge_pr_stash\n      fi\n    else\n      create_pr_stash\n      if [[
    $auto_merge == \"true\" ]]; then\n        approve_pr_stash\n        merge_pr_stash\n
    \     fi\n    fi\n  fi\n}\n"
kind: ConfigMap
metadata:
  name: pipe-promot-scripts
---
# Source: oes/charts/minio/templates/pvc.yaml
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: isd-minio
  labels:
    app: minio
    chart: minio-8.0.9
    release: isd
    heritage: Helm
spec:
  accessModes:
    - "ReadWriteOnce"
  resources:
    requests:
      storage: "10Gi"
---
# Source: oes/charts/minio/templates/post-install-prometheus-metrics-role.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: isd-minio-update-prometheus-secret
  labels:
    app: minio-update-prometheus-secret
    chart: minio-8.0.9
    release: isd
    heritage: Helm
rules:
  - apiGroups:
      - ""
    resources:
      - secrets
    verbs:
      - get
      - create
      - update
      - patch
    resourceNames:
      - isd-minio-prometheus
  - apiGroups:
      - ""
    resources:
      - secrets
    verbs:
      - create
  - apiGroups:
      - monitoring.coreos.com
    resources:
      - servicemonitors
    verbs:
      - get
    resourceNames:
      - isd-minio
---
# Source: oes/charts/spinnaker/templates/rbac/spinnaker-role.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: spinnaker-role
rules:
  - apiGroups: ['']
    resources:
      [
        'namespaces',
        'events',
        'replicationcontrollers',
        'serviceaccounts',
        'pods/log',
      ]
    verbs: ['get', 'list']
  - apiGroups: ['']
    resources: ['pods', 'services', 'secrets', 'configmaps']
    verbs:
      [
        'create',
        'delete',
        'deletecollection',
        'get',
        'list',
        'patch',
        'update',
        'watch',
      ]
  - apiGroups: ['autoscaling']
    resources: ['horizontalpodautoscalers']
    verbs: ['list', 'get']
  - apiGroups: ['apps']
    resources: ['controllerrevisions', 'statefulsets']
    verbs: ['list']
  - apiGroups: ['extensions', 'apps']
    resources: ['deployments', 'replicasets', 'ingresses']
    verbs:
      [
        'create',
        'delete',
        'deletecollection',
        'get',
        'list',
        'patch',
        'update',
        'watch',
      ]
  # These permissions are necessary for halyard to operate. We use this role also to deploy Spinnaker itself.
  - apiGroups: ['']
    resources: ['services/proxy', 'pods/portforward']
    verbs:
      [
        'create',
        'delete',
        'deletecollection',
        'get',
        'list',
        'patch',
        'update',
        'watch',
      ]
  # These permissions are necessary for halyard to operate. We use this role also to deploy Spinnaker itself.
  - apiGroups: ['batch']
    resources: ['jobs']
    verbs:
      [
        'create',
        'delete',
        'get',
        'list',
        'update',
        'watch',
      ]
---
# Source: oes/templates/forwarder/create-controller-secret.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: create-controller-secret
rules:
- apiGroups: [""]
  resources: ["secrets"]
  verbs: ["get","list","create","update","patch"]
---
# Source: oes/charts/minio/templates/post-install-prometheus-metrics-rolebinding.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: isd-minio-update-prometheus-secret
  labels:
    app: minio-update-prometheus-secret
    chart: minio-8.0.9
    release: isd
    heritage: Helm
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: isd-minio-update-prometheus-secret
subjects:
  - kind: ServiceAccount
    name: isd-minio-update-prometheus-secret
    namespace: "opsmx-isd"
---
# Source: oes/charts/spinnaker/templates/rbac/rolebinding.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: isd-spinnaker-halyard
  labels:
    app: "isd-spinnaker"
    heritage: "Helm"
    release: "isd"
    chart: "spinnaker-2.2.3"
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role                 # ClusterRole, if we have access to cluster resources
  name: spinnaker-role       # edit, if we have the access
subjects:
- namespace: opsmx-isd
  kind: ServiceAccount
  name: isd-spinnaker-halyard
---
# Source: oes/charts/spinnaker/templates/rbac/spinnaker-sa.yaml
# In the case of a local cluster Spinnaker needs
# to be able to deploy to all namespaces in the cluster.
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding  # ClusterRoleBinding, if we have access accross the cluster
metadata:
  name: isd-spinnaker-spinnaker
  labels:
    app: "isd-spinnaker"
    heritage: "Helm"
    release: "isd"
    chart: "spinnaker-2.2.3"
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role             # ClusteRoleBinding if we have access accross the cluster
  name: spinnaker-role   # cluster-admin if we have the access
subjects:
- namespace: opsmx-isd
  kind: ServiceAccount
  # Clouddriver does not currently allow config of its
  # service account.
  name: default
---
# Source: oes/templates/forwarder/create-controller-secret.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: create-controller-secret
subjects:
- kind: ServiceAccount
  name: create-controller-secret
roleRef:
  kind: Role
  name: create-controller-secret
  apiGroup: rbac.authorization.k8s.io
---
# Source: oes/templates/rbac/oes-init-rolebinding.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding # ClusterRole if you have cluster access
metadata:
  name: opsmx-isd-oes-access
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: view
subjects:
- namespace: opsmx-isd
  kind: ServiceAccount
  name: default
---
# Source: oes/charts/gitea/charts/memcached/templates/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: isd-memcached
  namespace: opsmx-isd
  labels:
    app.kubernetes.io/name: memcached
    helm.sh/chart: memcached-5.9.0
    app.kubernetes.io/instance: isd
    app.kubernetes.io/managed-by: Helm
  annotations:
spec:
  type: ClusterIP
  ports:
    - name: memcache
      port: 11211
      targetPort: memcache
      nodePort: null
  selector:
    app.kubernetes.io/name: memcached
    app.kubernetes.io/instance: isd
---
# Source: oes/charts/gitea/charts/postgresql/templates/svc-headless.yaml
apiVersion: v1
kind: Service
metadata:
  name: isd-postgresql-headless
  labels:
    app.kubernetes.io/name: postgresql
    helm.sh/chart: postgresql-10.3.17
    app.kubernetes.io/instance: isd
    app.kubernetes.io/managed-by: Helm
    # Use this annotation in addition to the actual publishNotReadyAddresses
    # field below because the annotation will stop being respected soon but the
    # field is broken in some versions of Kubernetes:
    # https://github.com/kubernetes/kubernetes/issues/58662
    service.alpha.kubernetes.io/tolerate-unready-endpoints: "true"
  namespace: opsmx-isd
spec:
  type: ClusterIP
  clusterIP: None
  # We want all pods in the StatefulSet to have their addresses published for
  # the sake of the other Postgresql pods even before they're ready, since they
  # have to be able to talk to each other in order to become ready.
  publishNotReadyAddresses: true
  ports:
    - name: tcp-postgresql
      port: 5432
      targetPort: tcp-postgresql
  selector:
    app.kubernetes.io/name: postgresql
    app.kubernetes.io/instance: isd
---
# Source: oes/charts/gitea/charts/postgresql/templates/svc.yaml
apiVersion: v1
kind: Service
metadata:
  name: isd-postgresql
  labels:
    app.kubernetes.io/name: postgresql
    helm.sh/chart: postgresql-10.3.17
    app.kubernetes.io/instance: isd
    app.kubernetes.io/managed-by: Helm
  annotations:
  namespace: opsmx-isd
spec:
  type: ClusterIP
  ports:
    - name: tcp-postgresql
      port: 5432
      targetPort: tcp-postgresql
  selector:
    app.kubernetes.io/name: postgresql
    app.kubernetes.io/instance: isd
    role: primary
---
# Source: oes/charts/gitea/templates/gitea/http-svc.yaml
apiVersion: v1
kind: Service
metadata:
  name: isd-gitea-http
  labels:
    helm.sh/chart: gitea-5.0.1
    app: gitea
    app.kubernetes.io/name: gitea
    app.kubernetes.io/instance: isd
    app.kubernetes.io/version: "1.15.10"
    version: "1.15.10"
    app.kubernetes.io/managed-by: Helm
  annotations:
    null
spec:
  type: ClusterIP
  clusterIP: None
  ports:
  - name: http
    port: 3000
    targetPort: 3000
  selector:
    app.kubernetes.io/name: gitea
    app.kubernetes.io/instance: isd
---
# Source: oes/charts/gitea/templates/gitea/ssh-svc.yaml
apiVersion: v1
kind: Service
metadata:
  name: isd-gitea-ssh
  labels:
    helm.sh/chart: gitea-5.0.1
    app: gitea
    app.kubernetes.io/name: gitea
    app.kubernetes.io/instance: isd
    app.kubernetes.io/version: "1.15.10"
    version: "1.15.10"
    app.kubernetes.io/managed-by: Helm
  annotations:
    null
spec:
  type: ClusterIP
  clusterIP: None
  ports:
  - name: ssh
    port: 22
    targetPort: 22
    protocol: TCP
  selector:
    app.kubernetes.io/name: gitea
    app.kubernetes.io/instance: isd
---
# Source: oes/charts/minio/templates/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: isd-minio
  labels:
    app: minio
    chart: minio-8.0.9
    release: isd
    heritage: Helm
spec:
  type: ClusterIP
  ports:
    - name: http
      port: 9000
      protocol: TCP
      targetPort: 9000
  selector:
    app: minio
    release: isd
---
# Source: oes/charts/openldap/templates/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: isd-openldap
  labels:
    app: openldap
    chart: openldap-1.2.3
    release: isd
    heritage: Helm
spec:
  ports:
    - name: ldap-port
      protocol: TCP
      port: 389
      targetPort: ldap-port
    - name: ssl-ldap-port
      protocol: TCP
      port: 636
      targetPort: ssl-ldap-port
  selector:
    app: openldap
    release: isd
  type: ClusterIP
---
# Source: oes/charts/redis/templates/headless-svc.yaml
apiVersion: v1
kind: Service
metadata:
  name: isd-redis-headless
  labels:
    app: redis
    chart: redis-10.5.3
    release: isd
    heritage: Helm
spec:
  type: ClusterIP
  clusterIP: None
  ports:
  - name: redis
    port: 6379
    targetPort: redis
  selector:
    app: redis
    release: isd
---
# Source: oes/charts/redis/templates/redis-master-svc.yaml
apiVersion: v1
kind: Service
metadata:
  name: isd-redis-master
  labels:
    app: redis
    chart: redis-10.5.3
    release: isd
    heritage: Helm
spec:
  type: ClusterIP
  ports:
  - name: redis
    port: 6379
    targetPort: redis
  selector:
    app: redis
    release: isd
    role: master
---
# Source: oes/charts/spinnaker/templates/services/halyard.yaml
apiVersion: v1
kind: Service
metadata:
  name: isd-spinnaker-halyard
  labels:
    app: "isd-spinnaker"
    heritage: "Helm"
    release: "isd"
    chart: "spinnaker-2.2.3"
    component: halyard
spec:
  ports:
  - port: 8064
    name: daemon
  clusterIP: None
  selector:
    app: isd-spinnaker
    component: halyard
---
# Source: oes/templates/forwarder/oes-forwarder-svc-agent.yaml
apiVersion: v1
kind: Service
metadata:
  name: opsmx-controller-controller1
  labels:
    agent.opsmx.com/name: controller1
    agent.opsmx.com/role: controller
    heritage: "Helm"
    release: "isd"
    chart: "oes-3.12.2"
spec:
  selector:
    app: opsmx-controller-controller1
  type: ClusterIP
  ports:
  - name: service-api
    port: 9002
    targetPort: service-api
  - name: control-api
    port: 9003
    targetPort: control-api
  - name: remote-command
    port: 9004
    targetPort: remote-command
---
# Source: oes/templates/forwarder/oes-forwarder-svc-agent.yaml
apiVersion: v1
kind: Service
metadata:
  name: agent-grpc
  labels:
    agent.opsmx.com/name: controller1
    agent.opsmx.com/role: controller
    heritage: "Helm"
    release: "isd"
    chart: "oes-3.12.2"
spec:
  selector:
    app: opsmx-controller-controller1
  type: LoadBalancer
  ports:
  - name: agent-grpc
    port: 9001
---
# Source: oes/templates/forwarder/oes-forwarder-svc-ipc.yaml
apiVersion: v1
kind: Service
metadata:
  name: opsmx-controller-controller1-interproc
  labels:
    agent.opsmx.com/name: controller1
    agent.opsmx.com/role: controller
    heritage: "Helm"
    release: "isd"
    chart: "oes-3.12.2"
spec:
  selector:
    app: opsmx-controller-controller1
  type: ClusterIP
  ports:
  - name: agent-grpc
    port: 9001
    targetPort: agent-grpc
---
# Source: oes/templates/sapor-gate/sapor-gate-service.yaml
apiVersion: v1
kind: Service
metadata:
  labels:
    app: spin
    component: sapor-gate
    heritage: "Helm"
    release: "isd"
    chart: "oes-3.12.2"
  name: sapor-gate
spec:
  type: ClusterIP
  ports:
  - name: "sapor-gate-service"
    port: 8084
    protocol: TCP
    targetPort: 8084
  selector:
    app: oes
    component: sapor-gate
---
# Source: oes/templates/services/oes-auditclient-service.yaml
apiVersion: v1
kind: Service
metadata:
  labels:
    app: oes
    component: auditclient
    heritage: "Helm"
    release: "isd"
    chart: "oes-3.12.2"
  name: oes-audit-client
spec:
  ports:
  - name: auditclient
    port: 8098
    protocol: TCP
    targetPort: 8098
  selector:
    app: oes
    component: auditclient
  type: ClusterIP
---
# Source: oes/templates/services/oes-auditservice-service.yaml
apiVersion: v1
kind: Service
metadata:
  labels:
    app: oes
    component: auditservice
    heritage: "Helm"
    release: "isd"
    chart: "oes-3.12.2"
  name: oes-audit-service
spec:
  ports:
  - name: auditservice
    port: 8097
    protocol: TCP
    targetPort: 8097
  selector:
    app: oes
    component: auditservice
  type: ClusterIP
---
# Source: oes/templates/services/oes-autopilot-service.yaml
apiVersion: v1
kind: Service
metadata:
  labels:
    app: oes
    component: autopilot
    heritage: "Helm"
    release: "isd"
    chart: "oes-3.12.2"
  name: oes-autopilot
spec:
  type: ClusterIP
  ports:
  - name: "cas-service"
    port: 8090
    targetPort: 8090
  - name: "monitoring-service"
    port: 9090
    targetPort: 9090
  selector:
    app: oes
    component: autopilot
---
# Source: oes/templates/services/oes-dashboard-service.yaml
apiVersion: v1
kind: Service
metadata:
  labels:
    app: oes
    component: dashboard
    heritage: "Helm"
    release: "isd"
    chart: "oes-3.12.2"
  name: oes-dashboard
spec:
  type: ClusterIP
  ports:
  - name: dashboard
    protocol: TCP
    port: 8094
    targetPort: 8094
  selector:
    app: oes
    component: dashboard
---
# Source: oes/templates/services/oes-datascience-service.yaml
apiVersion: v1
kind: Service
metadata:
  labels:
    app: oes
    component: datascience
    heritage: "Helm"
    release: "isd"
    chart: "oes-3.12.2"
  name: oes-datascience
spec:
  ports:
  - name: datascience
    port: 5005
    protocol: TCP
    targetPort: 5005
  selector:
    app: oes
    component: datascience
  type: ClusterIP
---
# Source: oes/templates/services/oes-db-service.yaml
apiVersion: v1
kind: Service
metadata:
  labels:
    app: oes
    component: db
    heritage: "Helm"
    release: "isd"
    chart: "oes-3.12.2"
  name: oes-db
spec:
  type: ClusterIP
  ports:
  - name: db
    protocol: TCP
    port: 5432
    targetPort: 5432
  selector:
    app: oes
    component: db
---
# Source: oes/templates/services/oes-gate-service.yaml
apiVersion: v1
kind: Service
metadata:
  labels:
    app: oes
    component: gate
    heritage: "Helm"
    release: "isd"
    chart: "oes-3.12.2"
  name: oes-gate
spec:
  type: ClusterIP
  ports:
  - name: "https"
    port: 443
    targetPort: 8084
  - name: "oes-gate-service"
    port: 8084
    protocol: TCP
    targetPort: 8084
  - name: "http"
    port: 80
    targetPort: 8084
  selector:
    app: oes
    component: gate
---
# Source: oes/templates/services/oes-platform-service.yaml
apiVersion: v1
kind: Service
metadata:
  labels:
    app: oes
    component: platform
    heritage: "Helm"
    release: "isd"
    chart: "oes-3.12.2"
  name: oes-platform
spec:
  type: ClusterIP
  ports:
  - name: oes-platform
    protocol: TCP
    port: 8095
    targetPort: 8095
  selector:
    app: oes
    component: platform
---
# Source: oes/templates/services/oes-rabbitmq-service.yaml
apiVersion: v1
kind: Service
metadata:
  labels:
    app: oes
    component: rabbitmq
    heritage: "Helm"
    release: "isd"
    chart: "oes-3.12.2"
  name: rabbitmq-service
spec:
  ports:
  - name: rabbitmq
    port: 5672
    protocol: TCP
    targetPort: 5672
  - name: rabbitmq-mgmt
    port: 15672
    protocol: TCP
    targetPort: 15672
  selector:
    app: oes
    component: rabbitmq
  type: ClusterIP
---
# Source: oes/templates/services/oes-sapor-service.yaml
apiVersion: v1
kind: Service
metadata:
  labels:
    app: oes
    component: sapor
    heritage: "Helm"
    release: "isd"
    chart: "oes-3.12.2"
  name: oes-sapor
spec:
  type: ClusterIP
  ports:
  - name: "sapor"
    port: 8085
    targetPort: 8085
  selector:
    app: oes
    component: sapor
---
# Source: oes/templates/services/oes-ui-service.yaml
apiVersion: v1
kind: Service
metadata:
  labels:
    app: oes
    component: ui
    heritage: "Helm"
    release: "isd"
    chart: "oes-3.12.2"
  name: oes-ui
spec:
  type: ClusterIP
  ports:
  - name: "https"
    port: 443
    targetPort: 8080
  - name: "http"
    port: 8080
    targetPort: 8080
  selector:
    app: oes
    component: ui
---
# Source: oes/templates/services/oes-visibility-service.yaml
apiVersion: v1
kind: Service
metadata:
  labels:
    app: oes
    component: visibility 
    heritage: "Helm"
    release: "isd"
    chart: "oes-3.12.2"
  name: oes-visibility
spec:
  type: ClusterIP
  ports:
  - name: visibility 
    protocol: TCP
    port: 8096
    targetPort: 8096
  selector:
    app: oes
    component: visibility
---
# Source: oes/templates/services/opa-service.yaml
apiVersion: v1
kind: Service
metadata:
  name: opa
  labels:
    heritage: "Helm"
    release: "isd"
    chart: "oes-3.12.2"
spec:
  selector:
    app: opa
  ports:
  - protocol: TCP
    port: 8181
    targetPort: 8181
  type: ClusterIP
---
# Source: oes/templates/spinnaker-extra/spinsvcs.yaml
apiVersion: v1
kind: Service
metadata:
  labels:
    app: spin
    stack: deck
    heritage: "Helm"
    release: "isd"
    chart: "oes-3.12.2"
  name: spin-deck-lb
spec:
  type: ClusterIP
  ports:
   - name: "https"
     port: 443
     targetPort: 9000
   - name: "http"
     port: 80
     protocol: TCP
     targetPort: 9000
  selector:
    cluster: spin-deck
---
# Source: oes/templates/spinnaker-extra/spinsvcs.yaml
apiVersion: v1
kind: Service
metadata:
  labels:
    app: spin
    stack: gate
    heritage: "Helm"
    release: "isd"
    chart: "oes-3.12.2"
  name: spin-gate-lb
spec:
  type: ClusterIP
  ports:
   - name: https
     port: 443
     targetPort: 8084
   - name: "http"
     port: 80
     protocol: TCP
     targetPort: 8084
  selector:
    cluster: spin-gate
---
# Source: oes/charts/gitea/charts/memcached/templates/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: isd-memcached
  namespace: opsmx-isd
  labels:
    app.kubernetes.io/name: memcached
    helm.sh/chart: memcached-5.9.0
    app.kubernetes.io/instance: isd
    app.kubernetes.io/managed-by: Helm
spec:
  selector:
    matchLabels:
      app.kubernetes.io/name: memcached
      app.kubernetes.io/instance: isd
  replicas: 1
  template:
    metadata:
      labels:
        app.kubernetes.io/name: memcached
        helm.sh/chart: memcached-5.9.0
        app.kubernetes.io/instance: isd
        app.kubernetes.io/managed-by: Helm
    spec:
      
      affinity:
        podAffinity:
          
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
            - podAffinityTerm:
                labelSelector:
                  matchLabels:
                    app.kubernetes.io/name: memcached
                    app.kubernetes.io/instance: isd
                namespaces:
                  - "opsmx-isd"
                topologyKey: kubernetes.io/hostname
              weight: 1
        nodeAffinity:
          
      securityContext:
        fsGroup: 1001
        runAsUser: 1001
      serviceAccountName: isd-memcached
      containers:
        - name: memcached
          image: docker.io/bitnami/memcached:1.6.9-debian-10-r114
          imagePullPolicy: "IfNotPresent"
          args:
            - /run.sh
          env:
            - name: BITNAMI_DEBUG
              value: "false"
          ports:
            - name: memcache
              containerPort: 11211
          livenessProbe:
            tcpSocket:
              port: memcache
            initialDelaySeconds: 30
            timeoutSeconds: 5
            failureThreshold: 6
          readinessProbe:
            tcpSocket:
              port: memcache
            initialDelaySeconds: 5
            timeoutSeconds: 3
            periodSeconds: 5
          resources:
            limits: {}
            requests:
              cpu: 250m
              memory: 256Mi
          volumeMounts:
            - name: tmp
              mountPath: /tmp
          securityContext:
            readOnlyRootFilesystem: false
      volumes:
        - name: tmp
          emptyDir: {}
---
# Source: oes/charts/minio/templates/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: isd-minio
  labels:
    app: minio
    chart: minio-8.0.9
    release: isd
    heritage: Helm
spec:
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 100%
      maxUnavailable: 0
  selector:
    matchLabels:
      app: minio
      release: isd
  template:
    metadata:
      name: isd-minio
      labels:
        app: minio
        release: isd
      annotations:
        checksum/secrets: 0e7fab1c3058994997feaa92931063f8fc4c7f719d54fd3ef3459505a6a61533
        checksum/config: 7a7ac5513fcd53ca17fde80ebf50780809224b63001a3969ca32fcaf1caf5999
    spec:
      serviceAccountName: "isd-minio"
      securityContext:
        runAsUser: 1000
        runAsGroup: 1000
        fsGroup: 1000
      containers:
        - name: minio
          image: "minio/minio:RELEASE.2020-12-03T05-49-24Z"
          imagePullPolicy: IfNotPresent
          command:
            - "/bin/sh"
            - "-ce"
            - "/usr/bin/docker-entrypoint.sh minio -S /etc/minio/certs/ server /export"
          volumeMounts:
            - name: export
              mountPath: /export            
          ports:
            - name: http
              containerPort: 9000
          env:
            - name: MINIO_ACCESS_KEY
              valueFrom:
                secretKeyRef:
                  name: isd-minio
                  key: accesskey
            - name: MINIO_SECRET_KEY
              valueFrom:
                secretKeyRef:
                  name: isd-minio
                  key: secretkey
          resources:
            requests:
              memory: 4Gi      
      volumes:
        - name: export
          persistentVolumeClaim:
            claimName: isd-minio
        - name: minio-user
          secret:
            secretName: isd-minio
---
# Source: oes/charts/openldap/templates/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name:  isd-openldap
  labels:
    app: openldap
    chart: openldap-1.2.3
    release: isd
    heritage: Helm
spec:
  replicas: 1
  selector:
    matchLabels:
      app: openldap
      release: isd
  template:
    metadata:
      annotations:
        checksum/configmap-env: da8e0c8da82ff9254423b65018fe528f67823beb164b9f81ba49b04afd696558
        checksum/configmap-customldif: 3bf9905ca1d307472278add416a8fff6618651f0ef01b0dcaab0009017d48376
      labels:
        app: openldap
        release: isd
    spec:
      initContainers:
      - name: openldap-init-ldif
        image: quay.io/opsmxpublic/busybox:1.28
        command: ['sh', '-c', 'cp /customldif/* /ldifworkingdir']
        imagePullPolicy: IfNotPresent
        volumeMounts:
        - name: customldif
          mountPath: /customldif
        - name: ldifworkingdir
          mountPath: /ldifworkingdir
        resources:
          {}
      containers:
        - name: openldap
          image: "osixia/openldap:1.2.4"
          lifecycle:
            postStart:
              exec:
                command:
                - /bin/sh
                - -c
                - until service slapd status; do sleep 10 ;done;ldapadd -x -D 'cn=admin,dc=example,dc=org'
                  -w opsmxadmin123 -f /container/service/slapd/assets/config/bootstrap/ldif/custom/10-users.ldif
          imagePullPolicy: IfNotPresent
          args: [--copy-service]
          ports:
            - name: ldap-port
              containerPort: 389
            - name: ssl-ldap-port
              containerPort: 636
          envFrom:
            - configMapRef:
                name: isd-openldap-env
            - secretRef:
                name: isd-openldap
          volumeMounts:
            - name: data
              mountPath: /var/lib/ldap
              subPath: data
            - name: data
              mountPath: /etc/ldap/slapd.d
              subPath: config-data
            - name: ldifworkingdir
              mountPath: /container/service/slapd/assets/config/bootstrap/ldif/custom
          env:
          livenessProbe:
            tcpSocket:
              port: ldap-port
            initialDelaySeconds: 20
            periodSeconds: 10
            failureThreshold: 10
          readinessProbe:
            tcpSocket:
              port: ldap-port
            initialDelaySeconds: 20
            periodSeconds: 10
            failureThreshold: 10
          resources:
            {}
      volumes:
        - name: customldif
          configMap:
            name: isd-openldap-customldif
        - name: ldifworkingdir
          emptyDir: {}
        - name: certs
          emptyDir:
            medium: Memory
        - name: data
          emptyDir: {}
---
# Source: oes/templates/deployments/oes-audit-client.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app: oes
    component: auditclient
    heritage: "Helm"
    release: "isd"
    chart: "oes-3.12.2"
  name: oes-audit-client
spec:
  replicas: 1
  selector:
    matchLabels:
      app: oes
      component: auditclient
  template:
    metadata:
      annotations:
        configmap/checksum: 44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a
        prometheus.io/scrape: "true"
        prometheus_io_path: /mgmt/prometheus
        prometheus_io_port: "8098"
      labels:
        app: oes
        component: auditclient
        heritage: "Helm"
        release: "isd"
        chart: "oes-3.12.2"
    spec:
      containers:
      - image: quay.io/opsmxpublic/ubi8-oes-audit-client:v3.12.0 
        imagePullPolicy: IfNotPresent
        name: oes-audit-client
        ports:
        - containerPort: 8098
          name: backend
          protocol: TCP
        livenessProbe:
          failureThreshold: 3
          httpGet:
            path: /mgmt/health
            port: 8098
            scheme: HTTP
          initialDelaySeconds: 60
          periodSeconds: 60
          successThreshold: 1
          timeoutSeconds: 1
        readinessProbe:
          failureThreshold: 3
          initialDelaySeconds: 60
          periodSeconds: 10
          successThreshold: 1
          tcpSocket:
            port: 8098
        volumeMounts:
        - mountPath: /opsmx/conf/audit-client-local.yml
          name: audit-config-volume
          subPath: audit-local.yml
        - mountPath: /opsmx/conf/bootstrap.yml
          name: bootstrap-config-volume
          subPath: bootstrap.yml
        - mountPath: /opsmx/conf/standard-error-code.csv
          name: standard-error-conf
          subPath: standard-error-codes.csv
      imagePullSecrets:
      - name: opsmx11-secret
      volumes:
      - secret:
          items:
          - key: audit-local.yml
            path: audit-local.yml
          secretName: oes-audit-client-config
        name: audit-config-volume
      - name: bootstrap-config-volume
        secret:
          defaultMode: 420
          secretName: bootstrap
      - configMap:
          defaultMode: 420
          items:
          - key: standard-error-codes.csv
            path: standard-error-codes.csv
          name: standard-error-codes-config
        name: standard-error-conf
---
# Source: oes/templates/deployments/oes-audit-service.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app: oes
    component: auditservice
    heritage: "Helm"
    release: "isd"
    chart: "oes-3.12.2"
  name: oes-audit-service
spec:
  replicas: 1
  selector:
    matchLabels:
      app: oes
      component: auditservice
  template:
    metadata:
      annotations:
        configmap/checksum: 44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a
        prometheus.io/scrape: "true"
        prometheus_io_path: /mgmt/prometheus
        prometheus_io_port: "8097"
      labels:
        app: oes
        component: auditservice
        heritage: "Helm"
        release: "isd"
        chart: "oes-3.12.2"
    spec:
      containers:
      - image: quay.io/opsmxpublic/ubi8-oes-audit-service:v3.12.0
        imagePullPolicy: IfNotPresent
        name: oes-audit
        ports:
        - containerPort: 8097
          name: backend
          protocol: TCP
        livenessProbe:
          failureThreshold: 3
          httpGet:
            path: /mgmt/health
            port: 8097
            scheme: HTTP
          initialDelaySeconds: 60
          periodSeconds: 60
          successThreshold: 1
          timeoutSeconds: 1
        readinessProbe:
          failureThreshold: 3
          initialDelaySeconds: 60
          periodSeconds: 10
          successThreshold: 1
          tcpSocket:
            port: 8097
          timeoutSeconds: 1
        volumeMounts:
        - mountPath: /opsmx/conf/audit-service-local.yml
          name: audit-config-volume
          subPath: audit-local.yml
        - mountPath: /opsmx/conf/bootstrap.yml
          name: bootstrap-config-volume
          subPath: bootstrap.yml
        - mountPath: /opsmx/conf/standard-error-code.csv
          name: standard-error-conf
          subPath: standard-error-codes.csv
      imagePullSecrets:
      - name: opsmx11-secret
      volumes:
      volumes:
      - secret:
          items:
          - key: audit-local.yml
            path: audit-local.yml
          secretName: oes-audit-service-config
        name: audit-config-volume
      - name: bootstrap-config-volume
        secret:
          defaultMode: 420
          secretName: bootstrap
      - configMap:
          defaultMode: 420
          items:
          - key: standard-error-codes.csv
            path: standard-error-codes.csv
          name: standard-error-codes-config
        name: standard-error-conf
---
# Source: oes/templates/deployments/oes-autopilot-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: oes-autopilot
  labels:
    app: oes
    component: autopilot
    heritage: "Helm"
    release: "isd"
    chart: "oes-3.12.2"
spec:
  replicas: 1
  selector:
    matchLabels:
      app: oes
      component: autopilot
  template:
    metadata:
      labels:
        app: oes
        component: autopilot
        heritage: "Helm"
        release: "isd"
        chart: "oes-3.12.2"
      annotations:
        configmap/checksum: 44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a
        prometheus.io/scrape: "true"
        prometheus_io_path: /mgmt/prometheus
        prometheus_io_port: "8090"
    spec:
      volumes:
        - name: autopilot-config-volume
          secret:
            secretName: oes-autopilot-config
        - secret:
            items:
            - key: bootstrap.yml
              path: bootstrap.yml
            secretName: bootstrap
          name: bootstrap-config-volume
        - configMap:
            defaultMode: 420
            items:
            - key: standard-error-codes.csv
              path: standard-error-codes.csv
            name: standard-error-codes-config
          name: standard-error-conf
      imagePullSecrets:
      - name: opsmx11-secret
      initContainers:
      - name: db-check
        image: quay.io/opsmxpublic/postgres:9.6.5
        command: ['/bin/bash', '-c', "sleep 30;echo Waiting for oes-db to be up and running; pg_isready -h oes-db -p 5432 && echo PostgreSQL DB is ready to receive connections"]
      containers:
        - image: quay.io/opsmxpublic/ubi8-oes-autopilot:v3.12.0
          imagePullPolicy: IfNotPresent
          name: oes-autopilot
          resources:
            {}
          ports:
            - containerPort: 8090
              name: backend
              protocol: TCP
            - containerPort: 9090
              name: metricfetcher
              protocol: TCP
          volumeMounts:
          - name: autopilot-config-volume
            mountPath: /opsmx/conf/autopilot.properties
            subPath: autopilot.properties
          - mountPath: /opsmx/conf/bootstrap.yml
            name: bootstrap-config-volume
            subPath: bootstrap.yml
          - mountPath: /opsmx/conf/standard-error-code.csv
            name: standard-error-conf
            subPath: standard-error-codes.csv
          readinessProbe:
            tcpSocket:
              port: 8090
            initialDelaySeconds: 60
            periodSeconds: 10
          livenessProbe:
            httpGet:
              path: /mgmt/health
              port: 8090
            initialDelaySeconds: 120
            periodSeconds: 60
---
# Source: oes/templates/deployments/oes-dashboard-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app: oes
    component: dashboard
    heritage: "Helm"
    release: "isd"
    chart: "oes-3.12.2"
  name: oes-dashboard
spec:
  replicas: 1
  selector:
    matchLabels:
      app: oes
      component: dashboard
  strategy: {}
  template:
    metadata:
      annotations:
        configmap/checksum: bfdbbd95b11053a548502713f0ae6f99111cd8f853d814981ca6ecf1c31231be
        prometheus.io/scrape: "true"
        prometheus_io_path: /mgmt/prometheus
        prometheus_io_port: "8094"
      labels:
        app: oes
        component: dashboard
        heritage: "Helm"
        release: "isd"
        chart: "oes-3.12.2"
    spec:
      containers:
      - image: quay.io/opsmxpublic/ubi8-oes-dashboard:v3.12.0
        name: oes-dashboard
        ports:
        - containerPort: 8094
          protocol: TCP
        env:
        volumeMounts:
        - mountPath: /opsmx/conf/dashboard-local.yml
          name: dashboard-config
          subPath: dashboard-local.yml
        - mountPath: /opsmx/conf/bootstrap.yml
          name: bootstrap-config-volume
          subPath: bootstrap.yml
        - mountPath: /opsmx/conf/standard-error-code.csv
          name: standard-error-conf
          subPath: standard-error-codes.csv
        resources:
            {}
        readinessProbe:
          tcpSocket:
            port: 8094
          initialDelaySeconds: 10
          periodSeconds: 5
        livenessProbe:
          httpGet:
            path: /mgmt/health
            port: 8094
          initialDelaySeconds: 30
          periodSeconds: 60
      imagePullSecrets:
      - name: opsmx11-secret
      volumes:
      - name: dashboard-config
        configMap:
          name: oes-dashboard-config
      - secret:
          items:
          - key: bootstrap.yml
            path: bootstrap.yml
          secretName: bootstrap
        name: bootstrap-config-volume
      - configMap:
          defaultMode: 420
          items:
          - key: standard-error-codes.csv
            path: standard-error-codes.csv
          name: standard-error-codes-config
        name: standard-error-conf
---
# Source: oes/templates/deployments/oes-datascience-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app: oes
    component: datascience
    heritage: "Helm"
    release: "isd"
    chart: "oes-3.12.2"
  name: oes-datascience
spec:
  replicas: 1
  selector:
    matchLabels:
      app: oes
      component: datascience
  template:
    metadata:
      annotations:
        configmap/checksum: 44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a
        prometheus.io/scrape: "true"
        prometheus_io_path: /mgmt/prometheus
        prometheus_io_port: "5005"
      labels:
        app: oes
        component: datascience
        heritage: "Helm"
        release: "isd"
        chart: "oes-3.12.2"
    spec:
      containers:
      - image: quay.io/opsmxpublic/ubi8-oes-datascience:v3.12.0
        imagePullPolicy: IfNotPresent
        name: oes-datascience
        ports:
        - containerPort: 5005
          name: backend
          protocol: TCP
        readinessProbe:
          failureThreshold: 3
          initialDelaySeconds: 60
          periodSeconds: 10
          successThreshold: 1
          tcpSocket:
            port: 5005
          timeoutSeconds: 1
        volumeMounts:
        - mountPath: /home/ubuntu/.aws/credentials
          name: datascience-config-volume
          subPath: minio-credentials
        - mountPath: /home/ubuntu/datascience/app_config.yaml
          name: datascience-config-volume
          subPath: app-config.yml
      imagePullSecrets:
      - name: opsmx11-secret
      volumes:
      - secret:
          secretName: oes-datascience-config
        name: datascience-config-volume
---
# Source: oes/templates/deployments/oes-gate-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app: oes
    component: gate
    heritage: "Helm"
    release: "isd"
    chart: "oes-3.12.2"
  name: oes-gate
spec:
  replicas: 1
  selector:
    matchLabels:
      app: oes
      component: gate
  template:
    metadata:
      annotations:
        checksum/secret: 6eb66e6ecf09147886157b6f4d9334f13c026f49ab6bc41091a4d1bb91110873
        prometheus.io/scrape: "true"
        prometheus_io_path: /mgmt/prometheus
        prometheus_io_port: "8084"
      labels:
        app: oes
        component: gate
        heritage: "Helm"
        release: "isd"
        chart: "oes-3.12.2"
    spec:
      containers:
      - image: quay.io/opsmxpublic/ubi8-gate:v3.12.0.1
        name: oes-gate
        env:
        - name: spring_profiles_active
          value: vault,local
        ports:
        - containerPort: 8084
          protocol: TCP
        resources:
            {}
        volumeMounts:
        - name: gate-volume
          mountPath: /opt/spinnaker/config/gate.yml
          subPath: gate.yml
        - mountPath: /opt/spinnaker/config/bootstrap.yml
          name: bootstrap-volume
          subPath: bootstrap.yml
        readinessProbe:
          tcpSocket:
            port: 8084
          initialDelaySeconds: 60
          periodSeconds: 30
        livenessProbe:
          httpGet:
            path: /health
            port: 8084
          initialDelaySeconds: 60
          periodSeconds: 60
      imagePullSecrets:
      - name: opsmx11-secret
      volumes:
      - name: gate-volume
        secret:
          secretName: oes-gate-config
      - secret:
          items:
          - key: bootstrap.yml
            path: bootstrap.yml
          secretName: bootstrap
        name: bootstrap-volume
---
# Source: oes/templates/deployments/oes-platform-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  creationTimestamp: null
  labels:
    app: oes
    component: platform
    heritage: "Helm"
    release: "isd"
    chart: "oes-3.12.2"
  name: oes-platform
spec:
  replicas: 1
  selector:
    matchLabels:
      app: oes
      component: platform
  strategy: {}
  template:
    metadata:
      annotations:
        configmap/checksum: 370b45cb8c2cb25c248dabe3c66ade76cccd149aeccd8859b5c3f7e1939ce7d7
        prometheus.io/scrape: "true"
        prometheus_io_path: /mgmt/prometheus
        prometheus_io_port: "8095"
      labels:
        app: oes
        component: platform
        heritage: "Helm"
        release: "isd"
        chart: "oes-3.12.2"
    spec:
      initContainers:
      - name: db-check
        image: quay.io/opsmxpublic/postgres:9.6.5
        command: ['/bin/bash', '-c', "sleep 30;echo Waiting for oes-db to be up and running; pg_isready -h oes-db -p 5432 && echo PostgreSQL DB is ready to receive connections"]
      containers:
      - image: quay.io/opsmxpublic/ubi8-oes-platform:v3.12.0
        name: oes-platform
        ports:
        - containerPort: 8095
          protocol: TCP
        env:
        resources:
            {}
        readinessProbe:
          tcpSocket:
            port: 8095
          initialDelaySeconds: 10
          periodSeconds: 5
        livenessProbe:
          httpGet:
            path: /mgmt/health
            port: 8095
          initialDelaySeconds: 60
          periodSeconds: 60
        volumeMounts:
        - mountPath: /opsmx/conf/platform-local.yml
          name: platform-config-volume
          subPath: platform-local.yml
        - mountPath: /opsmx/conf/bootstrap.yml
          name: bootstrap-config-volume
          subPath: bootstrap.yml
        - mountPath: /opsmx/conf/standard-error-code.csv
          name: standard-error-conf
          subPath: standard-error-codes.csv
      imagePullSecrets:
      - name: opsmx11-secret
      volumes:
      - name: platform-config-volume
        secret:
          secretName: oes-platform-config
      - secret:
          items:
          - key: bootstrap.yml
            path: bootstrap.yml
          secretName: bootstrap
        name: bootstrap-config-volume
      - configMap:
          defaultMode: 420
          items:
          - key: standard-error-codes.csv
            path: standard-error-codes.csv
          name: standard-error-codes-config
        name: standard-error-conf
---
# Source: oes/templates/deployments/oes-rabbitmq-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app: oes
    component: rabbitmq
    heritage: "Helm"
    release: "isd"
    chart: "oes-3.12.2"
  name: rabbitmq
spec:
  replicas: 1
  selector:
    matchLabels:
      app: oes
      component: rabbitmq
  template:
    metadata:
      labels:
        app: oes
        component: rabbitmq
        heritage: "Helm"
        release: "isd"
        chart: "oes-3.12.2"
    spec:
      containers:
      - image: quay.io/opsmxpublic/rabbitmq:3-management
        imagePullPolicy: IfNotPresent
        name: rabbitmq
        ports:
        - containerPort: 5672
          protocol: TCP
        resources: {}
      imagePullSecrets:
      - name: opsmx11-secret
      restartPolicy: Always
      securityContext:
        fsGroup: 1000
---
# Source: oes/templates/deployments/oes-sapor-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app: oes
    component: sapor
    heritage: "Helm"
    release: "isd"
    chart: "oes-3.12.2"
  name: oes-sapor
spec:
  replicas: 1
  selector:
    matchLabels:
      app: oes
      component: sapor
  template:
    metadata:
      annotations:
        checksum/configmap: e5bbe1062923bd0b7a269fab69a7dea06804a70ab24f6a7d14e4cd97347ecb38
        checksum/configmap: 44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a
        prometheus.io/scrape: "true"
        prometheus_io_path: /mgmt/prometheus
        prometheus_io_port: "8085"
      labels:
        app: oes
        component: sapor
        heritage: "Helm"
        release: "isd"
        chart: "oes-3.12.2"
    spec:
      initContainers:
      - name: db-check
        image: quay.io/opsmxpublic/postgres:9.6.5
        command: ['/bin/bash', '-c', "sleep 30;echo Waiting for oes-db to be up and running; pg_isready -h oes-db -p 5432 && echo PostgreSQL DB is ready to receive connections"]
      containers:
      - image: quay.io/opsmxpublic/ubi8-oes-sapor:v3.12.0
        name: oes-sapor
        env:
        ports:
        - containerPort: 8085
          protocol: TCP
        volumeMounts:
        - mountPath: /opt/opsmx/controller/ca.crt	
          name: ca-certs-volume	
          subPath: tls.crt	
        - mountPath: /opt/opsmx/controller/cert/tls.crt	
          name: certs-volume	
          subPath: tls.crt	
        - mountPath: /opt/opsmx/controller/cert/tls.key	
          name: certs-volume	
          subPath: tls.key
        - name: sapor-config-volume
          mountPath: /opt/opsmx/application.yml
          subPath: application.yml
        - mountPath: /opt/opsmx/bootstrap.yml
          name: bootstrap-config-volume
          subPath: bootstrap.yml
        - mountPath: /opsmx/conf/standard-error-code.csv
          name: standard-error-conf
          subPath: standard-error-codes.csv
        resources:
            {}
        readinessProbe:
          tcpSocket:
            port: 8085
          initialDelaySeconds: 60
          periodSeconds: 10
          failureThreshold: 10
        livenessProbe:
          httpGet:
            path: /mgmt/health
            port: 8085
          initialDelaySeconds: 60
          periodSeconds: 10
          failureThreshold: 10
      imagePullSecrets:
      - name: opsmx11-secret
      volumes:
      - secret:
          secretName: oes-control-secret
        name: certs-volume
      - secret:
          secretName: ca-secret
        name: ca-certs-volume
      - secret:
          secretName: oes-sapor-config
        name: sapor-config-volume
      - secret:
          items:
          - key: bootstrap.yml
            path: bootstrap.yml
          secretName: sapor-bootstrap
        name: bootstrap-config-volume
      - configMap:
          defaultMode: 420
          items:
          - key: standard-error-codes.csv
            path: standard-error-codes.csv
          name: standard-error-codes-config
        name: standard-error-conf
---
# Source: oes/templates/deployments/oes-ui-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app: oes
    component: ui
    heritage: "Helm"
    release: "isd"
    chart: "oes-3.12.2"
  name: oes-ui
spec:
  replicas: 1
  selector:
    matchLabels:
      app: oes
      component: ui
  template:
    metadata:
      annotations:
        checksum/configmap: ec1928c046c894ea0592049ca7ba025a7b4a3760cc5ec54f4bcffe0637d0d957
      labels:
        app: oes
        component: ui
        heritage: "Helm"
        release: "isd"
        chart: "oes-3.12.2"
    spec:
      containers:
      - image: quay.io/opsmxpublic/ubi8-oes-ui:v3.12.0
        name: oes-ui
        ports:
        - containerPort: 8080
          protocol: TCP
        volumeMounts:
        - name: config-dir
          mountPath: /var/www/html/ui/assets/config/app-config.json
          subPath: app-config.json
        - name: config-dir
          mountPath: /var/www/html/ui/assets/config/help-text.json
          subPath: help-text.json
        - mountPath: /etc/nginx/nginx.conf
          name: nginx-config
          subPath: nginx.conf
        readinessProbe:
          tcpSocket:
            port: 8080
          initialDelaySeconds: 15
          periodSeconds: 5
        livenessProbe:
          httpGet:
            path: /ui/indexl.html
            port: 8080
          initialDelaySeconds: 15
          periodSeconds: 5
      imagePullSecrets:
      - name: opsmx11-secret
      volumes:
      - configMap:
          defaultMode: 420
          name: oes-ui-config
        name: config-dir
      - configMap:
          defaultMode: 420
          name: oes-ui-nginxconf
        name: nginx-config
---
# Source: oes/templates/deployments/oes-visibility-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app: oes
    component: visibility
    heritage: "Helm"
    release: "isd"
    chart: "oes-3.12.2"
  name: oes-visibility
spec:
  replicas: 1
  selector:
    matchLabels:
      app: oes
      component: visibility
  strategy: {}
  template:
    metadata:
      annotations:
        configmap/checksum: 465d5557f6b894754bb55c2d628709efb4df467f4c109040c6abd3a6ae94a159
        prometheus.io/scrape: "true"
        prometheus_io_path: /mgmt/prometheus
        prometheus_io_port: "8096"
      labels:
        app: oes
        component: visibility
        heritage: "Helm"
        release: "isd"
        chart: "oes-3.12.2"
    spec:
      initContainers:
      - name: db-check
        image: quay.io/opsmxpublic/postgres:9.6.5
        command: ['/bin/bash', '-c', "sleep 30;echo Waiting for oes-db to be up and running; pg_isready -h oes-db -p 5432 && echo PostgreSQL DB is ready to receive connections"]
      containers:
      - image: quay.io/opsmxpublic/ubi8-oes-visibility:v3.12.0
        name: oes-visibility
        ports:
        - containerPort: 8096
          protocol: TCP
        env:
        env:
        volumeMounts:
        - mountPath: /opsmx/conf/visibility-local.yml
          name: visibility-config
          subPath: visibility-local.yml
        - mountPath: /opsmx/conf/bootstrap.yml
          name: bootstrap-config-volume
          subPath: bootstrap.yml
        - mountPath: /opsmx/conf/standard-error-code.csv
          name: standard-error-conf
          subPath: standard-error-codes.csv
        resources:
            {}
        readinessProbe:
          tcpSocket:
            port: 8096
          initialDelaySeconds: 10
          periodSeconds: 5
        livenessProbe:
          httpGet:
            path: /mgmt/health
            port: 8096
          initialDelaySeconds: 30
          periodSeconds: 60
      imagePullSecrets:
      - name: opsmx11-secret
      volumes:
      - name: visibility-config
        secret:
          secretName: oes-visibility-config
      - secret:
          items:
          - key: bootstrap.yml
            path: bootstrap.yml
          secretName: bootstrap
        name: bootstrap-config-volume
      - configMap:
          defaultMode: 420
          items:
          - key: standard-error-codes.csv
            path: standard-error-codes.csv
          name: standard-error-codes-config
        name: standard-error-conf
---
# Source: oes/templates/deployments/opa-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app: opa
    heritage: "Helm"
    release: "isd"
    chart: "oes-3.12.2"
  name: opa
spec:
  replicas: 1
  selector:
    matchLabels:
      app: opa
  template:
    metadata:
      labels:
        app: opa
        heritage: "Helm"
        release: "isd"
        chart: "oes-3.12.2"
      name: opa
    spec:
      containers:
        - name: opa
          image: openpolicyagent/opa:latest
          args:
            - "run"
            - "--server"
        - name: opa-persist
          command: 
          - /bin/bash
          - /tmp/config/opa-persist.sh
          envFrom:
          - secretRef:
              name: oes-gate-secret
          image: quay.io/opsmxpublic/customterraformstage:v1
          imagePullPolicy: IfNotPresent
          volumeMounts:
          - mountPath: /tmp/config
            name: opa-persist
      imagePullSecrets:
      - name: opsmx11-secret
      restartPolicy: Always
      volumes:
        - configMap:
            defaultMode: 420
            name: opa-persist
          name: opa-persist
---
# Source: oes/templates/forwarder/oes-forwarder-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: opsmx-controller-controller1
  labels:
    agent.opsmx.com/name: controller1
    agent.opsmx.com/role: controller
    heritage: "Helm"
    release: "isd"
    chart: "oes-3.12.2"
spec:
  replicas: 1
  selector:
    matchLabels:
      app: opsmx-controller-controller1
  template:
    metadata:
      labels:
        app: opsmx-controller-controller1
        agent.opsmx.com/name: controller1
        agent.opsmx.com/role: controller
        heritage: "Helm"
        release: "isd"
        chart: "oes-3.12.2"
      annotations:
        pullversion: "16"
        checksum/configmap: 44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a
    spec:
      containers:
      - name: opsmx-controller-controller1
        image: quay.io/opsmxpublic/forwarder-controller:v3.12.0
        ports:
          - containerPort: 9001
            name: agent-grpc
          - containerPort: 9002
            name: service-api
          - containerPort: 9003
            name: control-api
          - containerPort: 9004
            name: remote-command
          - containerPort: 9102
            name: metrics
        env:
          - name: POD_NAMESPACE
            valueFrom:
              fieldRef:
                fieldPath: metadata.namespace
        volumeMounts:
        - name: config
          mountPath: /app/config
          readOnly: true
        - name: ca-secret
          mountPath: /app/secrets/ca
          readOnly: true
        - name: jwt-secret
          mountPath: /app/secrets/serviceAuth
          readOnly: true
        resources:
          requests:
            memory: "64Mi"
            cpu: "100m"
          limits:
            memory: "128Mi"
            cpu: "250m"
      volumes:
      - name: ca-secret
        secret:
          secretName: ca-secret
      - name: jwt-secret
        secret:
          secretName: jwt-secret
      - name: config
        configMap:
          name: opsmx-controller-controller1
          items:
          - key: "configFile"
            path: "config.yaml"
---
# Source: oes/templates/sapor-gate/sapor-gate-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  annotations:
  labels:
    app: oes
    component: sapor-gate
    heritage: "Helm"
    release: "isd"
    chart: "oes-3.12.2"
  name: sapor-gate
spec:
  replicas: 1
  selector:
    matchLabels:
      app: oes
      component: sapor-gate
  template:
    metadata:
      annotations:
        checksum/secret: dbcd073b40ed2c5ead5dc0dacd6e860686487ddd1854cc3b9dfc0724a9c455c1
      labels:
        app: oes
        component: sapor-gate
        heritage: "Helm"
        release: "isd"
        chart: "oes-3.12.2"
    spec:
      containers:
      - image: quay.io/opsmxpublic/ubi8-oes-spin-gate:v3.12.0
        name: sapor-gate
        env:
        - name: JAVA_OPTS
          value: -XX:MaxRAMPercentage=100.0
        - name: SPRING_PROFILES_ACTIVE
          value: overrides,local
        ports:
        - containerPort: 8084
          protocol: TCP
        resources:
            {}
        volumeMounts:
        - mountPath: /opt/spinnaker/config
          name: sapor-gate-files
        readinessProbe:
          failureThreshold: 3
          httpGet:
            path: /health
            port: 8084
            scheme: HTTP
          periodSeconds: 10
          successThreshold: 1
          timeoutSeconds: 1
      volumes:
      - name: sapor-gate-files
        secret:
          secretName: sapor-gate-files
---
# Source: oes/charts/gitea/charts/postgresql/templates/statefulset.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: isd-postgresql
  labels:
    app.kubernetes.io/name: postgresql
    helm.sh/chart: postgresql-10.3.17
    app.kubernetes.io/instance: isd
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: primary
  annotations:
  namespace: opsmx-isd
spec:
  serviceName: isd-postgresql-headless
  replicas: 1
  updateStrategy:
    type: RollingUpdate
  selector:
    matchLabels:
      app.kubernetes.io/name: postgresql
      app.kubernetes.io/instance: isd
      role: primary
  template:
    metadata:
      name: isd-postgresql
      labels:
        app.kubernetes.io/name: postgresql
        helm.sh/chart: postgresql-10.3.17
        app.kubernetes.io/instance: isd
        app.kubernetes.io/managed-by: Helm
        role: primary
        app.kubernetes.io/component: primary
    spec:      
      affinity:
        podAffinity:
          
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
            - podAffinityTerm:
                labelSelector:
                  matchLabels:
                    app.kubernetes.io/name: postgresql
                    app.kubernetes.io/instance: isd
                    app.kubernetes.io/component: primary
                namespaces:
                  - "opsmx-isd"
                topologyKey: kubernetes.io/hostname
              weight: 1
        nodeAffinity:
          
      securityContext:
        fsGroup: 1001
      containers:
        - name: isd-postgresql
          image: docker.io/bitnami/postgresql:11.11.0-debian-10-r62
          imagePullPolicy: "IfNotPresent"
          resources:
            requests:
              cpu: 250m
              memory: 256Mi
          securityContext:
            runAsUser: 1001
          env:
            - name: BITNAMI_DEBUG
              value: "false"
            - name: POSTGRESQL_PORT_NUMBER
              value: "5432"
            - name: POSTGRESQL_VOLUME_DIR
              value: "/bitnami/postgresql"
            - name: PGDATA
              value: "/bitnami/postgresql/data"
            - name: POSTGRES_POSTGRES_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: isd-postgresql
                  key: postgresql-postgres-password
            - name: POSTGRES_USER
              value: "gitea"
            - name: POSTGRES_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: isd-postgresql
                  key: postgresql-password
            - name: POSTGRES_DB
              value: "gitea"
            - name: POSTGRESQL_ENABLE_LDAP
              value: "no"
            - name: POSTGRESQL_ENABLE_TLS
              value: "no"
            - name: POSTGRESQL_LOG_HOSTNAME
              value: "false"
            - name: POSTGRESQL_LOG_CONNECTIONS
              value: "false"
            - name: POSTGRESQL_LOG_DISCONNECTIONS
              value: "false"
            - name: POSTGRESQL_PGAUDIT_LOG_CATALOG
              value: "off"
            - name: POSTGRESQL_CLIENT_MIN_MESSAGES
              value: "error"
            - name: POSTGRESQL_SHARED_PRELOAD_LIBRARIES
              value: "pgaudit"
          ports:
            - name: tcp-postgresql
              containerPort: 5432
          livenessProbe:
            exec:
              command:
                - /bin/sh
                - -c
                - exec pg_isready -U "gitea" -d "dbname=gitea" -h 127.0.0.1 -p 5432
            initialDelaySeconds: 30
            periodSeconds: 10
            timeoutSeconds: 5
            successThreshold: 1
            failureThreshold: 6
          readinessProbe:
            exec:
              command:
                - /bin/sh
                - -c
                - -e
                - |
                  exec pg_isready -U "gitea" -d "dbname=gitea" -h 127.0.0.1 -p 5432
                  [ -f /opt/bitnami/postgresql/tmp/.initialized ] || [ -f /bitnami/postgresql/.initialized ]
            initialDelaySeconds: 5
            periodSeconds: 10
            timeoutSeconds: 5
            successThreshold: 1
            failureThreshold: 6
          volumeMounts:
            - name: dshm
              mountPath: /dev/shm
            - name: data
              mountPath: /bitnami/postgresql
              subPath: 
      volumes:
        - name: dshm
          emptyDir:
            medium: Memory
            sizeLimit: 1Gi
  volumeClaimTemplates:
    - metadata:
        name: data
      spec:
        accessModes:
          - "ReadWriteOnce"
        resources:
          requests:
            storage: "10Gi"
---
# Source: oes/charts/gitea/templates/gitea/statefulset.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: isd-gitea
  labels:
    helm.sh/chart: gitea-5.0.1
    app: gitea
    app.kubernetes.io/name: gitea
    app.kubernetes.io/instance: isd
    app.kubernetes.io/version: "1.15.10"
    version: "1.15.10"
    app.kubernetes.io/managed-by: Helm
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: gitea
      app.kubernetes.io/instance: isd
  serviceName: isd-gitea
  template:
    metadata:
      annotations:
        checksum/config: 9d002fd7ae2d1eb91f8238f5d0f2896011847d3d71b8dc12d45add370e19de9c
      labels:
        helm.sh/chart: gitea-5.0.1
        app: gitea
        app.kubernetes.io/name: gitea
        app.kubernetes.io/instance: isd
        app.kubernetes.io/version: "1.15.10"
        version: "1.15.10"
        app.kubernetes.io/managed-by: Helm
    spec:
      securityContext:
        fsGroup: 1000
      initContainers:
        - name: init-directories
          image: "gitea/gitea:1.15.10"
          command: ["/usr/sbin/init_directory_structure.sh"]
          env:
            - name: GITEA_APP_INI
              value: /data/gitea/conf/app.ini
            - name: GITEA_CUSTOM
              value: /data/gitea
            - name: GITEA_WORK_DIR
              value: /data
            - name: GITEA_TEMP
              value: /tmp/gitea
          volumeMounts:
            - name: init
              mountPath: /usr/sbin
            - name: temp
              mountPath: /tmp
            - name: data
              mountPath: /data
          securityContext:
            {}
        - name: init-app-ini
          image: "gitea/gitea:1.15.10"
          command: ["/usr/sbin/config_environment.sh"]
          env:
            - name: GITEA_APP_INI
              value: /data/gitea/conf/app.ini
            - name: GITEA_CUSTOM
              value: /data/gitea
            - name: GITEA_WORK_DIR
              value: /data
            - name: GITEA_TEMP
              value: /tmp/gitea
          volumeMounts:
            - name: config
              mountPath: /usr/sbin
            - name: temp
              mountPath: /tmp
            - name: data
              mountPath: /data
            - name: inline-config-sources
              mountPath: /env-to-ini-mounts/inlines/
          securityContext:
            {}
        - name: configure-gitea
          image: "gitea/gitea:1.15.10"
          command: ["/usr/sbin/configure_gitea.sh"]
          securityContext:
            runAsUser: 1000
          env:
            - name: GITEA_APP_INI
              value: /data/gitea/conf/app.ini
            - name: GITEA_CUSTOM
              value: /data/gitea
            - name: GITEA_WORK_DIR
              value: /data
            - name: GITEA_TEMP
              value: /tmp/gitea
            - name: GITEA_ADMIN_USERNAME
              valueFrom:
                secretKeyRef:
                  key:  username
                  name: gitea-secret
            - name: GITEA_ADMIN_PASSWORD
              valueFrom:
                secretKeyRef:
                  key:  password
                  name: gitea-secret
          volumeMounts:
            - name: init
              mountPath: /usr/sbin
            - name: temp
              mountPath: /tmp
            - name: data
              mountPath: /data
      terminationGracePeriodSeconds: 60
      containers:
        - name: gitea
          image: "gitea/gitea:1.15.10"
          imagePullPolicy: Always
          env:
            # SSH Port values have to be set here as well for openssh configuration
            - name: SSH_LISTEN_PORT
              value: "22"
            - name: SSH_PORT
              value: "22"
            - name: GITEA_APP_INI
              value: /data/gitea/conf/app.ini
            - name: GITEA_CUSTOM
              value: /data/gitea
            - name: GITEA_WORK_DIR
              value: /data
            - name: GITEA_TEMP
              value: /tmp/gitea
            - name: TMPDIR
              value: /tmp/gitea
          ports:
            - name: ssh
              containerPort: 22
            - name: http
              containerPort: 3000
          livenessProbe:
            failureThreshold: 10
            initialDelaySeconds: 200
            periodSeconds: 10
            successThreshold: 1
            tcpSocket:
              port: http
            timeoutSeconds: 1
          readinessProbe:
            failureThreshold: 3
            initialDelaySeconds: 5
            periodSeconds: 10
            successThreshold: 1
            tcpSocket:
              port: http
            timeoutSeconds: 1
          resources:
            {}
          securityContext:
            {}
          volumeMounts:
            - name: temp
              mountPath: /tmp
            - name: data
              mountPath: /data
      volumes:
        - name: init
          secret:
            secretName: isd-gitea-init
            defaultMode: 110
        - name: config
          secret:
            secretName: isd-gitea
            defaultMode: 110
        - name: inline-config-sources
          secret:
            secretName: isd-gitea-inline-config
        - name: temp
          emptyDir: {}
  volumeClaimTemplates:
    - metadata:
        name: data
      spec:
        accessModes:
            - "ReadWriteOnce"
        resources:
          requests:
            storage: "10Gi"
---
# Source: oes/charts/redis/templates/redis-master-statefulset.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: isd-redis-master
  labels:
    app: redis
    chart: redis-10.5.3
    release: isd
    heritage: Helm
spec:
  selector:
    matchLabels:
      app: redis
      release: isd
      role: master
  serviceName: isd-redis-headless
  template:
    metadata:
      labels:
        app: redis
        chart: redis-10.5.3
        release: isd
        role: master
      annotations:
        checksum/health: 36567aac6587929dc97be63c28c0aa1ec58d167572f3e5f191536195dc588d15
        checksum/configmap: 42a460f87c190197092321f0ae70720d271a2f6738150858f02b13ca057dae95
        checksum/secret: 92c3542fca96bee16e081be3a51ac49fa2ad66360cd283b768155ca7bae80c9e
    spec:      
      securityContext:
        fsGroup: 1001
      serviceAccountName: "default"
      containers:
      - name: isd-redis
        image: "quay.io/opsmxpublic/bitnami-redis:5.0.7-debian-10-r0"
        imagePullPolicy: "IfNotPresent"
        securityContext:
          runAsUser: 1001
        command:
        - /bin/bash
        - -c
        - |
          if [[ -n $REDIS_PASSWORD_FILE ]]; then
            password_aux=`cat ${REDIS_PASSWORD_FILE}`
            export REDIS_PASSWORD=$password_aux
          fi
          if [[ ! -f /opt/bitnami/redis/etc/master.conf ]];then
            cp /opt/bitnami/redis/mounted-etc/master.conf /opt/bitnami/redis/etc/master.conf
          fi
          if [[ ! -f /opt/bitnami/redis/etc/redis.conf ]];then
            cp /opt/bitnami/redis/mounted-etc/redis.conf /opt/bitnami/redis/etc/redis.conf
          fi
          ARGS=("--port" "${REDIS_PORT}")
          ARGS+=("--requirepass" "${REDIS_PASSWORD}")
          ARGS+=("--masterauth" "${REDIS_PASSWORD}")
          ARGS+=("--include" "/opt/bitnami/redis/etc/redis.conf")
          ARGS+=("--include" "/opt/bitnami/redis/etc/master.conf")
          /run.sh ${ARGS[@]}
        env:
        - name: REDIS_REPLICATION_MODE
          value: master
        - name: REDIS_PASSWORD
          valueFrom:
            secretKeyRef:
              name: isd-redis
              key: redis-password
        - name: REDIS_PORT
          value: "6379"
        ports:
        - name: redis
          containerPort: 6379
        livenessProbe:
          initialDelaySeconds: 5
          periodSeconds: 5
          timeoutSeconds: 5
          successThreshold: 1
          failureThreshold: 5
          exec:
            command:
            - sh
            - -c
            - /health/ping_liveness_local.sh 5
        readinessProbe:
          initialDelaySeconds: 5
          periodSeconds: 5
          timeoutSeconds: 1
          successThreshold: 1
          failureThreshold: 5
          exec:
            command:
            - sh
            - -c
            - /health/ping_readiness_local.sh 5
        resources:
          null
        volumeMounts:
        - name: health
          mountPath: /health
        - name: redis-data
          mountPath: /data
          subPath: 
        - name: config
          mountPath: /opt/bitnami/redis/mounted-etc
        - name: redis-tmp-conf
          mountPath: /opt/bitnami/redis/etc/
      volumes:
      - name: health
        configMap:
          name: isd-redis-health
          defaultMode: 0755
      - name: config
        configMap:
          name: isd-redis
      - name: redis-tmp-conf
        emptyDir: {}
  volumeClaimTemplates:
    - metadata:
        name: redis-data
        labels:
          app: redis
          release: isd
          heritage: Helm
          component: master
      spec:
        accessModes:
          - "ReadWriteOnce"
        resources:
          requests:
            storage: "8Gi"
        
        selector:
  updateStrategy:
    type: RollingUpdate
---
# Source: oes/charts/spinnaker/templates/statefulsets/halyard.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: isd-spinnaker-halyard
  labels:
    app: "isd-spinnaker"
    heritage: "Helm"
    release: "isd"
    chart: "spinnaker-2.2.3"
spec:
  serviceName: isd-spinnaker-halyard
  replicas: 1
  selector:
    matchLabels:
      app: "isd-spinnaker"
      release: "isd"
      component: halyard
  template:
    metadata:
      annotations:
        checksum/configmap: b90745987686cb7c3ddd1844abf4730178428639c6f3a202bdc2714d0bd3e2b5
      labels:
        app: "isd-spinnaker"
        heritage: "Helm"
        release: "isd"
        chart: "spinnaker-2.2.3"
        component: halyard
    spec:
      serviceAccountName: isd-spinnaker-halyard
      securityContext:
        fsGroup: 1000
        runAsUser: 1000
      initContainers:
      - name: "create-halyard-local"
        image: quay.io/opsmxpublic/awsgit:v2-openssh
        command:
        - sh
        - /tmp/initscript/init.sh
        env:
        - name: SPINNAKER_NAMESPACE
          valueFrom:
            fieldRef:
              fieldPath: metadata.namespace
        - name: GITEA_USER
          valueFrom:
            secretKeyRef:
              name: gitea-secret
              key: username
        - name: GITEA_PASS
          valueFrom:
            secretKeyRef:
              name: gitea-secret
              key: password
        volumeMounts:
        - name: halyard-config
          mountPath: /tmp/config
        - name: service-settings
          mountPath: /tmp/service-settings
        - name: halyard-home
          mountPath: /tmp/spinnaker
        - name: additional-profile-config-maps
          mountPath: /tmp/additionalProfileConfigMaps
        - name: halyard-initscript
          mountPath: /tmp/initscript
      - name: "halyardconfig-update"
        command:
        - sh
        - /tmp/akv2k8s/run.sh
        image: quay.io/opsmxpublic/k8s-decoder:hal
        imagePullPolicy: IfNotPresent
        resources: {}
        volumeMounts:
        - name: halyard-home
          mountPath: /tmp/spinnaker
        - name: secret-decoder
          mountPath: /tmp/akv2k8s
      - name: "halyard-overrideurl"
        command:
        - sh
        - /tmp/autoconfig/call_overrides.sh
        env:
        - name: NODE_IP
          valueFrom:
            fieldRef:
              apiVersion: v1
              fieldPath: status.hostIP
        image: quay.io/opsmxpublic/bitnami-kubectl:1.18.5
        imagePullPolicy: IfNotPresent
        resources: {}
        volumeMounts:
        - name: halyard-config
          mountPath: /tmp/config
        - name: service-settings
          mountPath: /tmp/service-settings
        - name: halyard-home
          mountPath: /tmp/spinnaker
        - name: additional-profile-config-maps
          mountPath: /tmp/additionalProfileConfigMaps
        - name: halyard-initscript
          mountPath: /tmp/initscript
        - mountPath: /tmp/autoconfig
          name: halyard-overrideurl
      volumes:
      - name: halyard-home
        emptyDir: {}
      - name: halyard-overrideurl
        configMap:
          name: isd-spinnaker-halyard-overrideurl
      - name: secret-decoder
        configMap:
          name: isd-spinnaker-spin-secret-decoder
      - name: reg-secrets
        secret:
          secretName: isd-spinnaker-registry
      - name: additional-profile-config-maps
        configMap:
          name: isd-spinnaker-additional-profile-config-maps
      - name: halyard-config
        emptyDir: {}
      - name: service-settings
        configMap:
          name: isd-spinnaker-service-settings
      - name: halyard-initscript
        configMap:
          name: isd-spinnaker-halyard-init-script
      containers:
      - name: halyard
        image: quay.io/opsmxpublic/ubi8-spin-halyard:opsmx-1.40.0
        lifecycle:
          postStart:
            exec:
              command: ["/bin/sh", "-c", "until hal --ready; do sleep 10 ;done;hal deploy apply"]
        ports:
        - containerPort: 8064
          name: daemon
        volumeMounts:
        - name: halyard-home
          mountPath: /home/spinnaker
        - name: halyard-config
          mountPath: /opt/halyard/config
        - name: reg-secrets
          mountPath: /opt/registry/passwords
---
# Source: oes/templates/statefulsets/oes-db-statefulset.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  labels:
    app: oes
    component: db
    heritage: "Helm"
    release: "isd"
    chart: "oes-3.12.2"
  name: oes-db
spec:
  podManagementPolicy: OrderedReady
  replicas: 1
  serviceName: oes-db
  selector:
    matchLabels:
      app: oes
      component: db
  template:
    metadata:
      labels:
        app: oes
        component: db
        heritage: "Helm"
        release: "isd"
        chart: "oes-3.12.2"
    spec:
      imagePullSecrets:
      - name: opsmx11-secret
      containers:
      - image: quay.io/opsmxpublic/ubi8-oes-db:v3.0.0
        imagePullPolicy: IfNotPresent
        name: oes-db
        lifecycle:
          preStop:
            exec:
              command:
              - /bin/sh
              - /opt/opsmx/bin/stop.sh
        ports:
        - containerPort: 5432
          protocol: TCP
        volumeMounts:
        - mountPath: "/var/lib/pgsql-pv"
          name: oes-db-postgresql
        readinessProbe:
          tcpSocket:
            port: 5432
          initialDelaySeconds: 10
          periodSeconds: 5
      securityContext:
        fsGroup: 1000
  volumeClaimTemplates:
  - metadata:
      creationTimestamp: null
      labels:
        app: oes
        component: db
      name: oes-db-postgresql
    spec:
      accessModes:
      - ReadWriteOnce
      resources:
        requests:
          storage: 8Gi
      volumeMode: Filesystem
---
# Source: oes/charts/spinnaker/templates/deployments/create-sample-job.yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: isd-create-sample-app
spec:
  template:
    spec:
      serviceAccountName: isd-spinnaker-halyard
      securityContext:
        fsGroup: 1000
        runAsUser: 1000
      restartPolicy: OnFailure
      volumes:
      - secret:
          secretName: isd-spinnaker-spin-config
        name: spin-config
      - configMap:
          defaultMode: 420
          name: isd-spinnaker-spin-pipeline-import
        name: spin-pipeline-import
      - name: spin-pipeline-config
        emptyDir: {}
      containers:
      - command:  
        - bash
        - /tmp/config/spin-pipeline-import.sh
        name: sample-pipeline-install
        image: quay.io/opsmxpublic/spin-sample-pipeline:1.0
        volumeMounts:         
        - name: spin-pipeline-config
          mountPath: /tmp/config/git
        - mountPath: /tmp/config
          name: spin-pipeline-import
        - mountPath: /tmp/config/spin
          name: spin-config
---
# Source: oes/templates/forwarder/create-controller-secret.yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: create-controller-secret
spec:
 template:
    spec:
       containers:
       - name: create-secret-container
         image: quay.io/opsmxpublic/create-secret:v20211127T140816
         env:
         - name: NAMESPACE
           valueFrom:
            fieldRef:
              fieldPath: metadata.namespace
         args: 
         - "$(NAMESPACE)" 
       restartPolicy: Never
       serviceAccount: create-controller-secret
---
# Source: oes/charts/minio/templates/post-install-create-bucket-job.yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: isd-minio-make-bucket-job
  labels:
    app: minio-make-bucket-job
    chart: minio-8.0.9
    release: isd
    heritage: Helm
  annotations:
    "helm.sh/hook": post-install,post-upgrade
    "helm.sh/hook-delete-policy": hook-succeeded,before-hook-creation
spec:
  template:
    metadata:
      labels:
        app: minio-job
        release: isd
    spec:
      restartPolicy: OnFailure      
      volumes:
        - name: minio-configuration
          projected:
            sources:
            - configMap:
                name: isd-minio
            - secret:
                name: isd-minio
      serviceAccountName: "isd-minio"
      containers:
      - name: minio-mc
        image: "minio/mc:RELEASE.2020-11-25T23-04-07Z"
        imagePullPolicy: IfNotPresent
        command: ["/bin/sh", "/config/initialize"]
        env:
          - name: MINIO_ENDPOINT
            value: isd-minio
          - name: MINIO_PORT
            value: "9000"
        volumeMounts:
          - name: minio-configuration
            mountPath: /config
        resources:
          requests:
            memory: 128Mi
---
# Source: oes/charts/spinnaker/templates/hooks/install-using-hal.yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: "isd-install-using-hal"
  labels:
    app: "isd-spinnaker"
    heritage: "Helm"
    release: "isd"
    chart: "spinnaker-2.2.3"
  annotations:
    "helm.sh/hook": "post-install,post-upgrade"
    "helm.sh/hook-delete-policy": "before-hook-creation"
    "helm.sh/hook-weight": "0"
spec:
  template:
    metadata:
      annotations:
        checksum/config: 2a98b46fe11260d3a3825a88d99252ea746c3fef7dbbedef2a475165c81f0b5c
      labels:
        app: "isd-spinnaker"
        heritage: "Helm"
        release: "isd"
        chart: "spinnaker-2.2.3"
    spec:
      serviceAccountName: isd-spinnaker-halyard
      securityContext:
        fsGroup: 1000
        runAsUser: 1000
      restartPolicy: OnFailure
      volumes:
      - name: halyard-config
        configMap:
          name: isd-spinnaker-halyard-config
      containers:
      - name: halyard-install
        image: quay.io/opsmxpublic/ubi8-spin-halyard:opsmx-1.40.0
        volumeMounts:
        - name: halyard-config
          mountPath: /opt/halyard/scripts
        command:
        - bash
        - -xe
        - "/opt/halyard/scripts/install.sh"
        env:
        - name: NODE_IP
          valueFrom:
            fieldRef:
              apiVersion: v1
              fieldPath: status.hostIP
---
# Source: oes/templates/hooks/oes-config-job.yaml
apiVersion: batch/v1
kind: Job
metadata:
  annotations:
    "helm.sh/hook": "post-install,post-upgrade"
    "helm.sh/hook-delete-policy": "before-hook-creation"
    "helm.sh/hook-weight": "5"
  labels:
    app: oes
    component: oes-config
    heritage: "Helm"
    release: "isd"
    chart: "oes-3.12.2"
  name: oes-config
spec:
  template:
    metadata:
      annotations:
        checksum/configmap: 44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a
      labels:
        app: oes
        component: oes-config
        heritage: "Helm"
        release: "isd"
        chart: "oes-3.12.2"
    spec:
      containers:
      - command: ["bash", "/tmp/config/datasource-api.sh" ]
        name: datasource-creation-api
        image: quay.io/opsmxpublic/oes-pre-configure:v2
        volumeMounts:
        - mountPath: /tmp/config
          name: datasource-creation
      imagePullSecrets:
      - name: opsmx11-secret
      restartPolicy: OnFailure
      volumes:
      - configMap:
          defaultMode: 420
          name: isd-oes-datasource-creation
        name: datasource-creation
